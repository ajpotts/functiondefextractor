,Uniq ID,Code,np_calls,num_np_calls,np_calls_w_args,arkouda_function
0,/home/amandapotts/git/arkouda/arkouda/series.py_is_supported_scalar,"def is_supported_scalar(x):
return isinstance(x, (int, float, bool, str, np.int64, np.float64, np.bool_, np.str_))
","['int64', 'float64', 'bool_', 'str_']",4,[],/series.py_is_supported_scalar
1,/home/amandapotts/git/arkouda/arkouda/series.py_natural_binary_operators,"def natural_binary_operators(cls):
for name, op in {
""__add__"": operator.add,
""__sub__"": operator.sub,
""__mul__"": operator.mul,
""__truediv__"": operator.truediv,
""__floordiv__"": operator.floordiv,
""__and__"": operator.and_,
""__or__"": operator.or_,
""__xor__"": operator.xor,
""__eq__"": operator.eq,
""__ge__"": operator.ge,
""__gt__"": operator.gt,
""__le__"": operator.le,
""__lshift__"": operator.lshift,
""__lt__"": operator.lt,
""__mod__"": operator.mod,
""__ne__"": operator.ne,
""__rshift__"": operator.rshift,
""__pow__"": operator.pow,
}.items():
setattr(cls, name, cls._make_binop(op))
return cls
",[],0,[],/series.py_natural_binary_operators
2,/home/amandapotts/git/arkouda/arkouda/series.py_unary_operators,"def unary_operators(cls):
for name, op in {
""__invert__"": operator.invert,
""__neg__"": operator.neg,
}.items():
setattr(cls, name, cls._make_unaryop(op))
return cls
",[],0,[],/series.py_unary_operators
3,/home/amandapotts/git/arkouda/arkouda/series.py_aggregation_operators,"def aggregation_operators(cls):
for name in [""max"", ""min"", ""mean"", ""sum"", ""std"", ""var"", ""argmax"", ""argmin"", ""prod""]:
setattr(cls, name, cls._make_aggop(name))
return cls
",[],0,[],/series.py_aggregation_operators
4,/home/amandapotts/git/arkouda/arkouda/series.py___init__,"def __init__(
self,
data: Union[Tuple, List, groupable_element_type],
name=None,
index: Optional[Union[pdarray, Strings, Tuple, List, Index]] = None,
",[],0,[],/series.py___init__
5,/home/amandapotts/git/arkouda/arkouda/series.py__constructor,"def _constructor(self) -> Callable[..., Series]:
return Series
",[],0,[],/series.py__constructor
6,/home/amandapotts/git/arkouda/arkouda/series.py__constructor_expanddim,"def _constructor_expanddim(self) -> Callable[..., arkouda.dataframe.DataFrame]:
""""""
Used when a manipulation result has one higher dimension as the
original, such as Series.to_frame()
""""""
from arkouda.dataframe import DataFrame
return DataFrame
",[],0,[],/series.py__constructor_expanddim
7,/home/amandapotts/git/arkouda/arkouda/series.py___len__,"def __len__(self):
return self.values.size
",[],0,[],/series.py___len__
8,/home/amandapotts/git/arkouda/arkouda/series.py___repr__,"def __repr__(self):
""""""
Return ascii-formatted version of the series.
""""""
if len(self) == 0:
return ""Series([ -- ][ 0 values : 0 B])""
maxrows = pd.get_option(""display.max_rows"")
if len(self) <= maxrows:
prt = self.to_pandas()
length_str = """"
else:
prt = pd.concat(
[
self.head(maxrows // 2 + 2).to_pandas(),
self.tail(maxrows // 2).to_pandas(),
]
)
length_str = f""\nLength {len(self)}""
return (
prt.to_string(
dtype=prt.dtype,
min_rows=get_option(""display.min_rows""),
max_rows=maxrows,
length=False,
)
+ length_str
)
",[],0,[],/series.py___repr__
9,/home/amandapotts/git/arkouda/arkouda/series.py_validate_key,"def validate_key(
self, key: Union[Series, pdarray, Strings, Categorical, List, supported_scalars]
",[],0,[],/series.py_validate_key
10,/home/amandapotts/git/arkouda/arkouda/series.py___getitem__,"def __getitem__(self, _key: Union[supported_scalars, pdarray, Strings, List]):
""""""
Gets values from Series.
Parameters
----------
key: pdarray, Strings, Series, list, supported_scalars
The key or container of keys to get entries for.
Returns
-------
Series with all entries with matching labels. If only one entry in the
Series is accessed, returns a scalar.
""""""
key = self.validate_key(_key)
if is_supported_scalar(key):
return self[array([key])]
assert isinstance(key, (pdarray, Strings))
if key.dtype == bool:
return Series(index=self.index[key], data=self.values[key])
indices = indexof1d(key, self.index.values)
if len(indices) == 1:
return self.values[indices[0]]
else:
return Series(index=self.index[indices], data=self.values[indices])
",[],0,[],/series.py___getitem__
11,/home/amandapotts/git/arkouda/arkouda/series.py_validate_val,"def validate_val(
self, val: Union[pdarray, Strings, supported_scalars, List]
",[],0,[],/series.py_validate_val
12,/home/amandapotts/git/arkouda/arkouda/series.py___setitem__,"def __setitem__(self, key, val):
""""""
Sets or adds entries in a Series by label.
Parameters
----------
key: pdarray, Strings, Series, list, supported_scalars
The key or container of keys to set entries for.
val: pdarray, list, supported_scalars
The values to set/add to the Series.
Raises
------
ValueError
Raised when setting multiple values to a Series with repeated labels
Raised when number of values provided does not match the number of
entries to set.
""""""
val = self.validate_val(val)
key = self.validate_key(key)
if isinstance(key, (pdarray, Strings)) and len(key) > 1 and self.has_repeat_labels():
raise ValueError(""Cannot set with multiple keys for Series with repeated labels."")
indices = None
if is_supported_scalar(key):  # type: ignore
indices = self.index == key
else:
indices = in1d(self.index.values, key)  # type: ignore
tf, counts = GroupBy(indices).count()
update_count = counts[1] if len(counts) == 2 else 0
if update_count == 0:
if isinstance(val, (pdarray, Strings)):
raise ValueError(""Cannot set. Too many values provided"")
new_index_values = concatenate([self.index.values, array([key])])
self.index = Index.factory(new_index_values)
self.values = concatenate([self.values, array([val])])
return
if is_supported_scalar(val):  # type: ignore
self.values[indices] = val
return
else:
if val.size == 1 and is_supported_scalar(key):  # type: ignore
self.values[indices] = val[0]  # type: ignore
return
if update_count != val.size:
raise ValueError(
""Cannot set using a list-like indexer with a different length from the value""
)
self.values[indices] = val
return
",[],0,[],/series.py___setitem__
13,/home/amandapotts/git/arkouda/arkouda/series.py_has_repeat_labels,"def has_repeat_labels(self) -> bool:
""""""
Returns whether the Series has any labels that appear more than once
""""""
tf, counts = GroupBy(self.index.values).count()
return counts.size != self.index.size
",[],0,[],/series.py_has_repeat_labels
14,/home/amandapotts/git/arkouda/arkouda/series.py_loc,"def loc(self) -> _LocIndexer:
""""""
Accesses entries of a Series by label
Parameters
----------
key: pdarray, Strings, Series, list, supported_scalars
The key or container of keys to access entries for
""""""
return _LocIndexer(self)
",[],0,[],/series.py_loc
15,/home/amandapotts/git/arkouda/arkouda/series.py_at,"def at(self) -> _LocIndexer:
""""""
Accesses entries of a Series by label
Parameters
----------
key: pdarray, Strings, Series, list, supported_scalars
The key or container of keys to access entries for
""""""
return _LocIndexer(self)
",[],0,[],/series.py_at
16,/home/amandapotts/git/arkouda/arkouda/series.py_iloc,"def iloc(self) -> _iLocIndexer:
""""""
Accesses entries of a Series by position
Parameters
----------
key: int
The positions or container of positions to access entries for
""""""
return _iLocIndexer(""iloc"", self)
",[],0,[],/series.py_iloc
17,/home/amandapotts/git/arkouda/arkouda/series.py_iat,"def iat(self) -> _iLocIndexer:
""""""
Accesses entries of a Series by position
Parameters
----------
key: int
The positions or container of positions to access entries for
""""""
return _iLocIndexer(""iat"", self)
",[],0,[],/series.py_iat
18,/home/amandapotts/git/arkouda/arkouda/series.py_shape,"def shape(self):
return (self.values.size,)
",[],0,[],/series.py_shape
19,/home/amandapotts/git/arkouda/arkouda/series.py_isin,"def isin(self, lst: Union[pdarray, Strings, List]) -> Series:
""""""Find series elements whose values are in the specified list
Input
-----
Either a python list or an arkouda array.
Returns
-------
Arkouda boolean which is true for elements that are in the list and false otherwise.
""""""
if isinstance(lst, list):
lst = array(lst)
boolean = in1d(self.values, lst)
return Series(data=boolean, index=self.index)
",[],0,[],/series.py_isin
20,/home/amandapotts/git/arkouda/arkouda/series.py_locate,"def locate(self, key: Union[int, pdarray, Index, Series, List, Tuple]) -> Series:
""""""Lookup values by index label
The input can be a scalar, a list of scalers, or a list of lists (if the series has a
MultiIndex). As a special case, if a Series is used as the key, the series labels are
preserved with its values use as the key.
Keys will be turned into arkouda arrays as needed.
Returns
-------
A Series containing the values corresponding to the key.
""""""
if isinstance(key, Series):
return Series(index=key.index, data=lookup(self.index.index, self.values, key.values))
elif isinstance(key, MultiIndex):
idx = self.index.lookup(key.index)
elif isinstance(key, Index):
idx = self.index.lookup(key.index)
elif isinstance(key, pdarray):
idx = self.index.lookup(key)
elif isinstance(key, (list, tuple)):
key0 = key[0]
if isinstance(key0, list) or isinstance(key0, tuple):
if not isinstance(key0[0], pdarray):
key = [array(a) for a in np.array(key).T.copy()]
elif not isinstance(key0, pdarray):
try:
val = array(key)
if isinstance(val, pdarray):
key = val
except Exception:
raise TypeError(""'key' parameter must be convertible to pdarray"")
idx = self.index.lookup(key)
else:
idx = self.index == key
return Series(index=self.index[idx], data=self.values[idx])
",['array'],1,['array(key).T.copy()'],/series.py_locate
21,/home/amandapotts/git/arkouda/arkouda/series.py__make_binop,"def _make_binop(cls, operator):
",[],0,[],/series.py__make_binop
22,/home/amandapotts/git/arkouda/arkouda/series.py_binop,"def binop(self, other):
if isinstance(other, Series):
if self.index._check_aligned(other.index):
return cls((self.index, operator(self.values, other.values)))
else:
idx = self.index._merge(other.index).index
a = lookup(self.index.index, self.values, idx, fillvalue=0)
b = lookup(other.index.index, other.values, idx, fillvalue=0)
return cls((idx, operator(a, b)))
else:
return cls((self.index, operator(self.values, other)))
",[],0,[],/series.py_binop
23,/home/amandapotts/git/arkouda/arkouda/series.py__make_unaryop,"def _make_unaryop(cls, operator):
",[],0,[],/series.py__make_unaryop
24,/home/amandapotts/git/arkouda/arkouda/series.py_unaryop,"def unaryop(self):
return cls((self.index, operator(self.values)))
",[],0,[],/series.py_unaryop
25,/home/amandapotts/git/arkouda/arkouda/series.py__make_aggop,"def _make_aggop(cls, name):
",[],0,[],/series.py__make_aggop
26,/home/amandapotts/git/arkouda/arkouda/series.py_aggop,"def aggop(self):
return getattr(self.values, name)()
",[],0,[],/series.py_aggop
27,/home/amandapotts/git/arkouda/arkouda/series.py_add,"def add(self, b: Series) -> Series:
index = self.index.concat(b.index).index
values = concatenate([self.values, b.values], ordered=False)
idx, vals = GroupBy(index).sum(values)
return Series(data=vals, index=idx)
",[],0,[],/series.py_add
28,/home/amandapotts/git/arkouda/arkouda/series.py_topn,"def topn(self, n: int = 10) -> Series:
""""""Return the top values of the series
Parameters
----------
n: Number of values to return
Returns
-------
A new Series with the top values
""""""
k = self.index
v = self.values
idx = argmaxk(v, n)
idx = idx[-1 : -n - 1 : -1]
return Series(index=k.index[idx], data=v[idx])
",[],0,[],/series.py_topn
29,/home/amandapotts/git/arkouda/arkouda/series.py__reindex,"def _reindex(self, idx):
if isinstance(self.index, MultiIndex):
new_index = MultiIndex(self.index[idx].values, name=self.index.name, names=self.index.names)
elif isinstance(self.index, Index):
new_index = Index(self.index[idx], name=self.index.name)
else:
new_index = Index(self.index[idx])
return Series(index=new_index, data=self.values[idx])
",[],0,[],/series.py__reindex
30,/home/amandapotts/git/arkouda/arkouda/series.py_sort_index,"def sort_index(self, ascending: bool = True) -> Series:
""""""Sort the series by its index
Parameters
----------
ascending : bool
Sort values in ascending (default) or descending order.
Returns
-------
A new Series sorted.
""""""
idx = self.index.argsort(ascending=ascending)
return self._reindex(idx)
",[],0,[],/series.py_sort_index
31,/home/amandapotts/git/arkouda/arkouda/series.py_sort_values,"def sort_values(self, ascending: bool = True) -> Series:
""""""Sort the series numerically
Parameters
----------
ascending : bool
Sort values in ascending (default) or descending order.
Returns
-------
A new Series sorted smallest to largest
""""""
if not ascending:
if isinstance(self.values, pdarray) and self.values.dtype in (
int64,
float64,
):
idx = argsort(-self.values)
else:
idx = argsort(self.values)[arange(self.values.size - 1, -1, -1)]
else:
idx = argsort(self.values)
return self._reindex(idx)
",[],0,[],/series.py_sort_values
32,/home/amandapotts/git/arkouda/arkouda/series.py_tail,"def tail(self, n: int = 10) -> Series:
""""""Return the last n values of the series""""""
idx_series = self.index[-n:]
return Series(index=idx_series.index, data=self.values[-n:])
",[],0,[],/series.py_tail
33,/home/amandapotts/git/arkouda/arkouda/series.py_head,"def head(self, n: int = 10) -> Series:
""""""Return the first n values of the series""""""
idx_series = self.index[0:n]
return Series(index=idx_series.index, data=self.values[0:n])
",[],0,[],/series.py_head
34,/home/amandapotts/git/arkouda/arkouda/series.py_to_pandas,"def to_pandas(self) -> pd.Series:
""""""Convert the series to a local PANDAS series""""""
idx = self.index.to_pandas()
val = convert_if_categorical(self.values)
return pd.Series(val.to_ndarray(), index=idx)
",[],0,[],/series.py_to_pandas
35,/home/amandapotts/git/arkouda/arkouda/series.py_to_list,"def to_list(self) -> list:
p = self.to_pandas()
return p.to_list()
",[],0,[],/series.py_to_list
36,/home/amandapotts/git/arkouda/arkouda/series.py_value_counts,"def value_counts(self, sort: bool = True) -> Series:
""""""Return a Series containing counts of unique values.
The resulting object will be in descending order so that the
first element is the most frequently-occurring element.
Parameters
----------
sort : Boolean. Whether or not to sort the results.  Default is true.
""""""
dtype = get_callback(self.values)
idx, vals = value_counts(self.values)
s = Series(index=idx, data=vals)
if sort:
s = s.sort_values(ascending=False)
s.index.set_dtype(dtype)
return s
",[],0,[],/series.py_value_counts
37,/home/amandapotts/git/arkouda/arkouda/series.py_diff,"def diff(self) -> Series:
""""""Diffs consecutive values of the series.
Returns a new series with the same index and length.  First value is set to NaN.
""""""
values = zeros(len(self), ""float64"")
if not isinstance(self.values, Categorical):
values[1:] = akcast(self.values[1:] - self.values[:-1], ""float64"")
values[0] = np.nan
else:
raise TypeError(""Diff not supported on Series built from Categorical."")
return Series(data=values, index=self.index)
",['nan'],1,[],/series.py_diff
38,/home/amandapotts/git/arkouda/arkouda/series.py_to_dataframe,"def to_dataframe(
self, index_labels: List[str] = None, value_label: str = None
",[],0,[],/series.py_to_dataframe
39,/home/amandapotts/git/arkouda/arkouda/series.py_register,"def register(self, user_defined_name: str):
""""""
Register this Series object and underlying components with the Arkouda server
Parameters
----------
user_defined_name : str
user defined name the Series is to be registered under,
this will be the root name for underlying components
Returns
-------
Series
The same Series which is now registered with the arkouda server and has an updated name.
This is an in-place modification, the original is returned to support
a fluid programming style.
Please note you cannot register two different Series with the same name.
Raises
------
TypeError
Raised if user_defined_name is not a str
RegistrationError
If the server was unable to register the Series with the user_defined_name
See also
--------
unregister, attach, is_registered
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.client import generic_msg
if self.registered_name is not None and self.is_registered():
raise RegistrationError(f""This object is already registered as {self.registered_name}"")
generic_msg(
cmd=""register"",
args={
""name"": user_defined_name,
""objType"": self.objType,
""num_idxs"": 1,
""idx_names"": [
json.dumps(
{
""codes"": self.index.values.codes.name,
""categories"": self.index.values.categories.name,
""NA_codes"": self.index.values._akNAcode.name,
{""permutation"": self.index.values.permutation.name}
if self.index.values.permutation is not None
else {}
),
{""segments"": self.index.values.segments.name}
if self.index.values.segments is not None
else {}
),
}
)
if isinstance(self.index.values, Categorical)
else self.index.values.name
],
""idx_types"": [self.index.values.objType],
""values"": json.dumps(
{
""codes"": self.values.codes.name,
""categories"": self.values.categories.name,
""NA_codes"": self.values._akNAcode.name,
{""permutation"": self.values.permutation.name}
if self.values.permutation is not None
else {}
),
{""segments"": self.values.segments.name}
if self.values.segments is not None
else {}
),
}
)
if isinstance(self.values, Categorical)
else self.values.name,
""val_type"": self.values.objType,
},
)
self.registered_name = user_defined_name
return self
",[],0,[],/series.py_register
40,/home/amandapotts/git/arkouda/arkouda/series.py_unregister,"def unregister(self):
""""""
Unregister this Series object in the arkouda server which was previously
registered using register() and/or attached to using attach()
Raises
------
RegistrationError
If the object is already unregistered or if there is a server error
when attempting to unregister
See also
--------
register, attach, is_registered
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.util import unregister
if not self.registered_name:
raise RegistrationError(""This object is not registered"")
unregister(self.registered_name)
self.registered_name = None
",[],0,[],/series.py_unregister
41,/home/amandapotts/git/arkouda/arkouda/series.py_attach,"def attach(label: str, nkeys: int = 1) -> Series:
""""""
DEPRECATED
Retrieve a series registered with arkouda
Parameters
----------
label: name used to register the series
nkeys: number of keys, if a multi-index was registerd
""""""
import warnings
from arkouda.util import attach
warnings.warn(
""ak.Series.attach() is deprecated. Please use ak.attach() instead."",
DeprecationWarning,
)
return attach(label)
",[],0,[],/series.py_attach
42,/home/amandapotts/git/arkouda/arkouda/series.py_is_registered,"def is_registered(self) -> bool:
""""""
Return True iff the object is contained in the registry or is a component of a
registered object.
Returns
-------
numpy.bool
Indicates if the object is contained in the registry
Raises
------
RegistrationError
Raised if there's a server-side error or a mis-match of registered components
See Also
--------
register, attach, unregister
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.util import is_registered
if self.registered_name is None:
return False
else:
return is_registered(self.registered_name)
",[],0,[],/series.py_is_registered
43,/home/amandapotts/git/arkouda/arkouda/series.py_from_return_msg,"def from_return_msg(cls, repMsg: str) -> Series:
""""""
Return a Series instance pointing to components created by the arkouda server.
The user should not call this function directly.
Parameters
----------
repMsg : str
+ delimited string containing the values and indexes
Returns
-------
Series
A Series representing a set of pdarray components on the server
Raises
------
RuntimeError
Raised if a server-side error is thrown in the process of creating
the Series instance
""""""
data = json.loads(repMsg)
val_comps = data[""value""].split(""+|+"")
if val_comps[0] == Categorical.objType.upper():
values = Categorical.from_return_msg(val_comps[1])  # type: ignore
elif val_comps[0] == Strings.objType.upper():
values = Strings.from_return_msg(val_comps[1])  # type: ignore
else:
values = create_pdarray(val_comps[1])  # type: ignore
index = Index.from_return_msg(data[""index""])
return cls(values, index)
",[],0,[],/series.py_from_return_msg
44,/home/amandapotts/git/arkouda/arkouda/series.py__all_aligned,"def _all_aligned(array: List) -> bool:
""""""Is an array of Series indexed aligned?""""""
itor = iter(array)
a1 = next(itor).index
for a2 in itor:
if a1._check_aligned(a2.index) is False:
return False
return True
",[],0,[],/series.py__all_aligned
45,/home/amandapotts/git/arkouda/arkouda/series.py_concat,"def concat(
arrays: List,
axis: int = 0,
index_labels: List[str] = None,
value_labels: List[str] = None,
",[],0,[],/series.py_concat
46,/home/amandapotts/git/arkouda/arkouda/series.py_pdconcat,"def pdconcat(arrays: List, axis: int = 0, labels: Strings = None) -> Union[pd.Series, pd.DataFrame]:
""""""Concatenate a list of arkouda Series or grouped arkouda arrays, returning a PANDAS object.
If a list of grouped arkouda arrays is passed they are converted to a series. Each grouping
is a 2-tuple with the first item being the key(s) and the second being the value.
If horizontal, each series or grouping must have the same length and the same index. The index of
the series is converted to a column in the dataframe.  If it is a multi-index,each level is
converted to a column.
Parameters
----------
arrays:  The list of series/groupings to concat.
axis  :  Whether or not to do a verticle (axis=0) or horizontal (axis=1) concatenation
labels:  names to give the columns of the data frame.
Returns
-------
axis=0: a local PANDAS series
axis=1: a local PANDAS dataframe
""""""
if len(arrays) == 0:
raise IndexError(""Array length must be non-zero"")
types = {type(x) for x in arrays}
if len(types) != 1:
raise TypeError(f""Items must all have same type: {types}"")
if isinstance(arrays[0], tuple):
arrays = [Series(i) for i in arrays]
if axis == 1:
idx = arrays[0].index.to_pandas()
cols = []
for col in arrays:
cols.append(pd.Series(data=col.values.to_ndarray(), index=idx))
retval = pd.concat(cols, axis=1)
if labels is not None:
retval.columns = labels
else:
retval = pd.concat([s.to_pandas() for s in arrays])
return retval
",[],0,[],/series.py_pdconcat
47,/home/amandapotts/git/arkouda/arkouda/series.py___init__,"def __init__(self, series):
self.series = series
",[],0,[],/series.py___init__
48,/home/amandapotts/git/arkouda/arkouda/series.py___getitem__,"def __getitem__(self, key):
return self.series[key]
",[],0,[],/series.py___getitem__
49,/home/amandapotts/git/arkouda/arkouda/series.py___setitem__,"def __setitem__(self, key, val):
self.series[key] = val
",[],0,[],/series.py___setitem__
50,/home/amandapotts/git/arkouda/arkouda/series.py___init__,"def __init__(self, method_name, series):
self.name = method_name
self.series = series
",[],0,[],/series.py___init__
51,/home/amandapotts/git/arkouda/arkouda/series.py_validate_key,"def validate_key(self, key):
if isinstance(key, list):
key = array(key)
if isinstance(key, tuple):
raise TypeError("".{} does not support tuple arguments"".format(self.name))
if isinstance(key, pdarray):
if len(key) == 0:
raise ValueError(""Cannot index using 0-length iterables."")
if key.dtype != int64 and key.dtype != bool:
raise TypeError("".{} requires integer keys"".format(self.name))
if key.dtype == bool and key.size != self.series.size:
raise IndexError(
""Boolean index has wrong length: {} instead of {}"".format(key.size, self.series.size)
)
elif any(key >= self.series.size):
raise IndexError(""{} cannot enlarge its target object."".format(self.name))
elif isinstance(key, int):
if key >= self.series.size:
raise IndexError(""{} cannot enlarge its target object."".format(self.name))
else:
raise TypeError("".{} requires integer keys"".format(self.name))
return key
",[],0,[],/series.py_validate_key
52,/home/amandapotts/git/arkouda/arkouda/series.py_validate_val,"def validate_val(self, val) -> Union[pdarray, supported_scalars]:
return self.series.validate_val(val)
",[],0,[],/series.py_validate_val
53,/home/amandapotts/git/arkouda/arkouda/series.py___getitem__,"def __getitem__(self, key):
key = self.validate_key(key)
if is_supported_scalar(key):  # type: ignore
key = array([key])
return Series(index=self.series.index[key], data=self.series.values[key])
",[],0,[],/series.py___getitem__
54,/home/amandapotts/git/arkouda/arkouda/series.py___setitem__,"def __setitem__(self, key, val):
key = self.validate_key(key)
val = self.validate_val(val)
if is_supported_scalar(val):  # type: ignore
self.series.values[key] = val
return
else:
if is_supported_scalar(key):  # type: ignore
self.series.values[key] = val
return
if key.dtype == int64 and len(val) != len(key):
raise ValueError(
""cannot set using a list-like indexer with a different length than the value""
)
self.series.values[key] = val
",[],0,[],/series.py___setitem__
55,/home/amandapotts/git/arkouda/arkouda/match.py___init__,"def __init__(
self,
matched: pdarray,
starts: pdarray,
lengths: pdarray,
indices: pdarray,
parent_entry_name: str,
match_type: MatchType,
pattern: str,
",[],0,[],/match.py___init__
56,/home/amandapotts/git/arkouda/arkouda/match.py___str__,"def __str__(self):
from arkouda.client import pdarrayIterThresh
if self._matched.size <= pdarrayIterThresh:
vals = [self.__getitem__(i) for i in range(self._matched.size)]
else:
vals = [self.__getitem__(i) for i in range(3)]
vals.append(""... "")
vals.extend([self.__getitem__(i) for i in range(self._matched.size - 3, self._matched.size)])
return f""<ak.{self._objtype} object: {'
",[],0,[],/match.py___str__
57,/home/amandapotts/git/arkouda/arkouda/match.py___getitem__,"def __getitem__(self, item):
return (
f""matched={self._matched[item]}, span=({self._starts[self._indices[item]]}""
f"", {self._ends[self._indices[item]]})""
if self._matched[item]
else f""matched={self._matched[item]}""
)
",[],0,[],/match.py___getitem__
58,/home/amandapotts/git/arkouda/arkouda/match.py___repr__,"def __repr__(self):
return self.__str__()
",[],0,[],/match.py___repr__
59,/home/amandapotts/git/arkouda/arkouda/match.py_matched,"def matched(self) -> pdarray:
""""""
Returns a boolean array indiciating whether each element matched
Returns
-------
pdarray, bool
True for elements that match, False otherwise
Examples
--------
>>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
>>> strings.search('_+').matched()
array([True True False True False])
""""""
return self._matched
",[],0,[],/match.py_matched
60,/home/amandapotts/git/arkouda/arkouda/match.py_start,"def start(self) -> pdarray:
""""""
Returns the starts of matches
Returns
-------
pdarray, int64
The start positions of matches
Examples
--------
>>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
>>> strings.search('_+').start()
array([1 0 0])
""""""
return self._starts
",[],0,[],/match.py_start
61,/home/amandapotts/git/arkouda/arkouda/match.py_end,"def end(self) -> pdarray:
""""""
Returns the ends of matches
Returns
-------
pdarray, int64
The end positions of matches
Examples
--------
>>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
>>> strings.search('_+').end()
array([2 4 2])
""""""
return self._ends
",[],0,[],/match.py_end
62,/home/amandapotts/git/arkouda/arkouda/match.py_match_type,"def match_type(self) -> str:
""""""
Returns the type of the Match object
Returns
-------
str
MatchType of the Match object
Examples
--------
>>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
>>> strings.search('_+').match_type()
'SEARCH'
""""""
return self._match_type.name
",[],0,[],/match.py_match_type
63,/home/amandapotts/git/arkouda/arkouda/match.py_find_matches,"def find_matches(self, return_match_origins: bool = False):
""""""
Return all matches as a new Strings object
Parameters
----------
return_match_origins: bool
If True, return a pdarray containing the index of the original string each pattern
match is from
Returns
-------
Strings
Strings object containing only matches
pdarray, int64 (optional)
The index of the original string each pattern match is from
Raises
------
RuntimeError
Raised if there is a server-side error thrown
Examples
--------
>>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
>>> strings.search('_+').find_matches(return_match_origins=True)
(array(['_', '____', '__']), array([0 1 3]))
""""""
from arkouda.strings import Strings
repMsg = cast(
str,
generic_msg(
cmd=""segmentedFindAll"",
args={
""objType"": self._objtype,
""parent_name"": self._parent_entry_name,
""num_matches"": self._matched,
""starts"": self._starts,
""lengths"": self._lengths,
""indices"": self._indices,
""rtn_origins"": return_match_origins,
},
),
)
if return_match_origins:
arrays = repMsg.split(""+"", maxsplit=2)
return Strings.from_return_msg(""+"".join(arrays[0:2])), create_pdarray(arrays[2])
else:
return Strings.from_return_msg(repMsg)
",[],0,[],/match.py_find_matches
64,/home/amandapotts/git/arkouda/arkouda/match.py_group,"def group(self, group_num: int = 0, return_group_origins: bool = False):
""""""
Returns a new Strings containing the capture group corresponding to group_num.
For the default, group_num=0, return the full match
Parameters
----------
group_num: int
The index of the capture group to be returned
return_group_origins: bool
If True, return a pdarray containing the index of the original string each
capture group is from
Returns
-------
Strings
Strings object containing only the capture groups corresponding to group_num
pdarray, int64 (optional)
The index of the original string each group is from
Examples
--------
>>> strings = ak.array([""Isaac Newton, physics"", '<-calculus->', 'Gottfried Leibniz, math'])
>>> m = strings.search(""(\\w+) (\\w+)"")
>>> m.group()
array(['Isaac Newton', 'Gottfried Leibniz'])
>>> m.group(1)
array(['Isaac', 'Gottfried'])
>>> m.group(2, return_group_origins=True)
(array(['Newton', 'Leibniz']), array([0 2]))
""""""
from arkouda.client import regexMaxCaptures
from arkouda.strings import Strings
if group_num < 0:
raise ValueError(""group_num cannot be negative"")
if group_num > regexMaxCaptures:
max_capture_flag = f""-e REGEX_MAX_CAPTURES={group_num}""
e = (
f""group_num={group_num} > regexMaxCaptures={regexMaxCaptures}.""
f"" To run group({group_num}), recompile the server with flag '{max_capture_flag}'""
)
raise ValueError(e)
repMsg = cast(
str,
generic_msg(
cmd=""segmentedFindLoc"",
args={
""objType"": self._objtype,
""parent_name"": self._parent_entry_name,
""groupNum"": group_num,
""pattern"": self.re,
},
),
)
created_map = json.loads(repMsg)
global_starts = create_pdarray(created_map[""Starts""])
global_lengths = create_pdarray(created_map[""Lens""])
global_indices = create_pdarray(created_map[""Indices""])
if self._match_type == MatchType.SEARCH:
matched = create_pdarray(created_map[""SearchBool""])
indices = create_pdarray(created_map[""SearchInd""])
elif self._match_type == MatchType.MATCH:
matched = create_pdarray(created_map[""MatchBool""])
indices = create_pdarray(created_map[""MatchInd""])
elif self._match_type == MatchType.FULLMATCH:
matched = create_pdarray(created_map[""FullMatchBool""])
indices = create_pdarray(created_map[""FullMatchInd""])
else:
raise ValueError(f""{self._match_type} is not a MatchType"")
starts = global_starts[global_indices[matched]]
lengths = global_lengths[global_indices[matched]]
repMsg = cast(
str,
generic_msg(
cmd=""segmentedFindAll"",
args={
""objType"": self._objtype,
""parent_name"": self._parent_entry_name,
""num_matches"": matched,
""starts"": starts,
""lengths"": lengths,
""indices"": indices,
""rtn_origins"": return_group_origins,
},
),
)
if return_group_origins:
arrays = repMsg.split(""+"", maxsplit=2)
return Strings.from_return_msg(""+"".join(arrays[0:2])), create_pdarray(arrays[2])
else:
return Strings.from_return_msg(repMsg)
",[],0,[],/match.py_group
65,/home/amandapotts/git/arkouda/arkouda/categorical.py___init__,"def __init__(self, values, **kwargs) -> None:
self.logger = getArkoudaLogger(name=__class__.__name__)  # type: ignore
if ""codes"" in kwargs and ""categories"" in kwargs:
self.codes = kwargs[""codes""]
self.categories = kwargs[""categories""]
if (self.codes.min() < 0) or (self.codes.max() >= self.categories.size):
raise ValueError(
f""Codes out of bounds for categories: min = {self.codes.min()},""
f"" max = {self.codes.max()}, categories = {self.categories.size}""
)
self.permutation = kwargs.get(""permutation"", None)
self.segments = kwargs.get(""segments"", None)
if self.permutation is not None and self.segments is not None:
self.permutation = cast(pdarray, self.permutation)
self.segments = cast(pdarray, self.segments)
unique_codes = self.codes[self.permutation[self.segments]]
else:
unique_codes = unique(self.codes)
self._categories_used = self.categories[unique_codes]
else:
if not isinstance(values, Strings):
raise ValueError((""Categorical: inputs other than "" + ""Strings not yet supported""))
g = GroupBy(values)
self.categories = g.unique_keys
self.codes = g.broadcast(arange(self.categories.size), permute=True)
self.permutation = cast(pdarray, g.permutation)
self.segments = g.segments
self._categories_used = self.categories[:]
if ""_akNAcode"" in kwargs and kwargs[""_akNAcode""] is not None:
self._akNAcode = kwargs[""_akNAcode""]
self._NAcode = int(self._akNAcode[0])
self.NAvalue = self.categories[self._NAcode]
else:
self.NAvalue = kwargs.get(""NAvalue"", ""N/A"")
findNA = self.categories == self.NAvalue
if findNA.any():
self._NAcode = int(akcast(findNA, akint64).argmax())
else:
self.categories = concatenate((self.categories, array([self.NAvalue])))
self._NAcode = self.categories.size - 1
self._akNAcode = array([self._NAcode])
self.size: int_scalars = self.codes.size
self.nlevels = self.categories.size
self.ndim = self.codes.ndim
self.shape = self.codes.shape
self.dtype = str_
self.registered_name: Optional[str] = None
",[],0,[],/categorical.py___init__
66,/home/amandapotts/git/arkouda/arkouda/categorical.py_from_codes,"def from_codes(
cls, codes: pdarray, categories: Strings, permutation=None, segments=None, **kwargs
",[],0,[],/categorical.py_from_codes
67,/home/amandapotts/git/arkouda/arkouda/categorical.py_from_return_msg,"def from_return_msg(cls, rep_msg) -> Categorical:
""""""
Create categorical from return message from server
Notes
------
This is currently only used when reading a Categorical from HDF5 files.
""""""
eles = json.loads(rep_msg)
codes = create_pdarray(eles[""codes""])
cats = Strings.from_return_msg(eles[""categories""])
na_code = create_pdarray(eles[""_akNAcode""])
segments = None
perm = None
if ""segments"" in eles and ""permutation"" in eles:
segments = create_pdarray(eles[""segments""])
perm = create_pdarray(eles[""permutation""])
return cls.from_codes(codes, cats, permutation=perm, segments=segments, _akNAcode=na_code)
",[],0,[],/categorical.py_from_return_msg
68,/home/amandapotts/git/arkouda/arkouda/categorical.py_standardize_categories,"def standardize_categories(cls, arrays, NAvalue=""N/A""):
""""""
Standardize an array of Categoricals so that they share the same categories.
Parameters
----------
arrays : sequence of Categoricals
The Categoricals to standardize
NAvalue : str scalar
The value to use to represent missing/null data
Returns
-------
List of Categoricals
A list of the original Categoricals remapped to the shared categories.
""""""
for arr in arrays:
if not isinstance(arr, cls):
raise TypeError(f""All arguments must be {cls.__name__}"")
new_categories = unique(concatenate([arr.categories for arr in arrays], ordered=False))
findNA = new_categories == NAvalue
if not findNA.any():
new_categories = concatenate((new_categories, array([NAvalue])))
return [arr.set_categories(new_categories, NAvalue=NAvalue) for arr in arrays]
",[],0,[],/categorical.py_standardize_categories
69,/home/amandapotts/git/arkouda/arkouda/categorical.py_set_categories,"def set_categories(self, new_categories, NAvalue=None):
""""""
Set categories to user-defined values.
Parameters
----------
new_categories : Strings
The array of new categories to use. Must be unique.
NAvalue : str scalar
The value to use to represent missing/null data
Returns
-------
Categorical
A new Categorical with the user-defined categories. Old values present
in new categories will appear unchanged. Old values not present will
be assigned the NA value.
""""""
if NAvalue is None:
NAvalue = self.NAvalue
findNA = new_categories == NAvalue
if not findNA.any():
new_categories = concatenate((new_categories, array([NAvalue])))
NAcode = new_categories.size - 1
else:
NAcode = int(akcast(findNA, akint64).argmax())
code_mapping = zeros(self.categories.size, dtype=akint64)
code_mapping.fill(NAcode)
bothcats = concatenate((self.categories, new_categories), ordered=False)
bothcodes = concatenate(
(arange(self.categories.size), arange(new_categories.size)), ordered=False
)
fromold = concatenate(
(ones(self.categories.size, dtype=akbool), zeros(new_categories.size, dtype=akbool)),
ordered=False,
)
g = GroupBy(bothcats)
ct = g.count()[1]
if (ct > 2).any():
raise ValueError(""User-specified categories must be unique"")
present = g.segments[(ct == 2)]
firstinds = g.permutation[present]
firstcodes = bothcodes[firstinds]
firstisold = fromold[firstinds]
secondinds = g.permutation[present + 1]
secondcodes = bothcodes[secondinds]
scatterinds = where(firstisold, firstcodes, secondcodes)
gatherinds = where(firstisold, secondcodes, firstcodes)
code_mapping[scatterinds] = arange(new_categories.size)[gatherinds]
new_codes = code_mapping[self.codes]
return self.__class__.from_codes(new_codes, new_categories, NAvalue=NAvalue)
",[],0,[],/categorical.py_set_categories
70,/home/amandapotts/git/arkouda/arkouda/categorical.py_to_ndarray,"def to_ndarray(self) -> np.ndarray:
""""""
Convert the array to a np.ndarray, transferring array data from
the arkouda server to Python. This conversion discards category
information and produces an ndarray of strings. If the arrays
exceeds a built-in size limit, a RuntimeError is raised.
Returns
-------
np.ndarray
A numpy ndarray of strings corresponding to the values in
this array
Notes
-----
The number of bytes in the array cannot exceed ``ak.client.maxTransferBytes``,
otherwise a ``RuntimeError`` will be raised. This is to protect the user
from overflowing the memory of the system on which the Python client
is running, under the assumption that the server is running on a
distributed system with much more memory than the client. The user
may override this limit by setting ak.client.maxTransferBytes to a larger
value, but proceed with caution.
""""""
if self.categories.size > self.codes.size:
newcat = self.reset_categories()
idx = newcat.categories.to_ndarray()
valcodes = newcat.codes.to_ndarray()
else:
idx = self.categories.to_ndarray()
valcodes = self.codes.to_ndarray()
return idx[valcodes]
","['ndarray', 'ndarray', 'ndarray']",3,[],/categorical.py_to_ndarray
71,/home/amandapotts/git/arkouda/arkouda/categorical.py_to_list,"def to_list(self) -> List:
""""""
Convert the Categorical to a list, transferring data from
the arkouda server to Python. This conversion discards category
information and produces a list of strings. If the arrays
exceeds a built-in size limit, a RuntimeError is raised.
Returns
-------
list
A list of strings corresponding to the values in
this Categorical
Notes
-----
The number of bytes in the Categorical cannot exceed ``ak.client.maxTransferBytes``,
otherwise a ``RuntimeError`` will be raised. This is to protect the user
from overflowing the memory of the system on which the Python client
is running, under the assumption that the server is running on a
distributed system with much more memory than the client. The user
may override this limit by setting ak.client.maxTransferBytes to a larger
value, but proceed with caution.
""""""
return self.to_ndarray().tolist()
",[],0,[],/categorical.py_to_list
72,/home/amandapotts/git/arkouda/arkouda/categorical.py___iter__,"def __iter__(self):
raise NotImplementedError(
""Categorical does not support iteration. To force data transfer from server, use to_ndarray""
)
",[],0,[],/categorical.py___iter__
73,/home/amandapotts/git/arkouda/arkouda/categorical.py___len__,"def __len__(self):
return self.shape[0]
",[],0,[],/categorical.py___len__
74,/home/amandapotts/git/arkouda/arkouda/categorical.py___str__,"def __str__(self):
from arkouda.client import pdarrayIterThresh
if self.size <= pdarrayIterThresh:
vals = [f""'{self[i]}'"" for i in range(self.size)]
else:
vals = [f""'{self[i]}'"" for i in range(3)]
vals.append(""... "")
vals.extend([f""'{self[i]}'"" for i in range(self.size - 3, self.size)])
return ""[{}]"".format("", "".join(vals))
",[],0,[],/categorical.py___str__
75,/home/amandapotts/git/arkouda/arkouda/categorical.py___repr__,"def __repr__(self):
return f""array({self.__str__()})""
",[],0,[],/categorical.py___repr__
76,/home/amandapotts/git/arkouda/arkouda/categorical.py__binop,"def _binop(self, other: Union[Categorical, str_scalars], op: str_scalars) -> pdarray:
""""""
Executes the requested binop on this Categorical instance and returns
the results within a pdarray object.
Parameters
----------
other : Union[Categorical,str_scalars]
the other object is a Categorical object or string scalar
op : str_scalars
name of the binary operation to be performed
Returns
-------
pdarray
encapsulating the results of the requested binop
Raises
-----
ValueError
Raised if (1) the op is not in the self.BinOps set, or (2) if the
sizes of this and the other instance don't match
RuntimeError
Raised if a server-side error is thrown while executing the
binary operation
""""""
if op not in self.BinOps:
raise NotImplementedError(f""Categorical: unsupported operator: {op}"")
if np.isscalar(other) and resolve_scalar_dtype(other) == ""str"":
idxresult = self.categories._binop(other, op)
return idxresult[self.codes]
if self.size != cast(Categorical, other).size:
raise ValueError(
f""Categorical {op}: size mismatch {self.size} {cast(Categorical, other).size}""
)
if isinstance(other, Categorical):
if (self.categories.size == other.categories.size) and (
self.categories == other.categories
).all():
return self.codes._binop(other.codes, op)
else:
tmpself, tmpother = self.standardize_categories((self, other))
return tmpself.codes._binop(tmpother.codes, op)
else:
raise NotImplementedError(
""Operations between Categorical and non-Categorical not yet implemented.""
""Consider converting operands to Categorical.""
)
",['isscalar'],1,['isscalar(other) and resolve_scalar_dtype(other)'],/categorical.py__binop
77,/home/amandapotts/git/arkouda/arkouda/categorical.py__r_binop,"def _r_binop(self, other: Union[Categorical, str_scalars], op: str_scalars) -> pdarray:
""""""
Executes the requested reverse binop on this Categorical instance and
returns the results within a pdarray object.
Parameters
----------
other : Union[Categorical,str_scalars]
the other object is a Categorical object or string scalar
op : str_scalars
name of the binary operation to be performed
Returns
-------
pdarray
encapsulating the results of the requested binop
Raises
-----
ValueError
Raised if (1) the op is not in the self.BinOps set, or (2) if the
sizes of this and the other instance don't match
RuntimeError
Raised if a server-side error is thrown while executing the
binary operation
""""""
return self._binop(other, op)
",[],0,[],/categorical.py__r_binop
78,/home/amandapotts/git/arkouda/arkouda/categorical.py___eq__,"def __eq__(self, other):
return self._binop(other, ""=="")
",[],0,[],/categorical.py___eq__
79,/home/amandapotts/git/arkouda/arkouda/categorical.py___ne__,"def __ne__(self, other):
return self._binop(other, ""!="")
",[],0,[],/categorical.py___ne__
80,/home/amandapotts/git/arkouda/arkouda/categorical.py___getitem__,"def __getitem__(self, key) -> Categorical:
if np.isscalar(key) and (resolve_scalar_dtype(key) in [""int64"", ""uint64""]):
return self.categories[self.codes[key]]
else:
return Categorical.from_codes(self.codes[key], self.categories)
",['isscalar'],1,"['isscalar(key) and (resolve_scalar_dtype(key) in [""int64"", ""uint64""])']",/categorical.py___getitem__
81,/home/amandapotts/git/arkouda/arkouda/categorical.py_isna,"def isna(self):
""""""
Find where values are missing or null (as defined by self.NAvalue)
""""""
return self.codes == self._NAcode
",[],0,[],/categorical.py_isna
82,/home/amandapotts/git/arkouda/arkouda/categorical.py_reset_categories,"def reset_categories(self) -> Categorical:
""""""
Recompute the category labels, discarding any unused labels. This
method is often useful after slicing or indexing a Categorical array,
when the resulting array only contains a subset of the original
categories. In this case, eliminating unused categories can speed up
other operations.
Returns
-------
Categorical
A Categorical object generated from the current instance
""""""
g = GroupBy(self.codes)
idx = self.categories[g.unique_keys]
newvals = g.broadcast(arange(idx.size), permute=True)
return Categorical.from_codes(
newvals, idx, permutation=g.permutation, segments=g.segments, NAvalue=self.NAvalue
)
",[],0,[],/categorical.py_reset_categories
83,/home/amandapotts/git/arkouda/arkouda/categorical.py_contains,"def contains(self, substr: Union[bytes, str_scalars], regex: bool = False) -> pdarray:
""""""
Check whether each element contains the given substring.
Parameters
----------
substr : Union[bytes, str_scalars]
The substring to search for
regex: bool
Indicates whether substr is a regular expression
Note: only handles regular expressions supported by re2
(does not support lookaheads/lookbehinds)
Returns
-------
pdarray, bool
True for elements that contain substr, False otherwise
Raises
------
TypeError
Raised if the substr parameter is not bytes or str_scalars
ValueError
Rasied if substr is not a valid regex
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
Categorical.startswith, Categorical.endswith
Notes
-----
This method can be significantly faster than the corresponding method
on Strings objects, because it searches the unique category labels
instead of the full array.
""""""
categories_contains = self.categories.contains(substr, regex)
return categories_contains[self.codes]
",[],0,[],/categorical.py_contains
84,/home/amandapotts/git/arkouda/arkouda/categorical.py_startswith,"def startswith(self, substr: Union[bytes, str_scalars], regex: bool = False) -> pdarray:
""""""
Check whether each element starts with the given substring.
Parameters
----------
substr : Union[bytes, str_scalars]
The substring to search for
regex: bool
Indicates whether substr is a regular expression
Note: only handles regular expressions supported by re2
(does not support lookaheads/lookbehinds)
Returns
-------
pdarray, bool
True for elements that start with substr, False otherwise
Raises
------
TypeError
Raised if the substr parameter is not bytes or str_scalars
ValueError
Rasied if substr is not a valid regex
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
Categorical.contains, Categorical.endswith
Notes
-----
This method can be significantly faster than the corresponding
method on Strings objects, because it searches the unique category
labels instead of the full array.
""""""
categories_ends_with = self.categories.startswith(substr, regex)
return categories_ends_with[self.codes]
",[],0,[],/categorical.py_startswith
85,/home/amandapotts/git/arkouda/arkouda/categorical.py_endswith,"def endswith(self, substr: Union[bytes, str_scalars], regex: bool = False) -> pdarray:
""""""
Check whether each element ends with the given substring.
Parameters
----------
substr : Union[bytes, str_scalars]
The substring to search for
regex: bool
Indicates whether substr is a regular expression
Note: only handles regular expressions supported by re2
(does not support lookaheads/lookbehinds)
Returns
-------
pdarray, bool
True for elements that end with substr, False otherwise
Raises
------
TypeError
Raised if the substr parameter is not bytes or str_scalars
ValueError
Rasied if substr is not a valid regex
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
Categorical.startswith, Categorical.contains
Notes
-----
This method can be significantly faster than the corresponding method
on Strings objects, because it searches the unique category labels
instead of the full array.
""""""
categories_ends_with = self.categories.endswith(substr, regex)
return categories_ends_with[self.codes]
",[],0,[],/categorical.py_endswith
86,/home/amandapotts/git/arkouda/arkouda/categorical.py_in1d,"def in1d(self, test: Union[Strings, Categorical]) -> pdarray:
""""""
Test whether each element of the Categorical object is
also present in the test Strings or Categorical object.
Returns a boolean array the same length as `self` that is True
where an element of `self` is in `test` and False otherwise.
Parameters
----------
test : Union[Strings,Categorical]
The values against which to test each value of 'self`.
Returns
-------
pdarray, bool
The values `self[in1d]` are in the `test` Strings or Categorical object.
Raises
------
TypeError
Raised if test is not a Strings or Categorical object
See Also
--------
unique, intersect1d, union1d
Notes
-----
`in1d` can be considered as an element-wise function version of the
python keyword `in`, for 1-D sequences. ``in1d(a, b)`` is logically
equivalent to ``ak.array([item in b for item in a])``, but is much
faster and scales to arbitrarily large ``a``.
Examples
--------
>>> strings = ak.array([f'String {i}' for i in range(0,5)])
>>> cat = ak.Categorical(strings)
>>> ak.in1d(cat,strings)
array([True, True, True, True, True])
>>> strings = ak.array([f'String {i}' for i in range(5,9)])
>>> catTwo = ak.Categorical(strings)
>>> ak.in1d(cat,catTwo)
array([False, False, False, False, False])
""""""
if isinstance(test, Categorical):
categoriesisin = in1d(self.categories, test._categories_used)
else:
categoriesisin = in1d(self.categories, test)
return categoriesisin[self.codes]
",[],0,[],/categorical.py_in1d
87,/home/amandapotts/git/arkouda/arkouda/categorical.py_unique,"def unique(self) -> Categorical:
return Categorical.from_codes(
arange(self._categories_used.size), self._categories_used, NAvalue=self.NAvalue
)
",[],0,[],/categorical.py_unique
88,/home/amandapotts/git/arkouda/arkouda/categorical.py_hash,"def hash(self) -> Tuple[pdarray, pdarray]:
""""""
Compute a 128-bit hash of each element of the Categorical.
Returns
-------
Tuple[pdarray,pdarray]
A tuple of two int64 pdarrays. The ith hash value is the concatenation
of the ith values from each array.
Notes
-----
The implementation uses SipHash128, a fast and balanced hash function (used
by Python for dictionaries and sets). For realistic numbers of strings (up
to about 10**15), the probability of a collision between two 128-bit hash
values is negligible.
""""""
rep_msg = generic_msg(
cmd=""categoricalHash"",
args={""objType"": self.objType, ""categories"": self.categories, ""codes"": self.codes},
)
hashes = json.loads(rep_msg)
return create_pdarray(hashes[""upperHash""]), create_pdarray(hashes[""lowerHash""])
",[],0,[],/categorical.py_hash
89,/home/amandapotts/git/arkouda/arkouda/categorical.py_group,"def group(self) -> pdarray:
""""""
Return the permutation that groups the array, placing equivalent
categories together. All instances of the same category are guaranteed
to lie in one contiguous block of the permuted array, but the blocks
are not necessarily ordered.
Returns
-------
pdarray
The permutation that groups the array by value
See Also
--------
GroupBy, unique
Notes
-----
This method is faster than the corresponding Strings method. If the
Categorical was created from a Strings object, then this function
simply returns the cached permutation. Even if the Categorical was
created using from_codes(), this function will be faster than
Strings.group() because it sorts dense integer values, rather than
128-bit hash values.
""""""
if self.permutation is None:
return argsort(self.codes)
else:
return self.permutation
",[],0,[],/categorical.py_group
90,/home/amandapotts/git/arkouda/arkouda/categorical.py__get_grouping_keys,"def _get_grouping_keys(self):
""""""
Private method for generating grouping keys used by GroupBy.
API: this method must be defined by all groupable arrays, and it
must return a list of arrays that can be (co)argsorted.
""""""
return [self.codes]
",[],0,[],/categorical.py__get_grouping_keys
91,/home/amandapotts/git/arkouda/arkouda/categorical.py_argsort,"def argsort(self):
idxperm = argsort(self.categories)
inverse = zeros_like(idxperm)
inverse[idxperm] = arange(idxperm.size)
newvals = inverse[self.codes]
return argsort(newvals)
",[],0,[],/categorical.py_argsort
92,/home/amandapotts/git/arkouda/arkouda/categorical.py_sort,"def sort(self):
idxperm = argsort(self.categories)
inverse = zeros_like(idxperm)
inverse[idxperm] = arange(idxperm.size)
newvals = inverse[self.codes]
return Categorical.from_codes(newvals, self.categories[idxperm])
",[],0,[],/categorical.py_sort
93,/home/amandapotts/git/arkouda/arkouda/categorical.py_concatenate,"def concatenate(self, others: Sequence[Categorical], ordered: bool = True) -> Categorical:
""""""
Merge this Categorical with other Categorical objects in the array,
concatenating the arrays and synchronizing the categories.
Parameters
----------
others : Sequence[Categorical]
The Categorical arrays to concatenate and merge with this one
ordered : bool
If True (default), the arrays will be appended in the
order given. If False, array data may be interleaved
in blocks, which can greatly improve performance but
results in non-deterministic ordering of elements.
Returns
-------
Categorical
The merged Categorical object
Raises
------
TypeError
Raised if any others array objects are not Categorical objects
Notes
-----
This operation can be expensive -- slower than concatenating Strings.
""""""
if isinstance(others, Categorical):
others = [others]
elif len(others) < 1:
return self
samecategories = True
for c in others:
if not isinstance(c, Categorical):
raise TypeError(""Categorical: can only merge/concatenate with other Categoricals"")
if (self.categories.size != c.categories.size) or not (
self.categories == c.categories
).all():
samecategories = False
if samecategories:
newvals = cast(
pdarray, concatenate([self.codes] + [o.codes for o in others], ordered=ordered)
)
return Categorical.from_codes(newvals, self.categories)
else:
new_arrays = self.standardize_categories([self] + list(others), NAvalue=self.NAvalue)
new_categories = new_arrays[0].categories
new_codes = cast(pdarray, concatenate([arr.codes for arr in new_arrays], ordered=ordered))
return Categorical.from_codes(new_codes, new_categories, NAvalue=self.NAvalue)
",[],0,[],/categorical.py_concatenate
94,/home/amandapotts/git/arkouda/arkouda/categorical.py_to_hdf,"def to_hdf(
self,
prefix_path,
dataset=""categorical_array"",
mode=""truncate"",
file_type=""distribute"",
",[],0,[],/categorical.py_to_hdf
95,/home/amandapotts/git/arkouda/arkouda/categorical.py_update_hdf,"def update_hdf(self, prefix_path, dataset=""categorical_array"", repack=True):
""""""
Overwrite the dataset with the name provided with this Categorical object. If
the dataset does not exist it is added.
Parameters
-----------
prefix_path : str
Directory and filename prefix that all output files share
dataset : str
Name of the dataset to create in files
repack: bool
Default: True
HDF5 does not release memory on delete. When True, the inaccessible
data (that was overwritten) is removed. When False, the data remains, but is
inaccessible. Setting to false will yield better performance, but will cause
file sizes to expand.
Returns
--------
None
Raises
-------
RuntimeError
Raised if a server-side error is thrown saving the Categorical
Notes
------
- If file does not contain File_Format attribute to indicate how it was saved,
the file name is checked for _LOCALE#### to determine if it is distributed.
- If the dataset provided does not exist, it will be added
- Because HDF5 deletes do not release memory, the repack option allows for
automatic creation of a file without the inaccessible data.
""""""
from arkouda.io import (
_file_type_to_int,
_get_hdf_filetype,
_mode_str_to_int,
_repack_hdf,
)
file_type = _get_hdf_filetype(prefix_path + ""*"")
args = {
""codes"": self.codes,
""categories"": self.categories,
""dset"": dataset,
""write_mode"": _mode_str_to_int(""append""),
""filename"": prefix_path,
""objType"": ""categorical"",
""overwrite"": True,
""file_format"": _file_type_to_int(file_type),
""NA_codes"": self._akNAcode,
}
if self.permutation is not None and self.segments is not None:
args[""permutation""] = self.permutation
args[""segments""] = self.segments
generic_msg(
cmd=""tohdf"",
args=args,
)
if repack:
_repack_hdf(prefix_path)
",[],0,[],/categorical.py_update_hdf
96,/home/amandapotts/git/arkouda/arkouda/categorical.py_to_parquet,"def to_parquet(
self,
prefix_path: str,
dataset: str = ""categorical_array"",
mode: str = ""truncate"",
compression: Optional[str] = None,
",[],0,[],/categorical.py_to_parquet
97,/home/amandapotts/git/arkouda/arkouda/categorical.py_save,"def save(
self,
prefix_path: str,
dataset: str = ""categorical_array"",
file_format: str = ""HDF5"",
mode: str = ""truncate"",
file_type: str = ""distribute"",
compression: Optional[str] = None,
",[],0,[],/categorical.py_save
98,/home/amandapotts/git/arkouda/arkouda/categorical.py_register,"def register(self, user_defined_name: str) -> Categorical:
""""""
Register this Categorical object and underlying components with the Arkouda server
Parameters
----------
user_defined_name : str
user defined name the Categorical is to be registered under,
this will be the root name for underlying components
Returns
-------
Categorical
The same Categorical which is now registered with the arkouda server and has an updated name.
This is an in-place modification, the original is returned to support
a fluid programming style.
Please note you cannot register two different Categoricals with the same name.
Raises
------
TypeError
Raised if user_defined_name is not a str
RegistrationError
If the server was unable to register the Categorical with the user_defined_name
See also
--------
unregister, attach, unregister_categorical_by_name, is_registered
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
if self.registered_name is not None and self.is_registered():
raise RegistrationError(f""This object is already registered as {self.registered_name}"")
generic_msg(
cmd=""register"",
args={
""name"": user_defined_name,
""objType"": self.objType,
""codes"": self.codes,
""categories"": self.categories,
""_akNAcode"": self._akNAcode,
""segments"": self.segments if self.segments is not None else """",
""permutation"": self.permutation if self.permutation is not None else """",
},
)
self.registered_name = user_defined_name
return self
",[],0,[],/categorical.py_register
99,/home/amandapotts/git/arkouda/arkouda/categorical.py_unregister,"def unregister(self) -> None:
""""""
Unregister this Categorical object in the arkouda server which was previously
registered using register() and/or attached to using attach()
Raises
------
RegistrationError
If the object is already unregistered or if there is a server error
when attempting to unregister
See also
--------
register, attach, unregister_categorical_by_name, is_registered
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.util import unregister
if not self.registered_name:
raise RegistrationError(""This object is not registered"")
unregister(self.registered_name)
self.registered_name = None
",[],0,[],/categorical.py_unregister
100,/home/amandapotts/git/arkouda/arkouda/categorical.py_is_registered,"def is_registered(self) -> np.bool_:
""""""
Return True iff the object is contained in the registry or is a component of a
registered object.
Returns
-------
numpy.bool
Indicates if the object is contained in the registry
Raises
------
RegistrationError
Raised if there's a server-side error or a mis-match of registered components
See Also
--------
register, attach, unregister, unregister_categorical_by_name
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.util import is_registered
if self.registered_name is None:
result = True
result &= is_registered(self.codes.name, as_component=True)
result &= is_registered(self.categories.name, as_component=True)
result &= is_registered(self._akNAcode.name, as_component=True)
if self.permutation is not None and self.segments is not None:
result &= is_registered(self.permutation.name, as_component=True)
result &= is_registered(self.segments.name, as_component=True)
return np.bool_(result)
else:
return np.bool_(is_registered(self.registered_name))
","['bool_', 'bool_', 'bool_']",3,"['bool_(result)', 'bool_(is_registered(self.registered_name))']",/categorical.py_is_registered
101,/home/amandapotts/git/arkouda/arkouda/categorical.py__get_components_dict,"def _get_components_dict(self) -> Dict:
""""""
Internal function that returns a dictionary with all required or non-None components of self
Required Categorical components (Codes and Categories) are always included in
returned components_dict
Optional Categorical components (Permutation and Segments) are only included if
they've been set (are not None)
Returns
-------
Dict
Dictionary of all required or non-None components of self
Keys: component names (Codes, Categories, Permutation, Segments)
Values: components of self
""""""
return {
piece_name: getattr(self, piece_name)
for piece_name in Categorical.RegisterablePieces
if piece_name in Categorical.RequiredPieces or getattr(self, piece_name) is not None
}
",[],0,[],/categorical.py__get_components_dict
102,/home/amandapotts/git/arkouda/arkouda/categorical.py__list_component_names,"def _list_component_names(self) -> List[str]:
""""""
Internal function that returns a list of all component names
Parameters
----------
None
Returns
-------
List[str]
List of all component names
""""""
return list(
itertools.chain.from_iterable(
[p._list_component_names() for p in Categorical._get_components_dict(self).values()]
)
)
",[],0,[],/categorical.py__list_component_names
103,/home/amandapotts/git/arkouda/arkouda/categorical.py_info,"def info(self) -> str:
""""""
Returns a JSON formatted string containing information about all components of self
Parameters
----------
None
Returns
-------
str
JSON string containing information about all components of self
""""""
return information(self._list_component_names())
",[],0,[],/categorical.py_info
104,/home/amandapotts/git/arkouda/arkouda/categorical.py_pretty_print_info,"def pretty_print_info(self) -> None:
""""""
Prints information about all components of self in a human readable format
Parameters
----------
None
Returns
-------
None
""""""
[p.pretty_print_info() for p in Categorical._get_components_dict(self).values()]
",[],0,[],/categorical.py_pretty_print_info
105,/home/amandapotts/git/arkouda/arkouda/categorical.py_attach,"def attach(user_defined_name: str) -> Categorical:
""""""
DEPRECATED
Function to return a Categorical object attached to the registered name in the
arkouda server which was registered using register()
Parameters
----------
user_defined_name : str
user defined name which Categorical object was registered under
Returns
-------
Categorical
The Categorical object created by re-attaching to the corresponding server components
Raises
------
TypeError
if user_defined_name is not a string
See Also
--------
register, is_registered, unregister, unregister_categorical_by_name
""""""
import warnings
from arkouda.util import attach
warnings.warn(
""ak.Categorical.attach() is deprecated. Please use ak.attach() instead."",
DeprecationWarning,
)
return attach(user_defined_name)
",[],0,[],/categorical.py_attach
106,/home/amandapotts/git/arkouda/arkouda/categorical.py_unregister_categorical_by_name,"def unregister_categorical_by_name(user_defined_name: str) -> None:
""""""
Function to unregister Categorical object by name which was registered
with the arkouda server via register()
Parameters
----------
user_defined_name : str
Name under which the Categorical object was registered
Raises
-------
TypeError
if user_defined_name is not a string
RegistrationError
if there is an issue attempting to unregister any underlying components
See Also
--------
register, unregister, attach, is_registered
""""""
import warnings
from arkouda.util import unregister
warnings.warn(
""ak.Categorical.unregister_categorical_by_name() is deprecated. ""
""Please use ak.unregister() instead."",
DeprecationWarning,
)
return unregister(user_defined_name)
",[],0,[],/categorical.py_unregister_categorical_by_name
107,/home/amandapotts/git/arkouda/arkouda/categorical.py_parse_hdf_categoricals,"def parse_hdf_categoricals(
d: Mapping[str, Union[pdarray, Strings]]
",[],0,[],/categorical.py_parse_hdf_categoricals
108,/home/amandapotts/git/arkouda/arkouda/categorical.py_transfer,"def transfer(self, hostname: str, port: int_scalars):
""""""
Sends a Categorical object to a different Arkouda server
Parameters
----------
hostname : str
The hostname where the Arkouda server intended to
receive the Categorical is running.
port : int_scalars
The port to send the array over. This needs to be an
open port (i.e., not one that the Arkouda server is
running on). This will open up `numLocales` ports,
each of which in succession, so will use ports of the
range {port..(port+numLocales)} (e.g., running an
Arkouda server of 4 nodes, port 1234 is passed as
`port`, Arkouda will use ports 1234, 1235, 1236,
and 1237 to send the array data).
This port much match the port passed to the call to
`ak.receive_array()`.
Returns
-------
A message indicating a complete transfer
Raises
------
ValueError
Raised if the op is not within the pdarray.BinOps set
TypeError
Raised if other is not a pdarray or the pdarray.dtype is not
a supported dtype
""""""
args = {
""codes"": self.codes,
""categories"": self.categories,
""objType"": self.objType,
""NA_codes"": self._akNAcode,
""hostname"": hostname,
""port"": port,
}
return generic_msg(
cmd=""sendArray"",
args=args,
)
",[],0,[],/categorical.py_transfer
109,/home/amandapotts/git/arkouda/arkouda/strings.py_from_return_msg,"def from_return_msg(rep_msg: str) -> Strings:
""""""
Factory method for creating a Strings object from an Arkouda server
response message
Parameters
----------
rep_msg : str
Server response message currently of form
`created name type size ndim shape itemsize+created bytes.size 1234`
Returns
-------
Strings
object representing a segmented strings array on the server
Raises
------
RuntimeError
Raised if there's an error converting a server-returned str-descriptor
Notes
-----
We really don't have an itemsize because these are variable length strings.
In the future we could probably use this position to store the total bytes.
""""""
left, right = cast(str, rep_msg).split(""+"")
bytes_size: int_scalars = int(right.split()[-1])
return Strings(create_pdarray(left), bytes_size)
",[],0,[],/strings.py_from_return_msg
110,/home/amandapotts/git/arkouda/arkouda/strings.py_from_parts,"def from_parts(offset_attrib: Union[pdarray, str], bytes_attrib: Union[pdarray, str]) -> Strings:
""""""
Factory method for creating a Strings object from an Arkouda server
response where the arrays are separate components.
Parameters
----------
offset_attrib : Union[pdarray, str]
the array containing the offsets
bytes_attrib : Union[pdarray, str]
the array containing the string values
Returns
-------
Strings
object representing a segmented strings array on the server
Raises
------
RuntimeError
Raised if there's an error converting a server-returned str-descriptor
Notes
-----
This factory method is used when we construct the parts of a Strings
object on the client side and transfer the offsets & bytes separately
to the server.  This results in two entries in the symbol table and we
need to instruct the server to assemble the into a composite entity.
""""""
if not isinstance(offset_attrib, pdarray):
try:
offset_attrib = create_pdarray(offset_attrib)
except Exception as e:
raise RuntimeError(e)
if not isinstance(bytes_attrib, pdarray):
try:
bytes_attrib = create_pdarray(bytes_attrib)
except Exception as e:
raise RuntimeError(e)
response = cast(
str, generic_msg(cmd=CMD_ASSEMBLE, args={""offsets"": offset_attrib, ""values"": bytes_attrib})
)
return Strings.from_return_msg(response)
",[],0,[],/strings.py_from_parts
111,/home/amandapotts/git/arkouda/arkouda/strings.py___init__,"def __init__(self, strings_pdarray: pdarray, bytes_size: int_scalars) -> None:
""""""
Initializes the Strings instance by setting all instance
attributes, some of which are derived from the array parameters.
Parameters
----------
strings_pdarray : pdarray
the array containing the meta-info on a server side strings object
bytes_size : int_scalars
length of the bytes array contained on the server aka total bytes
Returns
-------
None
Raises
------
RuntimeError
Raised if there's an error converting a server-returned str-descriptor
or pdarray to either the offset_attrib or bytes_attrib
ValueError
Raised if there's an error in generating instance attributes
from either the offset_attrib or bytes_attrib parameter
""""""
self.entry: pdarray = strings_pdarray
self.registered_name: Optional[str] = None
try:
self.size = self.entry.size
self.nbytes = bytes_size  # This is a deficiency of server GenSymEntry right now
self.ndim = self.entry.ndim
self.shape = self.entry.shape
self.name: Optional[str] = self.entry.name
except Exception as e:
raise ValueError(e)
self._bytes: Optional[pdarray] = None
self._offsets: Optional[pdarray] = None
self.dtype = npstr
self._regex_dict: Dict = dict()
self.logger = getArkoudaLogger(name=__class__.__name__)  # type: ignore
",[],0,[],/strings.py___init__
112,/home/amandapotts/git/arkouda/arkouda/strings.py___iter__,"def __iter__(self):
raise NotImplementedError(
""Strings does not support iteration. To force data transfer from server, use to_ndarray""
)
",[],0,[],/strings.py___iter__
113,/home/amandapotts/git/arkouda/arkouda/strings.py___len__,"def __len__(self) -> int:
return self.shape[0]
",[],0,[],/strings.py___len__
114,/home/amandapotts/git/arkouda/arkouda/strings.py___str__,"def __str__(self) -> str:
from arkouda.client import pdarrayIterThresh
if self.size <= pdarrayIterThresh:
vals = [f""'{self[i]}'"" for i in range(self.size)]
else:
vals = [f""'{self[i]}'"" for i in range(3)]
vals.append(""... "")
vals.extend([f""'{self[i]}'"" for i in range(self.size - 3, self.size)])
return ""[{}]"".format("", "".join(vals))
",[],0,[],/strings.py___str__
115,/home/amandapotts/git/arkouda/arkouda/strings.py___repr__,"def __repr__(self) -> str:
return f""array({self.__str__()})""
",[],0,[],/strings.py___repr__
116,/home/amandapotts/git/arkouda/arkouda/strings.py__binop,"def _binop(self, other: Union[Strings, str_scalars], op: str) -> pdarray:
""""""
Executes the requested binop on this Strings instance and the
parameter Strings object and returns the results within
a pdarray object.
Parameters
----------
other : Strings, str_scalars
the other object is a Strings object
op : str
name of the binary operation to be performed
Returns
-------
pdarray
encapsulating the results of the requested binop
Raises
-----
ValueError
Raised if (1) the op is not in the self.BinOps set, or (2) if the
sizes of this and the other instance don't match, or (3) the other
object is not a Strings object
RuntimeError
Raised if a server-side error is thrown while executing the
binary operation
""""""
if op not in self.BinOps:
raise ValueError(f""Strings: unsupported operator: {op}"")
if isinstance(other, Strings):
if self.size != other.size:
raise ValueError(f""Strings: size mismatch {self.size} {other.size}"")
cmd = ""segmentedBinopvv""
args = {
""op"": op,
""objType"": self.objType,
""obj"": self.entry,
""otherType"": other.objType,
""other"": other.entry,
""left"": False,  # placeholder for stick
""delim"": """",  # placeholder for stick
}
elif resolve_scalar_dtype(other) == ""str"":
cmd = ""segmentedBinopvs""
args = {
""op"": op,
""objType"": self.objType,
""obj"": self.entry,
""otherType"": ""str"",
""other"": other,
}
else:
raise ValueError(
f""Strings: {op} not supported between Strings and {other.__class__.__name__}""
)
return create_pdarray(generic_msg(cmd=cmd, args=args))
",[],0,[],/strings.py__binop
117,/home/amandapotts/git/arkouda/arkouda/strings.py___eq__,"def __eq__(self, other) -> bool:
return self._binop(other, ""=="")
",[],0,[],/strings.py___eq__
118,/home/amandapotts/git/arkouda/arkouda/strings.py___ne__,"def __ne__(self, other) -> bool:
return self._binop(cast(Strings, other), ""!="")
",[],0,[],/strings.py___ne__
119,/home/amandapotts/git/arkouda/arkouda/strings.py___getitem__,"def __getitem__(self, key):
if np.isscalar(key) and (resolve_scalar_dtype(key) in [""int64"", ""uint64""]):
orig_key = key
if key < 0:
key += self.size
if key >= 0 and key < self.size:
repMsg = generic_msg(
cmd=""segmentedIndex"",
args={
""subcmd"": ""intIndex"",
""objType"": self.objType,
""dtype"": self.entry.dtype,
""obj"": self.entry,
""key"": key,
},
)
_, value = repMsg.split(maxsplit=1)
return parse_single_value(value)
else:
raise IndexError(f""[int] {orig_key} is out of bounds with size {self.size}"")
elif isinstance(key, slice):
(start, stop, stride) = key.indices(self.size)
self.logger.debug(f""start: {start}
repMsg = generic_msg(
cmd=""segmentedIndex"",
args={
""subcmd"": ""sliceIndex"",
""objType"": self.objType,
""obj"": self.entry,
""dtype"": self.entry.dtype,
""key"": [start, stop, stride],
},
)
return Strings.from_return_msg(repMsg)
elif isinstance(key, pdarray):
kind, _ = translate_np_dtype(key.dtype)
if kind not in (""bool"", ""int"", ""uint""):
raise TypeError(f""unsupported pdarray index type {key.dtype}"")
if kind == ""bool"" and self.size != key.size:
raise ValueError(f""size mismatch {self.size} {key.size}"")
repMsg = generic_msg(
cmd=""segmentedIndex"",
args={
""subcmd"": ""pdarrayIndex"",
""objType"": self.objType,
""dtype"": self.entry.dtype,
""obj"": self.entry,
""key"": key,
},
)
return Strings.from_return_msg(repMsg)
else:
raise TypeError(f""unsupported pdarray index type {key.__class__.__name__}"")
",['isscalar'],1,"['isscalar(key) and (resolve_scalar_dtype(key) in [""int64"", ""uint64""])']",/strings.py___getitem__
120,/home/amandapotts/git/arkouda/arkouda/strings.py_get_lengths,"def get_lengths(self) -> pdarray:
""""""
Return the length of each string in the array.
Returns
-------
pdarray, int
The length of each string
Raises
------
RuntimeError
Raised if there is a server-side error thrown
""""""
return create_pdarray(
generic_msg(cmd=""segmentLengths"", args={""objType"": self.objType, ""obj"": self.entry})
)
",[],0,[],/strings.py_get_lengths
121,/home/amandapotts/git/arkouda/arkouda/strings.py_get_bytes,"def get_bytes(self):
""""""
Getter for the bytes component (uint8 pdarray) of this Strings.
Returns
-------
pdarray, uint8
Pdarray of bytes of the string accessed
Example
-------
>>> x = ak.array(['one', 'two', 'three'])
>>> x.get_bytes()
[111 110 101 0 116 119 111 0 116 104 114 101 101 0]
""""""
if self._bytes is None or self._bytes.name not in list_symbol_table():
self._bytes = create_pdarray(
generic_msg(
cmd=""getSegStringProperty"", args={""property"": ""get_bytes"", ""obj"": self.entry}
)
)
return self._bytes
",[],0,[],/strings.py_get_bytes
122,/home/amandapotts/git/arkouda/arkouda/strings.py_get_offsets,"def get_offsets(self):
""""""
Getter for the offsets component (int64 pdarray) of this Strings.
Returns
-------
pdarray, int64
Pdarray of offsets of the string accessed
Example
-------
>>> x = ak.array(['one', 'two', 'three'])
>>> x.get_offsets()
[0 4 8]
""""""
if self._offsets is None or self._offsets.name not in list_symbol_table():
self._offsets = create_pdarray(
generic_msg(
cmd=""getSegStringProperty"", args={""property"": ""get_offsets"", ""obj"": self.entry}
)
)
return self._offsets
",[],0,[],/strings.py_get_offsets
123,/home/amandapotts/git/arkouda/arkouda/strings.py_encode,"def encode(self, toEncoding: str, fromEncoding: str = ""UTF-8""):
""""""
Return a new strings object in `toEncoding`, expecting that the
current Strings is encoded in `fromEncoding`
Parameters
----------
toEncoding: str
The encoding that the strings will be converted to
fromEncoding: str
The current encoding of the strings object, default to
UTF-8
Returns
-------
Strings
A new Strings object in `toEncoding`
Raises
------
RuntimeError
Raised if there is a server-side error thrown
""""""
if (toEncoding.upper() == ""IDNA"" and fromEncoding.upper() != ""UTF-8"") or (
toEncoding.upper() != ""UTF-8"" and fromEncoding.upper() == ""IDNA""
):
rep_msg = generic_msg(
cmd=""encode"",
args={
""toEncoding"": ""UTF-8"",
""fromEncoding"": fromEncoding,
""obj"": self.entry,
},
)
intermediate = Strings.from_return_msg(cast(str, rep_msg))
rep_msg = generic_msg(
cmd=""encode"",
args={
""toEncoding"": toEncoding,
""fromEncoding"": ""UTF-8"",
""obj"": intermediate,
},
)
return Strings.from_return_msg(cast(str, rep_msg))
rep_msg = generic_msg(
cmd=""encode"",
args={
""toEncoding"": toEncoding,
""fromEncoding"": fromEncoding,
""obj"": self.entry,
},
)
return Strings.from_return_msg(cast(str, rep_msg))
",[],0,[],/strings.py_encode
124,/home/amandapotts/git/arkouda/arkouda/strings.py_decode,"def decode(self, fromEncoding, toEncoding=""UTF-8""):
""""""
Return a new strings object in `fromEncoding`, expecting that the
current Strings is encoded in `toEncoding`
Parameters
----------
fromEncoding: str
The current encoding of the strings object
toEncoding: str
The encoding that the strings will be converted to,
default to UTF-8
Returns
-------
Strings
A new Strings object in `toEncoding`
Raises
------
RuntimeError
Raised if there is a server-side error thrown
""""""
return self.encode(toEncoding, fromEncoding)
",[],0,[],/strings.py_decode
125,/home/amandapotts/git/arkouda/arkouda/strings.py_lower,"def lower(self) -> Strings:
""""""
Returns a new Strings with all uppercase characters from the original replaced with
their lowercase equivalent
Returns
-------
Strings
Strings with all uppercase characters from the original replaced with
their lowercase equivalent
Raises
------
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
Strings.upper
Examples
--------
>>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
>>> strings
array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
>>> strings.lower()
array(['strings 0', 'strings 1', 'strings 2', 'strings 3', 'strings 4'])
""""""
rep_msg = generic_msg(
cmd=""caseChange"", args={""subcmd"": ""toLower"", ""objType"": self.objType, ""obj"": self.entry}
)
return Strings.from_return_msg(cast(str, rep_msg))
",[],0,[],/strings.py_lower
126,/home/amandapotts/git/arkouda/arkouda/strings.py_upper,"def upper(self) -> Strings:
""""""
Returns a new Strings with all lowercase characters from the original replaced with
their uppercase equivalent
Returns
-------
Strings
Strings with all lowercase characters from the original replaced with
their uppercase equivalent
Raises
------
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
Strings.lower
Examples
--------
>>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
>>> strings
array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
>>> strings.upper()
array(['STRINGS 0', 'STRINGS 1', 'STRINGS 2', 'STRINGS 3', 'STRINGS 4'])
""""""
rep_msg = generic_msg(
cmd=""caseChange"", args={""subcmd"": ""toUpper"", ""objType"": self.objType, ""obj"": self.entry}
)
return Strings.from_return_msg(cast(str, rep_msg))
",[],0,[],/strings.py_upper
127,/home/amandapotts/git/arkouda/arkouda/strings.py_title,"def title(self) -> Strings:
""""""
Returns a new Strings from the original replaced with their titlecase equivalent.
Returns
-------
Strings
Strings from the original replaced with their titlecase equivalent.
Raises
------
RuntimeError
Raised if there is a server-side error thrown.
See Also
--------
Strings.lower
String.upper
Examples
--------
>>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
>>> strings
array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
>>> strings.title()
array(['Strings 0', 'Strings 1', 'Strings 2', 'Strings 3', 'Strings 4'])
""""""
rep_msg = generic_msg(
cmd=""caseChange"", args={""subcmd"": ""toTitle"", ""objType"": self.objType, ""obj"": self.entry}
)
return Strings.from_return_msg(cast(str, rep_msg))
",[],0,[],/strings.py_title
128,/home/amandapotts/git/arkouda/arkouda/strings.py_capitalize,"def capitalize(self) -> Strings:
""""""
Returns a new Strings from the original replaced with the first letter capitilzed
and the remaining letters lowercase.
Returns
-------
Strings
Strings from the original replaced with the capitalized equivalent.
Raises
------
RuntimeError
Raised if there is a server-side error thrown.
See Also
--------
Strings.lower
String.upper
String.title
Examples
--------
>>> strings = ak.array([f'StrINgS aRe Here {i}' for i in range(5)])
>>> strings
array(['StrINgS aRe Here 0', 'StrINgS aRe Here 1', 'StrINgS aRe Here 2', 'StrINgS aRe Here 3',
... 'StrINgS aRe Here 4'])
>>> strings.title()
array(['Strings are here 0', 'Strings are here 1', 'Strings are here 2', 'Strings are here 3',
... 'Strings are here 4'])
""""""
rep_msg = generic_msg(
cmd=""caseChange"", args={""subcmd"": ""capitalize"", ""objType"": self.objType, ""obj"": self.entry}
)
return Strings.from_return_msg(cast(str, rep_msg))
",[],0,[],/strings.py_capitalize
129,/home/amandapotts/git/arkouda/arkouda/strings.py_islower,"def islower(self) -> pdarray:
""""""
Returns a boolean pdarray where index i indicates whether string i of the
Strings is entirely lowercase
Returns
-------
pdarray, bool
True for elements that are entirely lowercase, False otherwise
Raises
------
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
Strings.isupper
Examples
--------
>>> lower = ak.array([f'strings {i}' for i in range(3)])
>>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
>>> strings = ak.concatenate([lower, upper])
>>> strings
array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
>>> strings.islower()
array([True True True False False False])
""""""
return create_pdarray(
generic_msg(
cmd=""checkChars"", args={""subcmd"": ""isLower"", ""objType"": self.objType, ""obj"": self.entry}
)
)
",[],0,[],/strings.py_islower
130,/home/amandapotts/git/arkouda/arkouda/strings.py_isupper,"def isupper(self) -> pdarray:
""""""
Returns a boolean pdarray where index i indicates whether string i of the
Strings is entirely uppercase
Returns
-------
pdarray, bool
True for elements that are entirely uppercase, False otherwise
Raises
------
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
Strings.islower
Examples
--------
>>> lower = ak.array([f'strings {i}' for i in range(3)])
>>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
>>> strings = ak.concatenate([lower, upper])
>>> strings
array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
>>> strings.isupper()
array([False False False True True True])
""""""
return create_pdarray(
generic_msg(
cmd=""checkChars"", args={""subcmd"": ""isUpper"", ""objType"": self.objType, ""obj"": self.entry}
)
)
",[],0,[],/strings.py_isupper
131,/home/amandapotts/git/arkouda/arkouda/strings.py_istitle,"def istitle(self) -> pdarray:
""""""
Returns a boolean pdarray where index i indicates whether string i of the
Strings is titlecase
Returns
-------
pdarray, bool
True for elements that are titlecase, False otherwise
Raises
------
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
Strings.islower
Strings.isupper
Examples
--------
>>> mixed = ak.array([f'sTrINgs {i}' for i in range(3)])
>>> title = ak.array([f'Strings {i}' for i in range(3)])
>>> strings = ak.concatenate([mixed, title])
>>> strings
array(['sTrINgs 0', 'sTrINgs 1', 'sTrINgs 2', 'Strings 0', 'Strings 1', 'Strings 2'])
>>> strings.istitle()
array([False False False True True True])
""""""
return create_pdarray(
generic_msg(
cmd=""checkChars"", args={""subcmd"": ""isTitle"", ""objType"": self.objType, ""obj"": self.entry}
)
)
",[],0,[],/strings.py_istitle
132,/home/amandapotts/git/arkouda/arkouda/strings.py_isalnum,"def isalnum(self) -> pdarray:
""""""
Returns a boolean pdarray where index i indicates whether string i of the
Strings is alphanumeric.
Returns
-------
pdarray, bool
True for elements that are alphanumeric, False otherwise
Raises
------
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
Strings.islower
Strings.isupper
Strings.istitle
Examples
--------
>>> not_alnum = ak.array([f'%Strings {i}' for i in range(3)])
>>> alnum = ak.array([f'Strings{i}' for i in range(3)])
>>> strings = ak.concatenate([not_alnum, alnum])
>>> strings
array(['%Strings 0', '%Strings 1', '%Strings 2', 'Strings0', 'Strings1', 'Strings2'])
>>> strings.isalnum()
array([False False False True True True])
""""""
return create_pdarray(
generic_msg(
cmd=""checkChars"", args={""subcmd"": ""isalnum"", ""objType"": self.objType, ""obj"": self.entry}
)
)
",[],0,[],/strings.py_isalnum
133,/home/amandapotts/git/arkouda/arkouda/strings.py_isalpha,"def isalpha(self) -> pdarray:
""""""
Returns a boolean pdarray where index i indicates whether string i of the
Strings is alphabetic.  This means there is at least one character,
and all the characters are alphabetic.
Returns
-------
pdarray, bool
True for elements that are alphabetic, False otherwise
Raises
------
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
Strings.islower
Strings.isupper
Strings.istitle
Strings.isalnum
Examples
--------
>>> not_alpha = ak.array([f'%Strings {i}' for i in range(3)])
>>> alpha = ak.array(['StringA','StringB','StringC'])
>>> strings = ak.concatenate([not_alpha, alpha])
>>> strings
array(['%Strings 0', '%Strings 1', '%Strings 2', 'StringA','StringB','StringC'])
>>> strings.isalpha()
array([False False False True True True])
""""""
return create_pdarray(
generic_msg(
cmd=""checkChars"", args={""subcmd"": ""isalpha"", ""objType"": self.objType, ""obj"": self.entry}
)
)
",[],0,[],/strings.py_isalpha
134,/home/amandapotts/git/arkouda/arkouda/strings.py_isdigit,"def isdigit(self) -> pdarray:
""""""
Returns a boolean pdarray where index i indicates whether string i of the
Strings has all digit characters.
Returns
-------
pdarray, bool
True for elements that are digits, False otherwise
Raises
------
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
Strings.islower
Strings.isupper
Strings.istitle
Examples
--------
>>> not_digit = ak.array([f'Strings {i}' for i in range(3)])
>>> digit = ak.array([f'12{i}' for i in range(3)])
>>> strings = ak.concatenate([not_digit, digit])
>>> strings
array(['Strings 0', 'Strings 1', 'Strings 2', '120', '121', '122'])
>>> strings.isdigit()
array([False False False True True True])
""""""
return create_pdarray(
generic_msg(
cmd=""checkChars"", args={""subcmd"": ""isdigit"", ""objType"": self.objType, ""obj"": self.entry}
)
)
",[],0,[],/strings.py_isdigit
135,/home/amandapotts/git/arkouda/arkouda/strings.py_isempty,"def isempty(self) -> pdarray:
""""""
Returns a boolean pdarray where index i indicates whether string i of the
Strings is empty.
True for elements that are the empty string, False otherwise
Returns
-------
pdarray, bool
True for elements that are digits, False otherwise
Raises
------
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
Strings.islower
Strings.isupper
Strings.istitle
Examples
--------
>>> not_empty = ak.array([f'Strings {i}' for i in range(3)])
>>> empty = ak.array(['' for i in range(3)])
>>> strings = ak.concatenate([not_empty, empty])
>>> strings
array(['%Strings 0', '%Strings 1', '%Strings 2', '', '', ''])
>>> strings.isempty()
""""""
return create_pdarray(
generic_msg(
cmd=""checkChars"", args={""subcmd"": ""isempty"", ""objType"": self.objType, ""obj"": self.entry}
)
)
",[],0,[],/strings.py_isempty
136,/home/amandapotts/git/arkouda/arkouda/strings.py_isspace,"def isspace(self) -> pdarray:
""""""
Returns a boolean pdarray where index i indicates whether string i has all
whitespace characters (‘ ‘, ‘\t’, ‘\n’, ‘\v’, ‘\f’, ‘\r’).
Returns
-------
pdarray, bool
True for elements that are whitespace, False otherwise
Raises
------
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
Strings.islower
Strings.isupper
Strings.istitle
Examples
--------
>>> not_space = ak.array([f'Strings {i}' for i in range(3)])
>>> space = ak.array([' ', '\t', '\n', '\v', '\f', '\r', ' \t\n\v\f\r'])
>>> strings = ak.concatenate([not_space, space])
>>> strings
array(['Strings 0', 'Strings 1', 'Strings 2', ' ',
... 'u0009', 'n', 'u000B', 'u000C', 'u000D', ' u0009nu000Bu000Cu000D'])
>>> strings.isspace()
array([False False False True True True True True True True])
""""""
return create_pdarray(
generic_msg(
cmd=""checkChars"", args={""subcmd"": ""isspace"", ""objType"": self.objType, ""obj"": self.entry}
)
)
",[],0,[],/strings.py_isspace
137,/home/amandapotts/git/arkouda/arkouda/strings.py_strip,"def strip(self, chars: Optional[Union[bytes, str_scalars]] = """") -> Strings:
""""""
Returns a new Strings object with all leading and trailing occurrences of characters contained
in chars removed. The chars argument is a string specifying the set of characters to be removed.
If omitted, the chars argument defaults to removing whitespace. The chars argument is not a
prefix or suffix
Parameters
----------
chars
the set of characters to be removed
Returns
-------
Strings
Strings object with the leading and trailing characters matching the set of characters in
the chars argument removed
Raises
------
RuntimeError
Raised if there is a server-side error thrown
Examples
--------
>>> strings = ak.array(['Strings ', '  StringS  ', 'StringS   '])
>>> s = strings.strip()
>>> s
array(['Strings', 'StringS', 'StringS'])
>>> strings = ak.array(['Strings 1', '1 StringS  ', '  1StringS  12 '])
>>> s = strings.strip(' 12')
>>> s
array(['Strings', 'StringS', 'StringS'])
""""""
if isinstance(chars, bytes):
chars = chars.decode()
rep_msg = generic_msg(
cmd=""segmentedStrip"", args={""objType"": self.objType, ""name"": self.entry, ""chars"": chars}
)
return Strings.from_return_msg(cast(str, rep_msg))
",[],0,[],/strings.py_strip
138,/home/amandapotts/git/arkouda/arkouda/strings.py_cached_regex_patterns,"def cached_regex_patterns(self) -> List:
""""""
Returns the regex patterns for which Match objects have been cached
""""""
return list(self._regex_dict.keys())
",[],0,[],/strings.py_cached_regex_patterns
139,/home/amandapotts/git/arkouda/arkouda/strings.py_purge_cached_regex_patterns,"def purge_cached_regex_patterns(self) -> None:
""""""
purges cached regex patterns
""""""
self._regex_dict = dict()
",[],0,[],/strings.py_purge_cached_regex_patterns
140,/home/amandapotts/git/arkouda/arkouda/strings.py__empty_pattern_verification,"def _empty_pattern_verification(self, pattern):
if pattern == ""$"" or (re.search(pattern, """") and (self == """").any()):  # type: ignore
raise ValueError(
""regex operations not currently supported with a pattern='$' or pattern='' when ""
""the empty string is contained in Strings""
)
",[],0,[],/strings.py__empty_pattern_verification
141,/home/amandapotts/git/arkouda/arkouda/strings.py__get_matcher,"def _get_matcher(self, pattern: Union[bytes, str_scalars], create: bool = True):
""""""
internal function to fetch cached Matcher objects
""""""
from arkouda.matcher import Matcher
if isinstance(pattern, bytes):
pattern = pattern.decode()
try:
re.compile(pattern)
except Exception as e:
raise ValueError(e)
self._empty_pattern_verification(pattern)
matcher = None
if pattern in self._regex_dict:
matcher = self._regex_dict[pattern]
elif create:
self._regex_dict[pattern] = Matcher(pattern=pattern, parent_entry_name=self.entry.name)
matcher = self._regex_dict[pattern]
return matcher
",[],0,[],/strings.py__get_matcher
142,/home/amandapotts/git/arkouda/arkouda/strings.py_find_locations,"def find_locations(self, pattern: Union[bytes, str_scalars]) -> Tuple[pdarray, pdarray, pdarray]:
""""""
Finds pattern matches and returns pdarrays containing the number, start postitions,
and lengths of matches
Parameters
----------
pattern: str_scalars
The regex pattern used to find matches
Returns
-------
pdarray, int64
For each original string, the number of pattern matches
pdarray, int64
The start positons of pattern matches
pdarray, int64
The lengths of pattern matches
Raises
------
TypeError
Raised if the pattern parameter is not bytes or str_scalars
ValueError
Raised if pattern is not a valid regex
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
Strings.findall, Strings.match
Examples
--------
>>> strings = ak.array([f'{i} string {i}' for i in range(1, 6)])
>>> num_matches, starts, lens = strings.find_locations('\\d')
>>> num_matches
array([2, 2, 2, 2, 2])
>>> starts
array([0, 9, 0, 9, 0, 9, 0, 9, 0, 9])
>>> lens
array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
""""""
matcher = self._get_matcher(pattern)
matcher.find_locations()
return matcher.num_matches, matcher.starts, matcher.lengths
",[],0,[],/strings.py_find_locations
143,/home/amandapotts/git/arkouda/arkouda/strings.py_search,"def search(self, pattern: Union[bytes, str_scalars]) -> Match:
""""""
Returns a match object with the first location in each element where pattern produces a match.
Elements match if any part of the string matches the regular expression pattern
Parameters
----------
pattern: str
Regex used to find matches
Returns
-------
Match
Match object where elements match if any part of the string matches the
regular expression pattern
Examples
--------
>>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
>>> strings.search('_+')
<ak.Match object: matched=True, span=(1, 2)
matched=False
""""""
return self._get_matcher(pattern).get_match(MatchType.SEARCH, self)
",[],0,[],/strings.py_search
144,/home/amandapotts/git/arkouda/arkouda/strings.py_match,"def match(self, pattern: Union[bytes, str_scalars]) -> Match:
""""""
Returns a match object where elements match only if the beginning of the string matches the
regular expression pattern
Parameters
----------
pattern: str
Regex used to find matches
Returns
-------
Match
Match object where elements match only if the beginning of the string matches the
regular expression pattern
Examples
--------
>>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
>>> strings.match('_+')
<ak.Match object: matched=False
matched=True, span=(0, 2)
""""""
return self._get_matcher(pattern).get_match(MatchType.MATCH, self)
",[],0,[],/strings.py_match
145,/home/amandapotts/git/arkouda/arkouda/strings.py_fullmatch,"def fullmatch(self, pattern: Union[bytes, str_scalars]) -> Match:
""""""
Returns a match object where elements match only if the whole string matches the
regular expression pattern
Parameters
----------
pattern: str
Regex used to find matches
Returns
-------
Match
Match object where elements match only if the whole string matches the
regular expression pattern
Examples
--------
>>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
>>> strings.fullmatch('_+')
<ak.Match object: matched=False
matched=False
""""""
return self._get_matcher(pattern).get_match(MatchType.FULLMATCH, self)
",[],0,[],/strings.py_fullmatch
146,/home/amandapotts/git/arkouda/arkouda/strings.py_split,"def split(
self, pattern: Union[bytes, str_scalars], maxsplit: int = 0, return_segments: bool = False
",[],0,[],/strings.py_split
147,/home/amandapotts/git/arkouda/arkouda/strings.py_findall,"def findall(
self, pattern: Union[bytes, str_scalars], return_match_origins: bool = False
",[],0,[],/strings.py_findall
148,/home/amandapotts/git/arkouda/arkouda/strings.py_sub,"def sub(
self, pattern: Union[bytes, str_scalars], repl: Union[bytes, str_scalars], count: int = 0
",[],0,[],/strings.py_sub
149,/home/amandapotts/git/arkouda/arkouda/strings.py_subn,"def subn(
self, pattern: Union[bytes, str_scalars], repl: Union[bytes, str_scalars], count: int = 0
",[],0,[],/strings.py_subn
150,/home/amandapotts/git/arkouda/arkouda/strings.py_contains,"def contains(self, substr: Union[bytes, str_scalars], regex: bool = False) -> pdarray:
""""""
Check whether each element contains the given substring.
Parameters
----------
substr: str_scalars
The substring in the form of string or byte array to search for
regex: bool
Indicates whether substr is a regular expression
Note: only handles regular expressions supported by re2
(does not support lookaheads/lookbehinds)
Returns
-------
pdarray, bool
True for elements that contain substr, False otherwise
Raises
------
TypeError
Raised if the substr parameter is not bytes or str_scalars
ValueError
Rasied if substr is not a valid regex
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
Strings.startswith, Strings.endswith
Examples
--------
>>> strings = ak.array([f'{i} string {i}' for i in range(1, 6)])
>>> strings
array(['1 string 1', '2 string 2', '3 string 3', '4 string 4', '5 string 5'])
>>> strings.contains('string')
array([True, True, True, True, True])
>>> strings.contains('string \\d', regex=True)
array([True, True, True, True, True])
""""""
if isinstance(substr, bytes):
substr = substr.decode()
if not regex:
substr = re.escape(substr)
self._empty_pattern_verification(substr)
matcher = self._get_matcher(substr, create=False)
if matcher is not None:
return matcher.get_match(MatchType.SEARCH, self).matched()
return create_pdarray(
generic_msg(
cmd=""segmentedSearch"",
args={""objType"": self.objType, ""obj"": self.entry, ""valType"": ""str"", ""val"": substr},
)
)
",[],0,[],/strings.py_contains
151,/home/amandapotts/git/arkouda/arkouda/strings.py_startswith,"def startswith(self, substr: Union[bytes, str_scalars], regex: bool = False) -> pdarray:
""""""
Check whether each element starts with the given substring.
Parameters
----------
substr: Union[bytes, str_scalars]
The prefix to search for
regex: bool
Indicates whether substr is a regular expression
Note: only handles regular expressions supported by re2
(does not support lookaheads/lookbehinds)
Returns
-------
pdarray, bool
True for elements that start with substr, False otherwise
Raises
------
TypeError
Raised if the substr parameter is not a bytes ior str_scalars
ValueError
Rasied if substr is not a valid regex
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
Strings.contains, Strings.endswith
Examples
--------
>>> strings_end = ak.array([f'string {i}' for i in range(1, 6)])
>>> strings_end
array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
>>> strings_end.startswith('string')
array([True, True, True, True, True])
>>> strings_start = ak.array([f'{i} string' for i in range(1,6)])
>>> strings_start
array(['1 string', '2 string', '3 string', '4 string', '5 string'])
>>> strings_start.startswith('\\d str', regex = True)
array([True, True, True, True, True])
""""""
if isinstance(substr, bytes):
substr = substr.decode()
if not regex:
substr = re.escape(substr)
self._empty_pattern_verification(substr)
matcher = self._get_matcher(substr, create=False)
if matcher is not None:
return matcher.get_match(MatchType.MATCH, self).matched()
else:
return self.contains(""^"" + substr, regex=True)
",[],0,[],/strings.py_startswith
152,/home/amandapotts/git/arkouda/arkouda/strings.py_endswith,"def endswith(self, substr: Union[bytes, str_scalars], regex: bool = False) -> pdarray:
""""""
Check whether each element ends with the given substring.
Parameters
----------
substr: Union[bytes, str_scalars]
The suffix to search for
regex: bool
Indicates whether substr is a regular expression
Note: only handles regular expressions supported by re2
(does not support lookaheads/lookbehinds)
Returns
-------
pdarray, bool
True for elements that end with substr, False otherwise
Raises
------
TypeError
Raised if the substr parameter is not bytes or str_scalars
ValueError
Rasied if substr is not a valid regex
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
Strings.contains, Strings.startswith
Examples
--------
>>> strings_start = ak.array([f'{i} string' for i in range(1,6)])
>>> strings_start
array(['1 string', '2 string', '3 string', '4 string', '5 string'])
>>> strings_start.endswith('ing')
array([True, True, True, True, True])
>>> strings_end = ak.array([f'string {i}' for i in range(1, 6)])
>>> strings_end
array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
>>> strings_end.endswith('ing \\d', regex = True)
array([True, True, True, True, True])
""""""
if isinstance(substr, bytes):
substr = substr.decode()
if not regex:
substr = re.escape(substr)
self._empty_pattern_verification(substr)
return self.contains(substr + ""$"", regex=True)
",[],0,[],/strings.py_endswith
153,/home/amandapotts/git/arkouda/arkouda/strings.py_flatten,"def flatten(
self, delimiter: str, return_segments: bool = False, regex: bool = False
",[],0,[],/strings.py_flatten
154,/home/amandapotts/git/arkouda/arkouda/strings.py_peel,"def peel(
self,
delimiter: Union[bytes, str_scalars],
times: int_scalars = 1,
includeDelimiter: bool = False,
keepPartial: bool = False,
fromRight: bool = False,
regex: bool = False,
",[],0,[],/strings.py_peel
155,/home/amandapotts/git/arkouda/arkouda/strings.py_rpeel,"def rpeel(
self,
delimiter: Union[bytes, str_scalars],
times: int_scalars = 1,
includeDelimiter: bool = False,
keepPartial: bool = False,
regex: bool = False,
",[],0,[],/strings.py_rpeel
156,/home/amandapotts/git/arkouda/arkouda/strings.py_stick,"def stick(
self, other: Strings, delimiter: Union[bytes, str_scalars] = """", toLeft: bool = False
",[],0,[],/strings.py_stick
157,/home/amandapotts/git/arkouda/arkouda/strings.py___add__,"def __add__(self, other: Strings) -> Strings:
return self.stick(other)
",[],0,[],/strings.py___add__
158,/home/amandapotts/git/arkouda/arkouda/strings.py_lstick,"def lstick(self, other: Strings, delimiter: Union[bytes, str_scalars] = """") -> Strings:
""""""
Join the strings from another array onto the left of the strings
of this array, optionally inserting a delimiter.
Parameters
----------
other : Strings
The strings to join onto self's strings
delimiter : Union[bytes,str_scalars]
String inserted between self and other
Returns
-------
Strings
The array of joined strings, as other + self
Raises
------
TypeError
Raised if the delimiter parameter is neither bytes nor a str
or if the other parameter is not a Strings instance
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
stick, peel, rpeel
Examples
--------
>>> s = ak.array(['a', 'c', 'e'])
>>> t = ak.array(['b', 'd', 'f'])
>>> s.lstick(t, delimiter='.')
array(['b.a', 'd.c', 'f.e'])
""""""
return self.stick(other, delimiter=delimiter, toLeft=True)
",[],0,[],/strings.py_lstick
159,/home/amandapotts/git/arkouda/arkouda/strings.py___radd__,"def __radd__(self, other: Strings) -> Strings:
return self.lstick(other)
",[],0,[],/strings.py___radd__
160,/home/amandapotts/git/arkouda/arkouda/strings.py_get_prefixes,"def get_prefixes(
self, n: int_scalars, return_origins: bool = True, proper: bool = True
",[],0,[],/strings.py_get_prefixes
161,/home/amandapotts/git/arkouda/arkouda/strings.py_get_suffixes,"def get_suffixes(
self, n: int_scalars, return_origins: bool = True, proper: bool = True
",[],0,[],/strings.py_get_suffixes
162,/home/amandapotts/git/arkouda/arkouda/strings.py_hash,"def hash(self) -> Tuple[pdarray, pdarray]:
""""""
Compute a 128-bit hash of each string.
Returns
-------
Tuple[pdarray,pdarray]
A tuple of two int64 pdarrays. The ith hash value is the concatenation
of the ith values from each array.
Notes
-----
The implementation uses SipHash128, a fast and balanced hash function (used
by Python for dictionaries and sets). For realistic numbers of strings (up
to about 10**15), the probability of a collision between two 128-bit hash
values is negligible.
""""""
repMsg = generic_msg(cmd=""segmentedHash"", args={""objType"": self.objType, ""obj"": self.entry})
h1, h2 = cast(str, repMsg).split(""+"")
return create_pdarray(h1), create_pdarray(h2)
",[],0,[],/strings.py_hash
163,/home/amandapotts/git/arkouda/arkouda/strings.py_group,"def group(self) -> pdarray:
""""""
Return the permutation that groups the array, placing equivalent
strings together. All instances of the same string are guaranteed to lie
in one contiguous block of the permuted array, but the blocks are not
necessarily ordered.
Returns
-------
pdarray
The permutation that groups the array by value
See Also
--------
GroupBy, unique
Notes
-----
If the arkouda server is compiled with ""-sSegmentedString.useHash=true"",
then arkouda uses 128-bit hash values to group strings, rather than sorting
the strings directly. This method is fast, but the resulting permutation
merely groups equivalent strings and does not sort them. If the ""useHash""
parameter is false, then a full sort is performed.
Raises
------
RuntimeError
Raised if there is a server-side error in executing group request or
creating the pdarray encapsulating the return message
""""""
return create_pdarray(
generic_msg(cmd=""segmentedGroup"", args={""objType"": self.objType, ""obj"": self.entry})
)
",[],0,[],/strings.py_group
164,/home/amandapotts/git/arkouda/arkouda/strings.py__get_grouping_keys,"def _get_grouping_keys(self) -> List[Strings]:
""""""
Private method for generating grouping keys used by GroupBy.
API: this method must be defined by all groupable arrays, and it
must return a list of arrays that can be (co)argsorted.
""""""
return [self]
",[],0,[],/strings.py__get_grouping_keys
165,/home/amandapotts/git/arkouda/arkouda/strings.py_to_ndarray,"def to_ndarray(self) -> np.ndarray:
""""""
Convert the array to a np.ndarray, transferring array data from the
arkouda server to Python. If the array exceeds a built-in size limit,
a RuntimeError is raised.
Returns
-------
np.ndarray
A numpy ndarray with the same strings as this array
Notes
-----
The number of bytes in the array cannot exceed ``ak.client.maxTransferBytes``,
otherwise a ``RuntimeError`` will be raised. This is to protect the user
from overflowing the memory of the system on which the Python client
is running, under the assumption that the server is running on a
distributed system with much more memory than the client. The user
may override this limit by setting ak.client.maxTransferBytes to a larger
value, but proceed with caution.
See Also
--------
array()
to_list()
Examples
--------
>>> a = ak.array([""hello"", ""my"", ""world""])
>>> a.to_ndarray()
array(['hello', 'my', 'world'], dtype='<U5')
>>> type(a.to_ndarray())
numpy.ndarray
""""""
npoffsets = np.hstack((self._comp_to_ndarray(""offsets""), np.array([self.nbytes])))
npvalues = self._comp_to_ndarray(""values"")
lengths = np.diff(npoffsets) - 1
dt = f""<U{lengths.max() if len(lengths) > 0 else 1}""
res = np.empty(self.size, dtype=dt)
for i, (o, l) in enumerate(zip(npoffsets, lengths)):
res[i] = np.str_(codecs.decode(b"""".join(npvalues[o : o + l])))
return res
","['ndarray', 'ndarray', 'ndarray', 'hstack', 'array', 'diff', 'empty', 'str_']",8,"['hstack((self._comp_to_ndarray(""offsets""), np.array([self.nbytes])))', 'diff(npoffsets)', 'empty(self.size, dtype=dt)', 'str_(codecs.decode(b"""".join(npvalues[o : o + l])))']",/strings.py_to_ndarray
166,/home/amandapotts/git/arkouda/arkouda/strings.py_to_list,"def to_list(self) -> list:
""""""
Convert the SegString to a list, transferring data from the
arkouda server to Python. If the SegString exceeds a built-in size limit,
a RuntimeError is raised.
Returns
-------
list
A list with the same strings as this SegString
Notes
-----
The number of bytes in the array cannot exceed ``ak.client.maxTransferBytes``,
otherwise a ``RuntimeError`` will be raised. This is to protect the user
from overflowing the memory of the system on which the Python client
is running, under the assumption that the server is running on a
distributed system with much more memory than the client. The user
may override this limit by setting ak.client.maxTransferBytes to a larger
value, but proceed with caution.
See Also
--------
to_ndarray()
Examples
--------
>>> a = ak.array([""hello"", ""my"", ""world""])
>>> a.to_list()
['hello', 'my', 'world']
>>> type(a.to_list())
list
""""""
return self.to_ndarray().tolist()
",[],0,[],/strings.py_to_list
167,/home/amandapotts/git/arkouda/arkouda/strings.py__comp_to_ndarray,"def _comp_to_ndarray(self, comp: str) -> np.ndarray:
""""""
This is an internal helper function to perform the to_ndarray for one
of the string components.
Parameters
----------
comp : str
The strings component to request
Returns
-------
np.ndarray
A numpy ndarray with the same attributes and data as the pdarray
Raises
------
RuntimeError
Raised if there is a server-side error thrown, if the pdarray size
exceeds the built-in client.maxTransferBytes size limit, or if the bytes
received does not match expected number of bytes
Notes
-----
The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
otherwise a ``RuntimeError`` will be raised. This is to protect the user
from overflowing the memory of the system on which the Python client
is running, under the assumption that the server is running on a
distributed system with much more memory than the client. The user
may override this limit by setting client.maxTransferBytes to a larger
value, but proceed with caution.
""""""
from arkouda.client import maxTransferBytes
array_bytes = (
self.size * arkouda.dtypes.int64.itemsize
if comp == ""offsets""
else self.nbytes * arkouda.dtypes.uint8.itemsize
)
if array_bytes > maxTransferBytes:
raise RuntimeError(
""Array exceeds allowed size for transfer. Increase ak.client.maxTransferBytes to allow""
)
rep_msg = generic_msg(
cmd=CMD_TO_NDARRAY, args={""obj"": self.entry, ""comp"": comp}, recv_binary=True
)
if len(rep_msg) != array_bytes:
raise RuntimeError(f""Expected {array_bytes} bytes but received {len(rep_msg)}"")
dt: np.dtype = np.dtype(np.int64) if comp == ""offsets"" else np.dtype(np.uint8)
if arkouda.dtypes.get_server_byteorder() == ""big"":
dt = dt.newbyteorder("">"")
else:
dt = dt.newbyteorder(""<"")
return (
np.frombuffer(rep_msg.encode(""utf_8""), dt).copy()
if isinstance(rep_msg, str)
else np.frombuffer(rep_msg, dt).copy()
)
","['ndarray', 'ndarray', 'dtype', 'dtype', 'int64', 'dtype', 'uint8', 'frombuffer', 'frombuffer']",9,"['dtype(np.int64) if comp == ""offsets"" else np.dtype(np.uint8)', 'frombuffer(rep_msg.encode(""utf_8""), dt).copy()', 'frombuffer(rep_msg, dt).copy()']",/strings.py__comp_to_ndarray
168,/home/amandapotts/git/arkouda/arkouda/strings.py_astype,"def astype(self, dtype) -> pdarray:
""""""
Cast values of Strings object to provided dtype
Parameters
__________
dtype: np.dtype or str
Dtype to cast to
Returns
_______
ak.pdarray
An arkouda pdarray with values converted to the specified data type
Notes
_____
This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.
""""""
from arkouda.numeric import cast as akcast
return akcast(self, dtype)
",['dtype'],1,[],/strings.py_astype
169,/home/amandapotts/git/arkouda/arkouda/strings.py_to_parquet,"def to_parquet(
self,
prefix_path: str,
dataset: str = ""strings_array"",
mode: str = ""truncate"",
compression: Optional[str] = None,
",[],0,[],/strings.py_to_parquet
170,/home/amandapotts/git/arkouda/arkouda/strings.py_to_hdf,"def to_hdf(
self,
prefix_path: str,
dataset: str = ""strings_array"",
mode: str = ""truncate"",
save_offsets: bool = True,
file_type: str = ""distribute"",
",[],0,[],/strings.py_to_hdf
171,/home/amandapotts/git/arkouda/arkouda/strings.py_update_hdf,"def update_hdf(
self,
prefix_path: str,
dataset: str = ""strings_array"",
save_offsets: bool = True,
repack: bool = True,
",[],0,[],/strings.py_update_hdf
172,/home/amandapotts/git/arkouda/arkouda/strings.py_to_csv,"def to_csv(
self,
prefix_path: str,
dataset: str = ""strings_array"",
col_delim: str = "","",
overwrite: bool = False,
",[],0,[],/strings.py_to_csv
173,/home/amandapotts/git/arkouda/arkouda/strings.py_save,"def save(
self,
prefix_path: str,
dataset: str = ""strings_array"",
mode: str = ""truncate"",
save_offsets: bool = True,
compression: Optional[str] = None,
file_format: str = ""HDF5"",
file_type: str = ""distribute"",
",[],0,[],/strings.py_save
174,/home/amandapotts/git/arkouda/arkouda/strings.py__list_component_names,"def _list_component_names(self) -> List[str]:
""""""
Internal Function that returns a list of all component names
Parameters
----------
None
Returns
-------
List[str]
List of all component names
""""""
return list(itertools.chain.from_iterable([self.entry._list_component_names()]))
",[],0,[],/strings.py__list_component_names
175,/home/amandapotts/git/arkouda/arkouda/strings.py_info,"def info(self) -> str:
""""""
Returns a JSON formatted string containing information about all components of self
Parameters
----------
None
Returns
-------
str
JSON string containing information about all components of self
""""""
return information(self._list_component_names())
",[],0,[],/strings.py_info
176,/home/amandapotts/git/arkouda/arkouda/strings.py_pretty_print_info,"def pretty_print_info(self) -> None:
""""""
Prints information about all components of self in a human readable format
Parameters
----------
None
Returns
-------
None
""""""
self.entry.pretty_print_info()
",[],0,[],/strings.py_pretty_print_info
177,/home/amandapotts/git/arkouda/arkouda/strings.py_register,"def register(self, user_defined_name: str) -> Strings:
""""""
Register this Strings object with a user defined name in the arkouda server
so it can be attached to later using Strings.attach()
This is an in-place operation, registering a Strings object more than once will
update the name in the registry and remove the previously registered name.
A name can only be registered to one object at a time.
Parameters
----------
user_defined_name : str
user defined name which the Strings object is to be registered under
Returns
-------
Strings
The same Strings object which is now registered with the arkouda server and
has an updated name.
This is an in-place modification, the original is returned to support a
fluid programming style.
Please note you cannot register two different objects with the same name.
Raises
------
TypeError
Raised if user_defined_name is not a str
RegistrationError
If the server was unable to register the Strings object with the user_defined_name
If the user is attempting to register more than one object with the same name,
the former should be unregistered first to free up the registration name.
See also
--------
attach, unregister
Notes
-----
Registered names/Strings objects in the server are immune to deletion
until they are unregistered.
""""""
if self.registered_name is not None and self.is_registered():
raise RegistrationError(f""This object is already registered as {self.registered_name}"")
generic_msg(
cmd=""register"",
args={
""name"": user_defined_name,
""objType"": self.objType,
""array"": self.name,
},
)
self.registered_name = user_defined_name
return self
",[],0,[],/strings.py_register
178,/home/amandapotts/git/arkouda/arkouda/strings.py_unregister,"def unregister(self) -> None:
""""""
Unregister a Strings object in the arkouda server which was previously
registered using register() and/or attached to using attach()
Parameters
----------
Returns
-------
None
Raises
------
RuntimeError
Raised if the server could not find the internal name/symbol to remove
See also
--------
register, attach
Notes
-----
Registered names/Strings objects in the server are immune to deletion until
they are unregistered.
""""""
from arkouda.util import unregister
if not self.registered_name:
raise RegistrationError(""This object is not registered"")
unregister(self.registered_name)
self.registered_name = None
",[],0,[],/strings.py_unregister
179,/home/amandapotts/git/arkouda/arkouda/strings.py_is_registered,"def is_registered(self) -> np.bool_:
""""""
Return True iff the object is contained in the registry
Parameters
----------
None
Returns
-------
bool
Indicates if the object is contained in the registry
Raises
------
RuntimeError
Raised if there's a server-side error thrown
""""""
from arkouda.util import is_registered
if self.registered_name is None:
return np.bool_(is_registered(self.name, as_component=True))
else:
return np.bool_(is_registered(self.registered_name))
","['bool_', 'bool_', 'bool_']",3,"['bool_(is_registered(self.name, as_component=True))', 'bool_(is_registered(self.registered_name))']",/strings.py_is_registered
180,/home/amandapotts/git/arkouda/arkouda/strings.py_attach,"def attach(user_defined_name: str) -> Strings:
""""""
class method to return a Strings object attached to the registered name in the arkouda
server which was registered using register()
Parameters
----------
user_defined_name : str
user defined name which the Strings object was registered under
Returns
-------
Strings object
the Strings object registered with user_defined_name in the arkouda server
Raises
------
TypeError
Raised if user_defined_name is not a str
See also
--------
register, unregister
Notes
-----
Registered names/Strings objects in the server are immune to deletion
until they are unregistered.
""""""
import warnings
from arkouda.util import attach
warnings.warn(
""ak.Strings.attach() is deprecated. Please use ak.attach() instead."",
DeprecationWarning,
)
return attach(user_defined_name)
",[],0,[],/strings.py_attach
181,/home/amandapotts/git/arkouda/arkouda/strings.py_unregister_strings_by_name,"def unregister_strings_by_name(user_defined_name: str) -> None:
""""""
Unregister a Strings object in the arkouda server previously registered via register()
Parameters
----------
user_defined_name : str
The registered name of the Strings object
See also
--------
register, unregister, attach, is_registered
""""""
import warnings
from arkouda.util import unregister
warnings.warn(
""ak.Strings.unregister_segarray_by_name() is deprecated. ""
""Please use ak.unregister() instead."",
DeprecationWarning,
)
return unregister(user_defined_name)
",[],0,[],/strings.py_unregister_strings_by_name
182,/home/amandapotts/git/arkouda/arkouda/strings.py_transfer,"def transfer(self, hostname: str, port: int_scalars):
""""""
Sends a Strings object to a different Arkouda server
Parameters
----------
hostname : str
The hostname where the Arkouda server intended to
receive the Strings object is running.
port : int_scalars
The port to send the array over. This needs to be an
open port (i.e., not one that the Arkouda server is
running on). This will open up `numLocales` ports,
each of which in succession, so will use ports of the
range {port..(port+numLocales)} (e.g., running an
Arkouda server of 4 nodes, port 1234 is passed as
`port`, Arkouda will use ports 1234, 1235, 1236,
and 1237 to send the array data).
This port much match the port passed to the call to
`ak.receive_array()`.
Returns
-------
A message indicating a complete transfer
Raises
------
ValueError
Raised if the op is not within the pdarray.BinOps set
TypeError
Raised if other is not a pdarray or the pdarray.dtype is not
a supported dtype
""""""
return generic_msg(
cmd=""sendArray"",
args={""values"": self.entry, ""hostname"": hostname, ""port"": port, ""objType"": ""strings""},
)
",[],0,[],/strings.py_transfer
183,/home/amandapotts/git/arkouda/arkouda/_version.py_get_keywords,"def get_keywords():
""""""Get the keywords needed to look up the version information.""""""
git_refnames = ""$Format:%d$""
git_full = ""$Format:%H$""
git_date = ""$Format:%ci$""
keywords = {""refnames"": git_refnames, ""full"": git_full, ""date"": git_date}
return keywords
",[],0,[],/_version.py_get_keywords
184,/home/amandapotts/git/arkouda/arkouda/_version.py_get_config,"def get_config():
""""""Create, populate and return the VersioneerConfig() object.""""""
cfg = VersioneerConfig()
cfg.VCS = ""git""
cfg.style = ""pep440""
cfg.tag_prefix = """"
cfg.parentdir_prefix = ""arkouda-""
cfg.versionfile_source = ""arkouda/_version.py""
cfg.verbose = False
return cfg
",[],0,[],/_version.py_get_config
185,/home/amandapotts/git/arkouda/arkouda/_version.py_register_vcs_handler,"def register_vcs_handler(vcs, method):  # decorator
""""""Create decorator to mark a method as the handler of a VCS.""""""
",[],0,[],/_version.py_register_vcs_handler
186,/home/amandapotts/git/arkouda/arkouda/_version.py_decorate,"def decorate(f):
""""""Store f in HANDLERS[vcs][method].""""""
if vcs not in HANDLERS:
HANDLERS[vcs] = {}
HANDLERS[vcs][method] = f
return f
",[],0,[],/_version.py_decorate
187,/home/amandapotts/git/arkouda/arkouda/_version.py_run_command,"def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):
""""""Call the given command(s).""""""
assert isinstance(commands, list)
p = None
for c in commands:
try:
dispcmd = str([c] + args)
p = subprocess.Popen(
[c] + args,
cwd=cwd,
env=env,
stdout=subprocess.PIPE,
stderr=(subprocess.PIPE if hide_stderr else None),
)
break
except EnvironmentError:
e = sys.exc_info()[1]
if e.errno == errno.ENOENT:
continue
if verbose:
print(""unable to run %s"" % dispcmd)
print(e)
return None, None
else:
if verbose:
print(""unable to find command, tried %s"" % (commands,))
return None, None
stdout = p.communicate()[0].strip().decode()
if p.returncode != 0:
if verbose:
print(""unable to run %s (error)"" % dispcmd)
print(""stdout was %s"" % stdout)
return None, p.returncode
return stdout, p.returncode
",[],0,[],/_version.py_run_command
188,/home/amandapotts/git/arkouda/arkouda/_version.py_versions_from_parentdir,"def versions_from_parentdir(parentdir_prefix, root, verbose):
""""""Try to determine the version from the parent directory name.
Source tarballs conventionally unpack into a directory that includes both
the project name and a version string. We will also support searching up
two directory levels for an appropriately named parent directory
""""""
rootdirs = []
for i in range(3):
dirname = os.path.basename(root)
if dirname.startswith(parentdir_prefix):
return {
""version"": dirname[len(parentdir_prefix) :],
""full-revisionid"": None,
""dirty"": False,
""error"": None,
""date"": None,
}
else:
rootdirs.append(root)
root = os.path.dirname(root)  # up a level
if verbose:
print(""Tried directories %s but none started with prefix %s"" % (str(rootdirs), parentdir_prefix))
raise NotThisMethod(""rootdir doesn't start with parentdir_prefix"")
",[],0,[],/_version.py_versions_from_parentdir
189,/home/amandapotts/git/arkouda/arkouda/_version.py_git_get_keywords,"def git_get_keywords(versionfile_abs):
""""""Extract version information from the given file.""""""
keywords = {}
try:
f = open(versionfile_abs, ""r"")
for line in f.readlines():
if line.strip().startswith(""git_refnames =""):
mo = re.search(r'=\s*""(.*)""', line)
if mo:
keywords[""refnames""] = mo.group(1)
if line.strip().startswith(""git_full =""):
mo = re.search(r'=\s*""(.*)""', line)
if mo:
keywords[""full""] = mo.group(1)
if line.strip().startswith(""git_date =""):
mo = re.search(r'=\s*""(.*)""', line)
if mo:
keywords[""date""] = mo.group(1)
f.close()
except EnvironmentError:
pass
return keywords
",[],0,[],/_version.py_git_get_keywords
190,/home/amandapotts/git/arkouda/arkouda/_version.py_git_versions_from_keywords,"def git_versions_from_keywords(keywords, tag_prefix, verbose):
""""""Get version information from git keywords.""""""
if not keywords:
raise NotThisMethod(""no keywords at all, weird"")
date = keywords.get(""date"")
if date is not None:
date = date.splitlines()[-1]
date = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)
refnames = keywords[""refnames""].strip()
if refnames.startswith(""$Format""):
if verbose:
print(""keywords are unexpanded, not using"")
raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")
refs = {r.strip() for r in refnames.strip(""()"").split("","")}
TAG = ""tag: ""
tags = {r[len(TAG) :] for r in refs if r.startswith(TAG)}
if not tags:
tags = {r for r in refs if re.search(r""\d"", r)}
if verbose:
print(""discarding '%s', no digits"" % "","".join(refs - tags))
if verbose:
print(""likely tags: %s"" % "","".join(sorted(tags)))
for ref in sorted(tags):
if ref.startswith(tag_prefix):
r = ref[len(tag_prefix) :]
if verbose:
print(""picking %s"" % r)
return {
""version"": r,
""full-revisionid"": keywords[""full""].strip(),
""dirty"": False,
""error"": None,
""date"": date,
}
if verbose:
print(""no suitable tags, using unknown + full revision id"")
return {
""version"": ""0+unknown"",
""full-revisionid"": keywords[""full""].strip(),
""dirty"": False,
""error"": ""no suitable tags"",
""date"": None,
}
",[],0,[],/_version.py_git_versions_from_keywords
191,/home/amandapotts/git/arkouda/arkouda/_version.py_git_pieces_from_vcs,"def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):
""""""Get version from 'git describe' in the root of the source tree.
This only gets called if the git-archive 'subst' keywords were *not*
expanded, and _version.py hasn't already been rewritten with a short
version string, meaning we're inside a checked out source tree.
""""""
GITS = [""git""]
if sys.platform == ""win32"":
GITS = [""git.cmd"", ""git.exe""]
out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root, hide_stderr=True)
if rc != 0:
if verbose:
print(""Directory %s not under git control"" % root)
raise NotThisMethod(""'git rev-parse --git-dir' returned error"")
describe_out, rc = run_command(
GITS,
[""describe"", ""--tags"", ""--dirty"", ""--always"", ""--long"", ""--match"", ""%s*"" % tag_prefix],
cwd=root,
)
if describe_out is None:
raise NotThisMethod(""'git describe' failed"")
describe_out = describe_out.strip()
full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)
if full_out is None:
raise NotThisMethod(""'git rev-parse' failed"")
full_out = full_out.strip()
pieces = {}
pieces[""long""] = full_out
pieces[""short""] = full_out[:7]  # maybe improved later
pieces[""error""] = None
git_describe = describe_out
dirty = git_describe.endswith(""-dirty"")
pieces[""dirty""] = dirty
if dirty:
git_describe = git_describe[: git_describe.rindex(""-dirty"")]
if ""-"" in git_describe:
mo = re.search(r""^(.+)-(\d+)-g([0-9a-f]+)$"", git_describe)
if not mo:
pieces[""error""] = ""unable to parse git-describe output: '%s'"" % describe_out
return pieces
full_tag = mo.group(1)
if not full_tag.startswith(tag_prefix):
if verbose:
fmt = ""tag '%s' doesn't start with prefix '%s'""
print(fmt % (full_tag, tag_prefix))
pieces[""error""] = ""tag '%s' doesn't start with prefix '%s'"" % (full_tag, tag_prefix)
return pieces
pieces[""closest-tag""] = full_tag[len(tag_prefix) :]
pieces[""distance""] = int(mo.group(2))
pieces[""short""] = mo.group(3)
else:
pieces[""closest-tag""] = None
count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""], cwd=root)
pieces[""distance""] = int(count_out)  # total number of commits
date = run_command(GITS, [""show"", ""-s"", ""--format=%ci"", ""HEAD""], cwd=root)[0].strip()
date = date.splitlines()[-1]
pieces[""date""] = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)
return pieces
",[],0,[],/_version.py_git_pieces_from_vcs
192,/home/amandapotts/git/arkouda/arkouda/_version.py_plus_or_dot,"def plus_or_dot(pieces):
""""""Return a + if we don't already have one, else return a .""""""
if ""+"" in pieces.get(""closest-tag"", """"):
return "".""
return ""+""
",[],0,[],/_version.py_plus_or_dot
193,/home/amandapotts/git/arkouda/arkouda/_version.py_render_pep440,"def render_pep440(pieces):
""""""Build up version string, with post-release ""local version identifier"".
Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you
get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty
Exceptions:
1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]
""""""
if pieces[""closest-tag""]:
rendered = pieces[""closest-tag""]
if pieces[""distance""] or pieces[""dirty""]:
rendered += plus_or_dot(pieces)
rendered += ""%d.g%s"" % (pieces[""distance""], pieces[""short""])
if pieces[""dirty""]:
rendered += "".dirty""
else:
rendered = ""0+untagged.%d.g%s"" % (pieces[""distance""], pieces[""short""])
if pieces[""dirty""]:
rendered += "".dirty""
return rendered
",[],0,[],/_version.py_render_pep440
194,/home/amandapotts/git/arkouda/arkouda/_version.py_render_pep440_pre,"def render_pep440_pre(pieces):
""""""TAG[.post0.devDISTANCE] -- No -dirty.
Exceptions:
1: no tags. 0.post0.devDISTANCE
""""""
if pieces[""closest-tag""]:
rendered = pieces[""closest-tag""]
if pieces[""distance""]:
rendered += "".post0.dev%d"" % pieces[""distance""]
else:
rendered = ""0.post0.dev%d"" % pieces[""distance""]
return rendered
",[],0,[],/_version.py_render_pep440_pre
195,/home/amandapotts/git/arkouda/arkouda/_version.py_render_pep440_post,"def render_pep440_post(pieces):
""""""TAG[.postDISTANCE[.dev0]+gHEX] .
The "".dev0"" means dirty. Note that .dev0 sorts backwards
(a dirty tree will appear ""older"" than the corresponding clean one),
but you shouldn't be releasing software with -dirty anyways.
Exceptions:
1: no tags. 0.postDISTANCE[.dev0]
""""""
if pieces[""closest-tag""]:
rendered = pieces[""closest-tag""]
if pieces[""distance""] or pieces[""dirty""]:
rendered += "".post%d"" % pieces[""distance""]
if pieces[""dirty""]:
rendered += "".dev0""
rendered += plus_or_dot(pieces)
rendered += ""g%s"" % pieces[""short""]
else:
rendered = ""0.post%d"" % pieces[""distance""]
if pieces[""dirty""]:
rendered += "".dev0""
rendered += ""+g%s"" % pieces[""short""]
return rendered
",[],0,[],/_version.py_render_pep440_post
196,/home/amandapotts/git/arkouda/arkouda/_version.py_render_pep440_old,"def render_pep440_old(pieces):
""""""TAG[.postDISTANCE[.dev0]] .
The "".dev0"" means dirty.
Exceptions:
1: no tags. 0.postDISTANCE[.dev0]
""""""
if pieces[""closest-tag""]:
rendered = pieces[""closest-tag""]
if pieces[""distance""] or pieces[""dirty""]:
rendered += "".post%d"" % pieces[""distance""]
if pieces[""dirty""]:
rendered += "".dev0""
else:
rendered = ""0.post%d"" % pieces[""distance""]
if pieces[""dirty""]:
rendered += "".dev0""
return rendered
",[],0,[],/_version.py_render_pep440_old
197,/home/amandapotts/git/arkouda/arkouda/_version.py_render_git_describe,"def render_git_describe(pieces):
""""""TAG[-DISTANCE-gHEX][-dirty].
Like 'git describe --tags --dirty --always'.
Exceptions:
1: no tags. HEX[-dirty]  (note: no 'g' prefix)
""""""
if pieces[""closest-tag""]:
rendered = pieces[""closest-tag""]
if pieces[""distance""]:
rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])
else:
rendered = pieces[""short""]
if pieces[""dirty""]:
rendered += ""-dirty""
return rendered
",[],0,[],/_version.py_render_git_describe
198,/home/amandapotts/git/arkouda/arkouda/_version.py_render_git_describe_long,"def render_git_describe_long(pieces):
""""""TAG-DISTANCE-gHEX[-dirty].
Like 'git describe --tags --dirty --always -long'.
The distance/hash is unconditional.
Exceptions:
1: no tags. HEX[-dirty]  (note: no 'g' prefix)
""""""
if pieces[""closest-tag""]:
rendered = pieces[""closest-tag""]
rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])
else:
rendered = pieces[""short""]
if pieces[""dirty""]:
rendered += ""-dirty""
return rendered
",[],0,[],/_version.py_render_git_describe_long
199,/home/amandapotts/git/arkouda/arkouda/_version.py_render,"def render(pieces, style):
""""""Render the given version pieces into the requested style.""""""
if pieces[""error""]:
return {
""version"": ""unknown"",
""full-revisionid"": pieces.get(""long""),
""dirty"": None,
""error"": pieces[""error""],
""date"": None,
}
if not style or style == ""default"":
style = ""pep440""  # the default
if style == ""pep440"":
rendered = render_pep440(pieces)
elif style == ""pep440-pre"":
rendered = render_pep440_pre(pieces)
elif style == ""pep440-post"":
rendered = render_pep440_post(pieces)
elif style == ""pep440-old"":
rendered = render_pep440_old(pieces)
elif style == ""git-describe"":
rendered = render_git_describe(pieces)
elif style == ""git-describe-long"":
rendered = render_git_describe_long(pieces)
else:
raise ValueError(""unknown style '%s'"" % style)
return {
""version"": rendered,
""full-revisionid"": pieces[""long""],
""dirty"": pieces[""dirty""],
""error"": None,
""date"": pieces.get(""date""),
}
",[],0,[],/_version.py_render
200,/home/amandapotts/git/arkouda/arkouda/_version.py_get_versions,"def get_versions():
""""""Get version information or return default if unable to do so.""""""
cfg = get_config()
verbose = cfg.verbose
try:
return git_versions_from_keywords(get_keywords(), cfg.tag_prefix, verbose)
except NotThisMethod:
pass
try:
root = os.path.realpath(__file__)
for i in cfg.versionfile_source.split(""/""):
root = os.path.dirname(root)
except NameError:
return {
""version"": ""0+unknown"",
""full-revisionid"": None,
""dirty"": None,
""error"": ""unable to find root of source tree"",
""date"": None,
}
try:
pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)
return render(pieces, cfg.style)
except NotThisMethod:
pass
try:
if cfg.parentdir_prefix:
return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)
except NotThisMethod:
pass
return {
""version"": ""0+unknown"",
""full-revisionid"": None,
""dirty"": None,
""error"": ""unable to compute version"",
""date"": None,
}
",[],0,[],/_version.py_get_versions
201,/home/amandapotts/git/arkouda/arkouda/array_view.py___init__,"def __init__(self, base: pdarray, shape, order=""row_major""):
self.shape = array(shape)
if not isinstance(self.shape, pdarray):
raise TypeError(f""ArrayView Shape cannot be type {type(self.shape)}. Expecting pdarray."")
if base.size != self.shape.prod():
raise ValueError(f""cannot reshape array of size {base.size} into shape {self.shape}"")
self.base = base
self.size = base.size
self.dtype = base.dtype
self.ndim = self.shape.size
self.itemsize = self.base.itemsize
if order.upper() in {""C"", ""ROW_MAJOR""}:
self.order = OrderType.ROW_MAJOR
elif order.upper() in {""F"", ""COLUMN_MAJOR""}:
self.order = OrderType.COLUMN_MAJOR
else:
raise ValueError(f""cannot traverse with order={order}"")
self._reverse_shape = self.shape if self.order is OrderType.COLUMN_MAJOR else self.shape[::-1]
if self.shape.min() == 0:
self._dim_prod = zeros(self.shape.size, self.dtype)
else:
self._dim_prod = (
cumprod(self.shape) // self.shape
if self.order is OrderType.COLUMN_MAJOR
else cumprod(self._reverse_shape) // self._reverse_shape
)
",[],0,[],/array_view.py___init__
202,/home/amandapotts/git/arkouda/arkouda/array_view.py___len__,"def __len__(self):
return self.size
",[],0,[],/array_view.py___len__
203,/home/amandapotts/git/arkouda/arkouda/array_view.py___repr__,"def __repr__(self):
from arkouda.client import pdarrayIterThresh
if self.size <= pdarrayIterThresh:
return self.to_ndarray().__repr__()
else:
edge_items = np.get_printoptions()[""edgeitems""]
vals = [f""'{self.base[i]}'"" for i in range(edge_items)]
vals.append(""... "")
vals.extend([f""'{self.base[i]}'"" for i in range(self.size - edge_items, self.size)])
return f""array([{', '.join(vals)}]), shape {self.shape}""
",['get_printoptions'],1,['get_printoptions()'],/array_view.py___repr__
204,/home/amandapotts/git/arkouda/arkouda/array_view.py___str__,"def __str__(self):
from arkouda.client import pdarrayIterThresh
if self.size <= pdarrayIterThresh:
return self.to_ndarray().__str__()
else:
edge_items = np.get_printoptions()[""edgeitems""]
vals = [f""'{self.base[i]}'"" for i in range(edge_items)]
vals.append(""... "")
vals.extend([f""'{self.base[i]}'"" for i in range(self.size - edge_items, self.size)])
return f""[{', '.join(vals)}], shape {self.shape}""
",['get_printoptions'],1,['get_printoptions()'],/array_view.py___str__
205,/home/amandapotts/git/arkouda/arkouda/array_view.py___getitem__,"def __getitem__(self, key):
if isinstance(key, int) or isinstance(key, slice):
key = [key]
elif isinstance(key, tuple):
key = list(key)
if len(key) > self.ndim:
raise IndexError(
f""too many indices for array: array is {self.ndim}-dimensional, ""
f""but {len(key)} were indexed""
)
if len(key) < self.ndim:
for i in range(self.ndim - len(key)):
key.append(slice(None, None, None))
try:
key = array(key)
except (RuntimeError, TypeError, ValueError, DeprecationWarning):
pass
if isinstance(key, pdarray):
kind, _ = translate_np_dtype(key.dtype)
if kind not in (""int"", ""uint"", ""bool""):
raise TypeError(f""unsupported pdarray index type {key.dtype}"")
if kind == ""bool"":
if key.all():
return self.base.reshape(
concatenate([ones(1, dtype=self.dtype), self.shape]), order=self.order.name
)
else:
return array([], dtype=self.dtype).reshape(
concatenate([zeros(1, dtype=self.dtype), self.shape]), order=self.order.name
)
key = where(key < 0, akcast(key + self.shape, kind), key)
out_of_bounds = (key < 0) | (self.shape <= key)
if out_of_bounds.any():
out = arange(key.size)[out_of_bounds][0]
raise IndexError(
f""index {key[out]} is out of bounds for axis {out} with size {self.shape[out]}""
)
coords = key if self.order is OrderType.COLUMN_MAJOR else key[::-1]
repMsg = generic_msg(
cmd=""arrayViewIntIndex"",
args={
""base"": self.base,
""dim_prod"": self._dim_prod,
""coords"": coords,
},
)
fields = repMsg.split()
return parse_single_value("" "".join(fields[1:]))
elif isinstance(key, list):
indices = []
reshape_dim_list = []
index_dim_list = []
key = key if self.order is OrderType.COLUMN_MAJOR else key[::-1]
for i in range(len(key)):
x = key[i]
if np.isscalar(x) and (resolve_scalar_dtype(x) in [""int64"", ""uint64""]):
orig_key = x
if x < 0:
x += self._reverse_shape[i]
if 0 <= x < self._reverse_shape[i]:
indices.append(""int"")
indices.append(json.dumps(int(x)))
index_dim_list.append(1)
else:
raise IndexError(
f""index {orig_key} is out of bounds for axis {i} ""
f""with size {self._reverse_shape[i]}""
)
elif isinstance(x, slice):
(start, stop, stride) = x.indices(self._reverse_shape[i])
indices.append(""slice"")
indices.append(json.dumps((start, stop, stride)))
slice_size = len(range(*(start, stop, stride)))
index_dim_list.append(slice_size)
reshape_dim_list.append(slice_size)
elif isinstance(x, pdarray) or isinstance(x, list):
raise TypeError(f""Advanced indexing is not yet supported {x} ({type(x)})"")
else:
raise TypeError(f""Unhandled key type: {x} ({type(x)})"")
index_dim = array(index_dim_list)
repMsg = generic_msg(
cmd=""arrayViewMixedIndex"",
args={
""base"": self.base,
""index_dim"": index_dim,
""ndim"": self.ndim,
""dim_prod"": self._dim_prod,
""coords"": indices,
},
)
reshape_dim = (
reshape_dim_list if self.order is OrderType.COLUMN_MAJOR else reshape_dim_list[::-1]
)
return create_pdarray(repMsg).reshape(reshape_dim, order=self.order.name)
else:
raise TypeError(f""Unhandled key type: {key} ({type(key)})"")
",['isscalar'],1,"['isscalar(x) and (resolve_scalar_dtype(x) in [""int64"", ""uint64""])']",/array_view.py___getitem__
206,/home/amandapotts/git/arkouda/arkouda/array_view.py___setitem__,"def __setitem__(self, key, value):
if isinstance(key, int) or isinstance(key, slice):
key = [key]
elif isinstance(key, tuple):
key = list(key)
if len(key) > self.ndim:
raise IndexError(
f""too many indices for array: array is {self.ndim}-dimensional, ""
f""but {len(key)} were indexed""
)
if len(key) < self.ndim:
for i in range(self.ndim - len(key)):
key.append(slice(None, None, None))
try:
key = array(key)
except (RuntimeError, TypeError, ValueError, DeprecationWarning):
pass
if isinstance(key, pdarray):
kind, _ = translate_np_dtype(key.dtype)
if kind not in (""int"", ""uint"", ""bool""):
raise TypeError(f""unsupported pdarray index type {key.dtype}"")
if kind == ""bool"":
if key.all():
self.base.fill(value)
else:
key = where(key < 0, akcast(key + self.shape, kind), key)
out_of_bounds = (key < 0) | (self.shape <= key)
if out_of_bounds.any():
out = arange(key.size)[out_of_bounds][0]
raise IndexError(
f""index {key[out]} is out of bounds for axis {out} with size {self.shape[out]}""
)
coords = key if self.order is OrderType.COLUMN_MAJOR else key[::-1]
generic_msg(
cmd=""arrayViewIntIndexAssign"",
args={
""base"": self.base,
""dtype"": self.dtype,
""dim_prod"": self._dim_prod,
""coords"": coords,
""value"": self.base.format_other(value),
},
)
elif isinstance(key, list):
raise NotImplementedError(""Setting via slicing and advanced indexing is not yet supported"")
else:
raise TypeError(f""Unhandled key type: {key} ({type(key)})"")
",[],0,[],/array_view.py___setitem__
207,/home/amandapotts/git/arkouda/arkouda/array_view.py_to_ndarray,"def to_ndarray(self) -> np.ndarray:
""""""
Convert the ArrayView to a np.ndarray, transferring array data from the
Arkouda server to client-side Python. Note: if the ArrayView size exceeds
client.maxTransferBytes, a RuntimeError is raised.
Returns
-------
np.ndarray
A numpy ndarray with the same attributes and data as the ArrayView
Raises
------
RuntimeError
Raised if there is a server-side error thrown, if the ArrayView size
exceeds the built-in client.maxTransferBytes size limit, or if the bytes
received does not match expected number of bytes
Notes
-----
The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
otherwise a ``RuntimeError`` will be raised. This is to protect the user
from overflowing the memory of the system on which the Python client
is running, under the assumption that the server is running on a
distributed system with much more memory than the client. The user
may override this limit by setting client.maxTransferBytes to a larger
value, but proceed with caution.
See Also
--------
array()
to_list()
Examples
--------
>>> a = ak.arange(6).reshape(2,3)
>>> a.to_ndarray()
array([[0, 1, 2],
[3, 4, 5]])
>>> type(a.to_ndarray())
numpy.ndarray
""""""
if self.order is OrderType.ROW_MAJOR:
return self.base.to_ndarray().reshape(self.shape.to_ndarray())
else:
return self.base.to_ndarray().reshape(self.shape.to_ndarray(), order=""F"")
","['ndarray', 'ndarray', 'ndarray']",3,[],/array_view.py_to_ndarray
208,/home/amandapotts/git/arkouda/arkouda/array_view.py_to_list,"def to_list(self) -> list:
""""""
Convert the ArrayView to a list, transferring array data from the
Arkouda server to client-side Python. Note: if the ArrayView size exceeds
client.maxTransferBytes, a RuntimeError is raised.
Returns
-------
list
A list with the same data as the ArrayView
Raises
------
RuntimeError
Raised if there is a server-side error thrown, if the ArrayView size
exceeds the built-in client.maxTransferBytes size limit, or if the bytes
received does not match expected number of bytes
Notes
-----
The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
otherwise a ``RuntimeError`` will be raised. This is to protect the user
from overflowing the memory of the system on which the Python client
is running, under the assumption that the server is running on a
distributed system with much more memory than the client. The user
may override this limit by setting client.maxTransferBytes to a larger
value, but proceed with caution.
See Also
--------
to_ndarray()
Examples
--------
>>> a = ak.arange(6).reshape(2,3)
>>> a.to_list()
[[0, 1, 2], [3, 4, 5]]
>>> type(a.to_list())
list
""""""
return self.to_ndarray().tolist()
",[],0,[],/array_view.py_to_list
209,/home/amandapotts/git/arkouda/arkouda/array_view.py_to_hdf,"def to_hdf(
self,
prefix_path: str,
dataset: str = ""ArrayView"",
mode: str = ""truncate"",
file_type: str = ""distribute"",
",[],0,[],/array_view.py_to_hdf
210,/home/amandapotts/git/arkouda/arkouda/array_view.py_update_hdf,"def update_hdf(
self,
prefix_path: str,
dataset: str = ""ArrayView"",
repack: bool = True,
",[],0,[],/array_view.py_update_hdf
211,/home/amandapotts/git/arkouda/arkouda/row.py___str__,"def __str__(self):
""""""
Return ascii-formatted version of the dataframe.
""""""
return tabulate(self.items(), headers=[""keys"", ""values""], showindex=False)
",[],0,[],/row.py___str__
212,/home/amandapotts/git/arkouda/arkouda/row.py___repr__,"def __repr__(self):
return dict(self).__repr__()
",[],0,[],/row.py___repr__
213,/home/amandapotts/git/arkouda/arkouda/row.py__repr_html_,"def _repr_html_(self):
""""""
Return html-formatted version of the dataframe.
""""""
headers = [""keys"", ""values""]
return tabulate(self.items(), headers=headers, tablefmt=""html"", showindex=False)
",[],0,[],/row.py__repr_html_
214,/home/amandapotts/git/arkouda/arkouda/message.py___str__,"def __str__(self) -> str:
""""""
Overridden method returns value, which is useful in outputting
a MessageType object to JSON.
""""""
return self.value
",[],0,[],/message.py___str__
215,/home/amandapotts/git/arkouda/arkouda/message.py___repr__,"def __repr__(self) -> str:
""""""
Overridden method returns value, which is useful in outputting
a MessageType object to JSON.
""""""
return self.value
",[],0,[],/message.py___repr__
216,/home/amandapotts/git/arkouda/arkouda/message.py___init__,"def __init__(self, key, objType, dtype, val):
object.__setattr__(self, ""key"", key)
object.__setattr__(self, ""objType"", objType)
object.__setattr__(self, ""dtype"", dtype)
object.__setattr__(self, ""val"", val)
",[],0,[],/message.py___init__
217,/home/amandapotts/git/arkouda/arkouda/message.py_dict,"def dict(self):
return {
""key"": self.key,
""objType"": str(self.objType),
""dtype"": self.dtype,
""val"": self.val,
}
",[],0,[],/message.py_dict
218,/home/amandapotts/git/arkouda/arkouda/message.py__build_pdarray_param,"def _build_pdarray_param(key: str, val) -> ParameterObject:
""""""
Create a ParameterObject from a pdarray value
Parameters
----------
key : str
key from the dictionary object
val
pdarray object ot load from the symbol table
Returns
-------
ParameterObject
""""""
return ParameterObject(key, ObjectType.PDARRAY, str(val.dtype), val.name)
",[],0,[],/message.py__build_pdarray_param
219,/home/amandapotts/git/arkouda/arkouda/message.py__build_strings_param,"def _build_strings_param(key: str, val) -> ParameterObject:
""""""
Create a ParameterObject from a Strings value
Parameters
----------
key : str
key from the dictionary object
val
Strings object ot load from the symbol table
Returns
-------
ParameterObject
""""""
name = val.name if val.name else """"
return ParameterObject(key, ObjectType.STRINGS, ""str"", name)
",[],0,[],/message.py__build_strings_param
220,/home/amandapotts/git/arkouda/arkouda/message.py__build_segarray_param,"def _build_segarray_param(key: str, val) -> ParameterObject:
""""""
Create a ParameterObject from a SegArray value
Parameters
----------
key : str
key from the dictionary object
val
SegArray object to load from the symbol table
Returns
-------
ParameterObject
""""""
data = json.dumps({""segments"": val.segments.name, ""values"": val.values.name})
return ParameterObject(key, ObjectType.SEGARRAY, str(val.values.dtype), data)
",[],0,[],/message.py__build_segarray_param
221,/home/amandapotts/git/arkouda/arkouda/message.py__is_supported_value,"def _is_supported_value(val):
import builtins
import numpy as np
return isinstance(val, (str, np.str_, builtins.bool, np.bool_)) or isSupportedNumber(val)
","['str_', 'bool_']",2,[],/message.py__is_supported_value
222,/home/amandapotts/git/arkouda/arkouda/message.py__format_param,"def _format_param(p):
from arkouda.segarray import SegArray
return (
json.dumps({""segments"": p.segments.name, ""values"": p.values.name})
if isinstance(p, SegArray)
else p.name
)
",[],0,[],/message.py__format_param
223,/home/amandapotts/git/arkouda/arkouda/message.py__build_list_param,"def _build_list_param(key: str, val: list) -> ParameterObject:
""""""
Create a ParameterObject from a list
Parameters
----------
key : str
key from the dictionary object
val : list
list object to format as string
Returns
-------
ParameterObject
""""""
from arkouda.pdarrayclass import pdarray
from arkouda.segarray import SegArray
from arkouda.strings import Strings
dtypes = {
resolve_scalar_dtype(p) if ParameterObject._is_supported_value(p) else type(p).__name__
for p in val
}
if len(dtypes) == 1:
t = dtypes.pop()
else:
for p in val:
if not (
isinstance(p, (pdarray, Strings, SegArray)) or ParameterObject._is_supported_value(p)
):
raise TypeError(
f""List parameters must be pdarray, Strings, SegArray, str or a type ""
f""that inherits from the aforementioned. {type(p).__name__} ""
f""does not meet that criteria.""
)
t = ""mixed""
data = [
str(p) if ParameterObject._is_supported_value(p) else ParameterObject._format_param(p)
for p in val
]
return ParameterObject(key, ObjectType.LIST, t, json.dumps(data))
",[],0,[],/message.py__build_list_param
224,/home/amandapotts/git/arkouda/arkouda/message.py__build_dict_param,"def _build_dict_param(key: str, val: Dict) -> ParameterObject:
j = []
for k, v in val.items():
if not isinstance(k, str):
raise TypeError(f""Argument keys are required to be str. Found {type(k)}"")
param = ParameterObject.factory(k, v)
j.append(json.dumps(param.dict))
return ParameterObject(key, ObjectType.DICT, str(dict.__name__), json.dumps(j))
",[],0,[],/message.py__build_dict_param
225,/home/amandapotts/git/arkouda/arkouda/message.py__build_gen_param,"def _build_gen_param(key: str, val) -> ParameterObject:
""""""
Create a ParameterObject from a single value
Parameters
----------
key : str
key from the dictionary object
val
singular value to use. This could be str, int, float, etc
Returns
-------
ParameterObject
""""""
v = val if isinstance(val, str) else str(val)
return ParameterObject(key, ObjectType.VALUE, resolve_scalar_dtype(val), v)
",[],0,[],/message.py__build_gen_param
226,/home/amandapotts/git/arkouda/arkouda/message.py_generate_dispatch,"def generate_dispatch() -> Dict:
""""""
Builds and returns the dispatch table used to build parameter object.
Returns
-------
Dictionary - mapping the parameter type to the build function
""""""
from arkouda.segarray import SegArray
from arkouda.strings import Strings
return {
Strings.__name__: ParameterObject._build_strings_param,
SegArray.__name__: ParameterObject._build_segarray_param,
list.__name__: ParameterObject._build_list_param,
dict.__name__: ParameterObject._build_dict_param,
}
",[],0,[],/message.py_generate_dispatch
227,/home/amandapotts/git/arkouda/arkouda/message.py_factory,"def factory(cls, key: str, val) -> ParameterObject:
""""""
Factory method used to build ParameterObject given a key value pair
Parameters
----------
key : str
key from the dictionary object
val
the value corresponding to the provided key from the dictionary
Returns
--------
ParameterObject - The parameter object formatted to be parsed by the chapel server
""""""
from arkouda.pdarrayclass import pdarray
dispatch = ParameterObject.generate_dispatch()
if isinstance(
val, pdarray
):  # this is done here to avoid multiple dispatch entries for the same type
return cls._build_pdarray_param(key, val)
elif (f := dispatch.get(type(val).__name__)) is not None:
return f(key, val)
else:
return ParameterObject._build_gen_param(key, val)
",[],0,[],/message.py_factory
228,/home/amandapotts/git/arkouda/arkouda/message.py___str__,"def __str__(self) -> str:
""""""
Overridden method returns value, which is useful in outputting
a MessageFormat object to JSON.
""""""
return self.value
",[],0,[],/message.py___str__
229,/home/amandapotts/git/arkouda/arkouda/message.py___repr__,"def __repr__(self) -> str:
""""""
Overridden method returns value, which is useful in outputting
a MessageFormat object to JSON.
""""""
return self.value
",[],0,[],/message.py___repr__
230,/home/amandapotts/git/arkouda/arkouda/message.py___str__,"def __str__(self) -> str:
""""""
Overridden method returns value, which is useful in outputting
a MessageType object to JSON.
""""""
return self.value
",[],0,[],/message.py___str__
231,/home/amandapotts/git/arkouda/arkouda/message.py___repr__,"def __repr__(self) -> str:
""""""
Overridden method returns value, which is useful in outputting
a MessageType object to JSON.
""""""
return self.value
",[],0,[],/message.py___repr__
232,/home/amandapotts/git/arkouda/arkouda/message.py___init__,"def __init__(
self,
user: str,
cmd: str,
token: str = None,
format: MessageFormat = MessageFormat.STRING,
args: str = None,
size: int = -1,
",[],0,[],/message.py___init__
233,/home/amandapotts/git/arkouda/arkouda/message.py_asdict,"def asdict(self) -> Dict:
""""""
Overridden asdict implementation sets the values of non-required
fields to an empty space (for Chapel JSON processing) and invokes
str() on the format instance attribute.
Returns
-------
Dict
A dict object encapsulating ReplyMessage state
""""""
args = self.args if self.args else """"
token = self.token if self.token else """"
return {
""user"": self.user,
""token"": token,
""cmd"": self.cmd,
""format"": str(self.format),
""args"": args,
""size"": self.size,
}
",[],0,[],/message.py_asdict
234,/home/amandapotts/git/arkouda/arkouda/message.py_fromdict,"def fromdict(values: Dict) -> ReplyMessage:
""""""
Generates a ReplyMessage from a dict encapsulating the data and
metadata from a reply returned by the Arkouda server.
Parameters
----------
values : Dict
The dict object encapsulating the fields required to instantiate
a ReplyMessage
Returns
-------
ReplyMessage
The ReplyMessage composed of values encapsulated within values dict
Raises
------
ValueError
Raised if the values Dict is missing fields or contains malformed values
""""""
try:
return ReplyMessage(
msg=values[""msg""], msgType=MessageType(values[""msgType""]), user=values[""user""]
)
except KeyError as ke:
raise ValueError(f""values dict missing {ke} field"")
",[],0,[],/message.py_fromdict
235,/home/amandapotts/git/arkouda/arkouda/matcher.py___init__,"def __init__(self, pattern: str_scalars, parent_entry_name: str) -> None:
self.objType = type(self).__name__
try:
self.pattern = pattern
re.compile(self.pattern)
except Exception as e:
raise ValueError(e)
self.parent_entry_name = parent_entry_name
self.num_matches: pdarray
self.starts: pdarray
self.lengths: pdarray
self.indices: pdarray
self.search_bool: pdarray
self.search_ind: pdarray
self.match_bool: pdarray
self.match_ind: pdarray
self.full_match_bool: pdarray
self.full_match_ind: pdarray
self.populated = False
self.logger = getArkoudaLogger(name=__class__.__name__)  # type: ignore
",[],0,[],/matcher.py___init__
236,/home/amandapotts/git/arkouda/arkouda/matcher.py_find_locations,"def find_locations(self) -> None:
""""""
Populates Matcher object by finding the positions of matches
""""""
sym_tab = list_symbol_table()
if not self.populated or any(
[getattr(self, pda).name not in sym_tab for pda in self.LocationsInfo]
):
repMsg = cast(
str,
generic_msg(
cmd=""segmentedFindLoc"",
args={
""objType"": self.objType,
""parent_name"": self.parent_entry_name,
""groupNum"": 0,  # groupNum is 0 for regular matches
""pattern"": self.pattern,
},
),
)
created_map = json.loads(repMsg)
self.num_matches = create_pdarray(created_map[""NumMatches""])
self.starts = create_pdarray(created_map[""Starts""])
self.lengths = create_pdarray(created_map[""Lens""])
self.indices = create_pdarray(created_map[""Indices""])
self.search_bool = create_pdarray(created_map[""SearchBool""])
self.search_ind = create_pdarray(created_map[""SearchInd""])
self.match_bool = create_pdarray(created_map[""MatchBool""])
self.match_ind = create_pdarray(created_map[""MatchInd""])
self.full_match_bool = create_pdarray(created_map[""FullMatchBool""])
self.full_match_ind = create_pdarray(created_map[""FullMatchInd""])
self.populated = True
",[],0,[],/matcher.py_find_locations
237,/home/amandapotts/git/arkouda/arkouda/matcher.py_get_match,"def get_match(self, match_type: MatchType, parent: object = None) -> Match:
""""""
Create a Match object of type match_type
""""""
self.find_locations()
if match_type == MatchType.SEARCH:
matched = self.search_bool
indices = self.search_ind
elif match_type == MatchType.MATCH:
matched = self.match_bool
indices = self.match_ind
elif match_type == MatchType.FULLMATCH:
matched = self.full_match_bool
indices = self.full_match_ind
else:
raise ValueError(f""{match_type} is not a MatchType"")
match = Match(
matched=matched,
starts=self.starts[self.indices[matched]],
lengths=self.lengths[self.indices[matched]],
indices=indices,
parent_entry_name=self.parent_entry_name,
match_type=match_type,
pattern=self.pattern,
)
match._parent_obj = parent
return match
",[],0,[],/matcher.py_get_match
238,/home/amandapotts/git/arkouda/arkouda/matcher.py_split,"def split(self, maxsplit: int = 0, return_segments: bool = False):
""""""
Split string by the occurrences of pattern. If maxsplit is nonzero, at most maxsplit splits occur
""""""
from arkouda.strings import Strings
if re.search(self.pattern, """"):
raise ValueError(""Cannot split or flatten with a pattern that matches the empty string"")
cmd = ""segmentedSplit""
repMsg = cast(
str,
generic_msg(
cmd=cmd,
args={
""parent_name"": self.parent_entry_name,
""objtype"": self.objType,
""max"": maxsplit,
""return_segs"": return_segments,
""pattern"": self.pattern,
},
),
)
if return_segments:
arrays = repMsg.split(""+"", maxsplit=2)
return Strings.from_return_msg(""+"".join(arrays[0:2])), create_pdarray(arrays[2])
else:
return Strings.from_return_msg(repMsg)
",[],0,[],/matcher.py_split
239,/home/amandapotts/git/arkouda/arkouda/matcher.py_findall,"def findall(self, return_match_origins: bool = False):
""""""
Return all non-overlapping matches of pattern in Strings as a new Strings object
""""""
from arkouda.strings import Strings
self.find_locations()
repMsg = cast(
str,
generic_msg(
cmd=""segmentedFindAll"",
args={
""objType"": self.objType,
""parent_name"": self.parent_entry_name,
""num_matches"": self.num_matches,
""starts"": self.starts,
""lengths"": self.lengths,
""indices"": self.indices,
""rtn_origins"": return_match_origins,
},
),
)
if return_match_origins:
arrays = repMsg.split(""+"", maxsplit=2)
return Strings.from_return_msg(""+"".join(arrays[0:2])), create_pdarray(arrays[2])
else:
return Strings.from_return_msg(repMsg)
",[],0,[],/matcher.py_findall
240,/home/amandapotts/git/arkouda/arkouda/matcher.py_sub,"def sub(self, repl: str, count: int = 0, return_num_subs: bool = False):
""""""
Return the Strings obtained by replacing non-overlapping occurrences of pattern
with the replacement repl.
If count is nonzero, at most count substitutions occur
If return_num_subs is True, return the number of substitutions that occurred
""""""
from arkouda.strings import Strings
repMsg = cast(
str,
generic_msg(
cmd=""segmentedSub"",
args={
""objType"": self.objType,
""obj"": self.parent_entry_name,
""repl"": repl,
""count"": count,
""rtn_num_subs"": return_num_subs,
""pattern"": self.pattern,
},
),
)
if return_num_subs:
arrays = repMsg.split(""+"", maxsplit=2)
return Strings.from_return_msg(""+"".join(arrays[0:2])), create_pdarray(arrays[2])
else:
return Strings.from_return_msg(repMsg)
",[],0,[],/matcher.py_sub
241,/home/amandapotts/git/arkouda/arkouda/client.py__mem_get_factor,"def _mem_get_factor(unit: str) -> int:
unit = unit.lower()
if unit in _memunit2factor:
return _memunit2factor[unit]
else:
for key, normunit in _memunit2normunit.items():
if key.startswith(unit):
return _memunit2factor[normunit]
raise ValueError(
f""Argument must be one of {set(_memunit2factor.keys()) | set(_memunit2normunit.keys())}""
)
",[],0,[],/client.py__mem_get_factor
242,/home/amandapotts/git/arkouda/arkouda/client.py___str__,"def __str__(self) -> str:
""""""
Overridden method returns value.
""""""
return self.value
",[],0,[],/client.py___str__
243,/home/amandapotts/git/arkouda/arkouda/client.py___repr__,"def __repr__(self) -> str:
""""""
Overridden method returns value.
""""""
return self.value
",[],0,[],/client.py___repr__
244,/home/amandapotts/git/arkouda/arkouda/client.py___str__,"def __str__(self) -> str:
""""""
Overridden method returns value.
""""""
return self.value
",[],0,[],/client.py___str__
245,/home/amandapotts/git/arkouda/arkouda/client.py___repr__,"def __repr__(self) -> str:
""""""
Overridden method returns value.
""""""
return self.value
",[],0,[],/client.py___repr__
246,/home/amandapotts/git/arkouda/arkouda/client.py___str__,"def __str__(self) -> str:
""""""
Overridden method returns value.
""""""
return self.value
",[],0,[],/client.py___str__
247,/home/amandapotts/git/arkouda/arkouda/client.py___repr__,"def __repr__(self) -> str:
""""""
Overridden method returns value.
""""""
return self.value
",[],0,[],/client.py___repr__
248,/home/amandapotts/git/arkouda/arkouda/client.py___str__,"def __str__(self) -> str:
""""""
Overridden method returns value.
""""""
return self.value
",[],0,[],/client.py___str__
249,/home/amandapotts/git/arkouda/arkouda/client.py___repr__,"def __repr__(self) -> str:
""""""
Overridden method returns value.
""""""
return self.value
",[],0,[],/client.py___repr__
250,/home/amandapotts/git/arkouda/arkouda/client.py_get_shell_mode,"def get_shell_mode():
""""""
Determines the Python shell type and returns the corresponding
ShellMode enum.
Returns
-------
ShellMode
The shell mode corresponding to a Python shell, Jupyter notebook,
or IPython notebook
""""""
shell_mode = None
try:
shell_mode = ShellMode(get_ipython().__class__.__name__)
except NameError:
shell_mode = ShellMode.REPL_SHELL
finally:
return shell_mode
",[],0,[],/client.py_get_shell_mode
251,/home/amandapotts/git/arkouda/arkouda/client.py_set_defaults,"def set_defaults() -> None:
""""""
Sets client variables including verbose, maxTransferBytes and
pdarrayIterThresh to default values.
Returns
-------
None
""""""
global verbose, maxTransferBytes, pdarrayIterThresh
verbose = verboseDefVal
pdarrayIterThresh = pdarrayIterThreshDefVal
maxTransferBytes = maxTransferBytesDefVal
",[],0,[],/client.py_set_defaults
252,/home/amandapotts/git/arkouda/arkouda/client.py___str__,"def __str__(self) -> str:
""""""
Overridden method returns value.
""""""
return self.value
",[],0,[],/client.py___str__
253,/home/amandapotts/git/arkouda/arkouda/client.py___repr__,"def __repr__(self) -> str:
""""""
Overridden method returns value.
""""""
return self.value
",[],0,[],/client.py___repr__
254,/home/amandapotts/git/arkouda/arkouda/client.py___init__,"def __init__(
self,
user: str,
server: str = ""localhost"",
port: int = 5555,
token: str = None,
connect_url: str = None,
",[],0,[],/client.py___init__
255,/home/amandapotts/git/arkouda/arkouda/client.py__set_url,"def _set_url(self, server: str, port: int, connect_url: str = None) -> None:
""""""
If the connect_url is None, generates and sets the Channel url per the
Channel protocol as well as host and port. Otherwise, sets the Channel url
to the supplied connect_url value.
Parameters
----------
server : str
Arkouda server hostname, ip address, or service name
port : int
Arkouda server host port
connect_url : str, optional
The complete url in the format of tcp://server:port?token=<token_value>
where the token is optional
Returns
-------
None
""""""
self.url = connect_url if connect_url else f""tcp://{server}:{port}""
",[],0,[],/client.py__set_url
256,/home/amandapotts/git/arkouda/arkouda/client.py__set_access_token,"def _set_access_token(self, server: str, port: int, token: Optional[str]) -> None:
""""""
Sets the token for the Channel by doing the following:
1. retrieves the token configured for the connect_string from the
.arkouda/tokens.txt file, if any
2. if token is None, returns the retrieved token
3. if token is not None, replaces retrieved token with the token to account
for situations where the token can change for a url (for example,
the arkouda_server is restarted and a corresponding new token is generated).
Parameters
----------
server : str
The hostname of the server (must be visible to the current machine)
port : int
The port of the server
username : str
The username retrieved from the user's home directory
token : str, optional
The token supplied by the user, which is required if authentication
is enabled, defaults to None
Returns
-------
None
Raises
------
IOError
If there's an error writing host:port -> access_token mapping to
the user's tokens.txt file or retrieving the user's tokens
""""""
path = f""{security.get_arkouda_client_directory()}/tokens.txt""
url = f""{server}:{port}""
try:
tokens = io_util.delimited_file_to_dict(path)
except Exception as e:
raise IOError(e)
if cast(str, token) and cast(str, token) not in {"""", ""None""}:
saved_token = tokens.get(url)
if saved_token is None or saved_token != token:
tokens[url] = cast(str, token)
try:
io_util.dict_to_delimited_file(values=tokens, path=path, delimiter="","")
except Exception as e:
raise IOError(e)
self.token = token
else:
try:
tokens = io_util.delimited_file_to_dict(path)
except Exception as e:
raise IOError(e)
self.token = tokens.get(url)
",[],0,[],/client.py__set_access_token
257,/home/amandapotts/git/arkouda/arkouda/client.py_send_string_message,"def send_string_message(
self,
cmd: str,
recv_binary: bool = False,
args: str = None,
size: int = -1,
request_id: str = None,
",[],0,[],/client.py_send_string_message
258,/home/amandapotts/git/arkouda/arkouda/client.py_send_binary_message,"def send_binary_message(
self,
cmd: str,
payload: memoryview,
recv_binary: bool = False,
args: str = None,
size: int = -1,
request_id: str = None,
",[],0,[],/client.py_send_binary_message
259,/home/amandapotts/git/arkouda/arkouda/client.py_connect,"def connect(self, timeout: int = 0) -> None:
""""""
Establishes a connection to the Arkouda server
Parameters
----------
timeout : int
Connection timeout
Raises
------
RuntimeError
Raised if the return message contains the word ""Error"", indicating
a server-side error was thrown
""""""
raise NotImplementedError(""connect must be implemented in derived class"")
",[],0,[],/client.py_connect
260,/home/amandapotts/git/arkouda/arkouda/client.py_disconnect,"def disconnect(self) -> None:
""""""
Disconnects from the Arkouda server
Raises
------
RuntimeError
Raised if the return message contains the word ""Error"", indicating
a server-side error was thrown
""""""
raise NotImplementedError(""connect must be implemented in derived class"")
",[],0,[],/client.py_disconnect
261,/home/amandapotts/git/arkouda/arkouda/client.py_send_string_message,"def send_string_message(
self,
cmd: str,
recv_binary: bool = False,
args: str = None,
size: int = -1,
request_id: str = None,
",[],0,[],/client.py_send_string_message
262,/home/amandapotts/git/arkouda/arkouda/client.py_send_binary_message,"def send_binary_message(
self,
cmd: str,
payload: memoryview,
recv_binary: bool = False,
args: str = None,
size: int = -1,
request_id: str = None,
",[],0,[],/client.py_send_binary_message
263,/home/amandapotts/git/arkouda/arkouda/client.py_connect,"def connect(self, timeout: int = 0) -> None:
import zmq  # type: ignore
context = zmq.Context()
self.socket = context.socket(zmq.REQ)
logger.debug(f""ZMQ version: {zmq.zmq_version()}"")
if timeout > 0:
self.socket.setsockopt(zmq.SNDTIMEO, timeout * 1000)
self.socket.setsockopt(zmq.RCVTIMEO, timeout * 1000)
try:
self.socket.connect(self.url)
except Exception as e:
raise ConnectionError(e)
",[],0,[],/client.py_connect
264,/home/amandapotts/git/arkouda/arkouda/client.py_disconnect,"def disconnect(self) -> None:
try:
self.socket.disconnect(self.url)
except Exception as e:
raise RuntimeError(e)
",[],0,[],/client.py_disconnect
265,/home/amandapotts/git/arkouda/arkouda/client.py_get_channel,"def get_channel(
server: str = ""localhost"", port: int = 5555, token: str = None, connect_url: str = None
",[],0,[],/client.py_get_channel
266,/home/amandapotts/git/arkouda/arkouda/client.py_connect,"def connect(
server: str = ""localhost"",
port: int = 5555,
timeout: int = 0,
access_token: str = None,
connect_url: str = None,
access_channel: Channel = None,
",[],0,[],/client.py_connect
267,/home/amandapotts/git/arkouda/arkouda/client.py__parse_url,"def _parse_url(url: str) -> Tuple[str, int, Optional[str]]:
""""""
Parses the url in the following format if authentication enabled:
tcp://<hostname/url>:<port>?token=<token>
If authentication is not enabled, the url is expected to be in the format:
tcp://<hostname/url>:<port>
Parameters
----------
url : str
The url string
Returns
-------
Tuple[str,int,Optional[str]]
A tuple containing the host, port, and token, the latter of which is None
if authentication is not enabled for the Arkouda server being accessed
Raises
------
ValueError
if the url does not match one of the above formats, if the port is not an
integer, or if there's a general string parse error raised in the parsing
of the url parameter
""""""
try:
no_protocol_stub = url.split(""tcp://"")
if len(no_protocol_stub) < 2:
raise ValueError(
""url must be in form tcp://<hostname/url>:<port> or ""
""tcp://<hostname/url>:<port>?token=<token>""
)
host_stub = no_protocol_stub[1].split("":"")
if len(host_stub) < 2:
raise ValueError(
""url must be in form tcp://<hostname/url>:<port> or ""
""tcp://<hostname/url>:<port>?token=<token>""
)
host = host_stub[0]
port_stub = host_stub[1]
if ""?token="" in port_stub:
port_token_stub = port_stub.split(""?token="")
return (host, int(port_token_stub[0]), port_token_stub[1])
else:
return (host, int(port_stub), None)
except Exception as e:
raise ValueError(e)
",[],0,[],/client.py__parse_url
268,/home/amandapotts/git/arkouda/arkouda/client.py__start_tunnel,"def _start_tunnel(addr: str, tunnel_server: str) -> Tuple[str, object]:
""""""
Starts ssh tunnel
Parameters
----------
tunnel_server : str
The ssh server url
Returns
-------
str
The new tunneled-version of connect string
object
The ssh tunnel object
Raises
------
ConnectionError
If the ssh tunnel could not be created given the tunnel_server
url and credentials (either password or key file)
""""""
from zmq import ssh
kwargs = {""addr"": addr, ""server"": tunnel_server}
keyfile = os.getenv(""ARKOUDA_KEY_FILE"")
password = os.getenv(""ARKOUDA_PASSWORD"")
if keyfile:
kwargs[""keyfile""] = keyfile
if password:
kwargs[""password""] = password
try:
return ssh.tunnel.open_tunnel(**kwargs)
except Exception as e:
raise ConnectionError(e)
",[],0,[],/client.py__start_tunnel
269,/home/amandapotts/git/arkouda/arkouda/client.py_disconnect,"def disconnect() -> None:
""""""
Disconnects the client from the Arkouda server
Returns
-------
None
Raises
------
ConnectionError
Raised if there's an error disconnecting from the Arkouda server
""""""
global connected, serverConfig, verbose
if connected:
message = ""disconnect""
logger.debug(f""[Python] Sending request: {message}"")
return_message = cast(str, cast(Channel, channel).send_string_message(message))
logger.debug(f""[Python] Received response: {return_message}"")
try:
cast(Channel, channel).disconnect()
except Exception as e:
raise ConnectionError(e)
connected = False
serverConfig = None
clientLogger.info(return_message)
else:
clientLogger.info(""not connected
",[],0,[],/client.py_disconnect
270,/home/amandapotts/git/arkouda/arkouda/client.py_shutdown,"def shutdown() -> None:
""""""
Sends a shutdown message to the Arkouda server that does the
following:
1. Delete all objects in the SymTable
2. Shuts down the Arkouda server
3. Disconnects the client from the stopped Arkouda Server
Returns
-------
None
Raises
------
RuntimeError
Raised if the client is not connected to the Arkouda server or
there is an error in disconnecting from the server
""""""
global socket, pspStr, connected, serverConfig, verbose
if not connected:
raise RuntimeError(""not connected, cannot shutdown server"")
message = ""shutdown""
logger.debug(f""[Python] Sending request: {message}"")
return_message = cast(str, cast(Channel, channel).send_string_message(message))
logger.debug(f""[Python] Received response: {return_message}"")
try:
cast(Channel, channel).disconnect()
except Exception as e:
raise RuntimeError(e)
connected = False
serverConfig = None
",[],0,[],/client.py_shutdown
271,/home/amandapotts/git/arkouda/arkouda/client.py__json_args_to_str,"def _json_args_to_str(json_obj: Dict = None) -> Tuple[int, str]:
""""""
Convert Python Dictionary into a JSON formatted string that can be parsed by the msg
processing system on the Arkouda Server
Parameters
----------
json_obj : dict
Python dictionary of key:val representing command arguments
Return
------
Tuple - the number of parameters found and the json formatted string
Raises
------
TypeError
- Keys are a type other than str
- Any value is a dictionary.
- A list contains values of multiple types.
Notes
-----
- Nested dictionaries are not yet supported, but are planned for future support.
- Support for lists of pdarray or Strings objects does not yet exist.
""""""
j: List[str] = []
if json_obj is None:
return 0, json.dumps(j)
for key, val in json_obj.items():
if not isinstance(key, str):
raise TypeError(f""Argument keys are required to be str. Found {type(key)}"")
param = ParameterObject.factory(key, val)
j.append(json.dumps(param.dict))
return len(j), json.dumps(j)
",[],0,[],/client.py__json_args_to_str
272,/home/amandapotts/git/arkouda/arkouda/client.py_generic_msg,"def generic_msg(
cmd: str,
args: Dict = None,
payload: memoryview = None,
send_binary: bool = False,
recv_binary: bool = False,
",[],0,[],/client.py_generic_msg
273,/home/amandapotts/git/arkouda/arkouda/client.py_get_config,"def get_config() -> Mapping[str, Union[str, int, float]]:
""""""
Get runtime information about the server.
Returns
-------
Mapping[str, Union[str, int, float]]
serverHostname
serverPort
numLocales
numPUs (number of processor units per locale)
maxTaskPar (maximum number of tasks per locale)
physicalMemory
Raises
------
RuntimeError
Raised if the client is not connected to a server
""""""
if serverConfig is None:
raise RuntimeError(""client is not connected to a server"")
return serverConfig
",[],0,[],/client.py_get_config
274,/home/amandapotts/git/arkouda/arkouda/client.py__get_config_msg,"def _get_config_msg() -> Mapping[str, Union[str, int, float]]:
""""""
Get runtime information about the server.
Raises
------
RuntimeError
Raised if there is a server-side error in getting memory used
ValueError
Raised if there's an error in parsing the JSON-formatted server config
""""""
try:
raw_message = cast(str, generic_msg(cmd=""getconfig""))
return json.loads(raw_message)
except json.decoder.JSONDecodeError:
raise ValueError(f""Returned config is not valid JSON: {raw_message}"")
except Exception as e:
raise RuntimeError(f""{e} in retrieving Arkouda server config"")
",[],0,[],/client.py__get_config_msg
275,/home/amandapotts/git/arkouda/arkouda/client.py_get_mem_used,"def get_mem_used(unit: str = ""b"", as_percent: bool = False) -> int:
""""""
Compute the amount of memory used by objects in the server's symbol table.
Parameters
----------
unit : str {'b', 'kb', 'mb', 'gb', 'tb', 'pb'}
unit of return ('b' by default)
as_percent : bool
If True, return the percent (as an int) of the available memory that's been used
False by default
Returns
-------
int
Indicates the amount of memory allocated to symbol table objects.
Raises
------
RuntimeError
Raised if there is a server-side error in getting memory used
ValueError
Raised if the returned value is not an int-formatted string
""""""
mem_used_message = cast(
str,
generic_msg(cmd=""getmemused"", args={""factor"": _mem_get_factor(unit), ""as_percent"": as_percent}),
)
return int(mem_used_message)
",[],0,[],/client.py_get_mem_used
276,/home/amandapotts/git/arkouda/arkouda/client.py_get_mem_avail,"def get_mem_avail(unit: str = ""b"", as_percent: bool = False) -> int:
""""""
Compute the amount of memory available to be used.
Parameters
----------
unit : str {'b', 'kb', 'mb', 'gb', 'tb', 'pb'}
unit of return ('b' by default)
as_percent : bool
If True, return the percent (as an int) of the memory that's available to be used
False by default
Returns
-------
int
Indicates the amount of memory available to be used.
Raises
------
RuntimeError
Raised if there is a server-side error in getting memory available
ValueError
Raised if the returned value is not an int-formatted string
""""""
mem_avail_message = cast(
str,
generic_msg(cmd=""getavailmem"", args={""factor"": _mem_get_factor(unit), ""as_percent"": as_percent}),
)
return int(mem_avail_message)
",[],0,[],/client.py_get_mem_avail
277,/home/amandapotts/git/arkouda/arkouda/client.py_get_mem_status,"def get_mem_status() -> List[Mapping[str, Union[str, int, float]]]:
""""""
Retrieves the memory status for each locale
Returns
-------
List[Mapping[str, Union[str, int, float]]]
total_mem: total physical memory on locale host
avail_mem: current available memory on locale host
arkouda_mem_alloc: memory allocated to Arkouda chapel process on locale host
pct_avail_mem: percentage of physical memory currently available on locale host
locale_id: locale id which is between 0 and numLocales-1
locale_hostname: host name of locale host
Raises
------
RuntimeError
Raised if there is a server-side error in getting per-locale
memory status information
""""""
try:
raw_message = cast(str, generic_msg(cmd=""getmemstatus""))
return json.loads(raw_message)
except json.decoder.JSONDecodeError:
raise ValueError(f""Returned memory status is not valid JSON: {raw_message}"")
except Exception as e:
raise RuntimeError(f""{e} in retrieving Arkouda server config"")
",[],0,[],/client.py_get_mem_status
278,/home/amandapotts/git/arkouda/arkouda/client.py_get_server_commands,"def get_server_commands() -> Mapping[str, str]:
""""""
Return a dictionary of available server commands and the functions they map to
Returns
-------
dict
String to String mapping of available server commands to functions
Raises
------
RuntimeError
Raised if there is a server-side error in retrieving and formatting the CommandMap
ValueError
Raised if there's an error in parsing the JSON-formatted server string
""""""
try:
raw_message = cast(str, generic_msg(cmd=""getCmdMap""))
return json.loads(raw_message)
except json.decoder.JSONDecodeError:
raise ValueError(f""Returned config is not valid JSON: {raw_message}"")
except Exception as e:
raise RuntimeError(f""{e} in retrieving Arkouda server config"")
",[],0,[],/client.py_get_server_commands
279,/home/amandapotts/git/arkouda/arkouda/client.py_print_server_commands,"def print_server_commands():
""""""
Print the list of the available Server commands
""""""
cmdMap = get_server_commands()
cmds = [k for k in sorted(cmdMap.keys())]
print(f""Total available server commands: {len(cmds)}"")
for cmd in cmds:
print(f""\t{cmd}"")
",[],0,[],/client.py_print_server_commands
280,/home/amandapotts/git/arkouda/arkouda/client.py__no_op,"def _no_op() -> str:
""""""
Send a no-op message just to gather round trip time
Returns
-------
str
The noop command result
Raises
------
RuntimeError
Raised if there is a server-side error in executing noop request
""""""
return cast(str, generic_msg(cmd=""noop""))
",[],0,[],/client.py__no_op
281,/home/amandapotts/git/arkouda/arkouda/client.py_ruok,"def ruok() -> str:
""""""
Simply sends an ""ruok"" message to the server and, if the return message is
""imok"", this means the arkouda_server is up and operating normally. A return
message of ""imnotok"" indicates an error occurred or the connection timed out.
This method is basically a way to do a quick healthcheck in a way that does
not require error handling.
Returns
-------
str
A string indicating if the server is operating normally (imok), if there's
an error server-side, or if ruok did not return a response (imnotok) in
both of the latter cases
""""""
try:
res = cast(str, generic_msg(cmd=""ruok""))
if res == ""imok"":
return ""imok""
else:
return f""imnotok because: {res}""
except Exception as e:
return f""ruok did not return response: {str(e)}""
",[],0,[],/client.py_ruok
282,/home/amandapotts/git/arkouda/arkouda/client.py_generate_history,"def generate_history(
num_commands: Optional[int] = None, command_filter: Optional[str] = None
",[],0,[],/client.py_generate_history
283,/home/amandapotts/git/arkouda/arkouda/history.py__filter_arkouda_command,"def _filter_arkouda_command(self, command: str, filter_string: str = ""ak"") -> Optional[str]:
""""""
Returns command string if the filter string is in the command and the
command is not generate_history. Otherwise, returns None
""""""
return command if (filter_string in command and ""generate_history"" not in command) else None
",[],0,[],/history.py__filter_arkouda_command
284,/home/amandapotts/git/arkouda/arkouda/history.py_retrieve,"def retrieve(
self, command_filter: Optional[str] = None, num_commands: Optional[int] = None
",[],0,[],/history.py_retrieve
285,/home/amandapotts/git/arkouda/arkouda/history.py_retrieve,"def retrieve(
self, command_filter: Optional[str] = None, num_commands: Optional[int] = None
",[],0,[],/history.py_retrieve
286,/home/amandapotts/git/arkouda/arkouda/history.py_retrieve,"def retrieve(
self, command_filter: Optional[str] = None, num_commands: Optional[int] = None
",[],0,[],/history.py_retrieve
287,/home/amandapotts/git/arkouda/arkouda/infoclass.py_auto_str,"def auto_str(cls):
",[],0,[],/infoclass.py_auto_str
288,/home/amandapotts/git/arkouda/arkouda/infoclass.py___str__,"def __str__(self):
return ""%s(%s)"" % (type(self).__name__, "", "".join(""%s=%s"" % item for item in vars(self).items()))
",[],0,[],/infoclass.py___str__
289,/home/amandapotts/git/arkouda/arkouda/infoclass.py_default,"def default(self, o):
return o.__dict__
",[],0,[],/infoclass.py_default
290,/home/amandapotts/git/arkouda/arkouda/infoclass.py___init__,"def __init__(self, **kwargs) -> None:
self.name = kwargs[""name""]
self.dtype = kwargs[""dtype""]
self.size = kwargs[""size""]
self.ndim = kwargs[""ndim""]
self.shape = kwargs[""shape""]
self.itemsize = kwargs[""itemsize""]
self.registered = kwargs[""registered""]
",[],0,[],/infoclass.py___init__
291,/home/amandapotts/git/arkouda/arkouda/infoclass.py_information,"def information(names: Union[List[str], str] = RegisteredSymbols) -> str:
""""""
Returns JSON formatted string containing information about the objects in names
Parameters
----------
names : Union[List[str], str]
names is either the name of an object or list of names of objects to retrieve info
if names is ak.AllSymbols, retrieves info for all symbols in the symbol table
if names is ak.RegisteredSymbols, retrieves info for all symbols in the registry
Returns
------
str
JSON formatted string containing a list of information for each object in names
Raises
------
RuntimeError
Raised if a server-side error is thrown in the process of
retrieving information about the objects in names
""""""
if isinstance(names, str):
if names in [AllSymbols, RegisteredSymbols]:
return cast(str, generic_msg(cmd=""info"", args={""names"": names}))
else:
names = [names]  # allows user to call ak.information(pda.name)
return cast(str, generic_msg(cmd=""info"", args={""names"": json.dumps(names)}))
",[],0,[],/infoclass.py_information
292,/home/amandapotts/git/arkouda/arkouda/infoclass.py_list_registry,"def list_registry(detailed: bool = False):
""""""
Return a list containing the names of all registered objects
Parameters
----------
detailed: bool
Default = False
Return details of registry objects. Currently includes object type for any objects
Returns
-------
dict
Dict containing keys ""Components"" and ""Objects"".
Raises
------
RuntimeError
Raised if there's a server-side error thrown
""""""
data = json.loads(cast(str, generic_msg(cmd=""list_registry"")))
objs = json.loads(data[""Objects""]) if data[""Objects""] != """" else []
obj_types = json.loads(data[""Object_Types""]) if data[""Object_Types""] != """" else []
return {
""Objects"": list(zip(objs, obj_types)) if detailed else objs,
""Components"": json.loads(data[""Components""]),
}
",[],0,[],/infoclass.py_list_registry
293,/home/amandapotts/git/arkouda/arkouda/infoclass.py_list_symbol_table,"def list_symbol_table() -> List[str]:
""""""
Return a list containing the names of all objects in the symbol table
Parameters
----------
None
Returns
-------
list
List of all object names in the symbol table
Raises
------
RuntimeError
Raised if there's a server-side error thrown
""""""
return [i.name for i in _parse_json(AllSymbols)]
",[],0,[],/infoclass.py_list_symbol_table
294,/home/amandapotts/git/arkouda/arkouda/infoclass.py_pretty_print_information,"def pretty_print_information(names: Union[List[str], str] = RegisteredSymbols) -> None:
""""""
Prints verbose information for each object in names in a human readable format
Parameters
----------
names : Union[List[str], str]
names is either the name of an object or list of names of objects to retrieve info
if names is ak.AllSymbols, retrieves info for all symbols in the symbol table
if names is ak.RegisteredSymbols, retrieves info for all symbols in the registry
Returns
------
None
Raises
------
RuntimeError
Raised if a server-side error is thrown in the process of
retrieving information about the objects in names
""""""
for i in _parse_json(names):
print(i)
",[],0,[],/infoclass.py_pretty_print_information
295,/home/amandapotts/git/arkouda/arkouda/logger.py___init__,"def __init__(
self,
name: str,
logLevel: LogLevel = LogLevel.INFO,
handlers: Optional[List[Handler]] = None,
logFormat: Optional[str] = ""[%(name)s] Line %(lineno)d %(levelname)s: %(message)s"",
",[],0,[],/logger.py___init__
296,/home/amandapotts/git/arkouda/arkouda/logger.py_changeLogLevel,"def changeLogLevel(self, level: LogLevel, handlerNames: List[str] = None) -> None:
""""""
Dynamically changes the logging level for ArkoudaLogger and 1..n
of configured Handlers
Parameters
----------
level : LogLevel
The desired log level in the form of a LogLevel enum value
handlerNames : List[str]
Names of 1..n Handlers configured for the ArkoudaLogger that
the log level will be changed for.
Returns
-------
None
Raises
------
TypeError
Raised if level is not a LogLevel enum or if handlerNames is
not a list of str objects
Notes
-----
The default is to change the log level of all configured Handlers.
If the handlerNames list is not None, then only the log level of
the named Handler object is changed.
""""""
newLevel = ArkoudaLogger.levelMappings[level]
if handlerNames is None:
for handler in self.handlers:
handler.setLevel(newLevel)
else:
for name, handler in zip(handlerNames, self.handlers):
if name == handler.name:
handler.setLevel(newLevel)
",[],0,[],/logger.py_changeLogLevel
297,/home/amandapotts/git/arkouda/arkouda/logger.py_enableVerbose,"def enableVerbose(self) -> None:
""""""
Enables verbose output by setting the log level for all handlers
to DEBUG
Returns
-------
None
""""""
self.changeLogLevel(LogLevel.DEBUG)
",[],0,[],/logger.py_enableVerbose
298,/home/amandapotts/git/arkouda/arkouda/logger.py_disableVerbose,"def disableVerbose(self, logLevel: LogLevel = LogLevel.INFO) -> None:
""""""
Disables verbose output by setting the log level for all handlers
to a level other than DEBUG, with a default of INFO
Parameters
----------
logLevel : LogLevel, defaults to LogLevel.INFO
The desired log level that will disable verbose output (logging at
the DEBUG level) by resetting the log level for all handlers.
Raises
------
TypeError
Raised if logLevel is not a LogLevel enum
Returns
-------
None
""""""
self.changeLogLevel(logLevel)
",[],0,[],/logger.py_disableVerbose
299,/home/amandapotts/git/arkouda/arkouda/logger.py_getHandler,"def getHandler(self, name: str) -> Handler:
""""""
Retrieves the Handler object corresponding to the name.
Parameters
----------
name : str
The name to be used to retrieve the desired Handler
Returns
-------
Handler with matching Handler.name
Raises
------
TypeError
Raised if the name is not a str
ValueError
Raised if the name does not match the name of any
of the configured handlers
""""""
for handler in self.handlers:
if name == handler.name:
return handler
raise ValueError(f""The name {name} does not match any handler"")
",[],0,[],/logger.py_getHandler
300,/home/amandapotts/git/arkouda/arkouda/logger.py_getArkoudaLogger,"def getArkoudaLogger(
name: str,
handlers: Optional[List[Handler]] = None,
logFormat: Optional[str] = ArkoudaLogger.DEFAULT_LOG_FORMAT,
logLevel: LogLevel = None,
",[],0,[],/logger.py_getArkoudaLogger
301,/home/amandapotts/git/arkouda/arkouda/logger.py_getArkoudaClientLogger,"def getArkoudaClientLogger(name: str) -> ArkoudaLogger:
""""""
A convenience method for instantiating an ArkoudaLogger that retrieves the
logging level from the ARKOUDA_LOG_LEVEL env variable and outputs log
messages without any formatting to stdout.
Parameters
----------
name : str
The name of the ArkoudaLogger
Returns
-------
ArkoudaLogger
Raises
------
TypeError
Raised if the name is not a str
Notes
-----
The returned ArkoudaLogger is configured to write unformatted log messages to
stdout, making it suitable for logging messages users will see such as
confirmation of successful login or pdarray creation
""""""
return getArkoudaLogger(name=name, logFormat=ArkoudaLogger.CLIENT_LOG_FORMAT)
",[],0,[],/logger.py_getArkoudaClientLogger
302,/home/amandapotts/git/arkouda/arkouda/logger.py_enableVerbose,"def enableVerbose() -> None:
""""""
Enables verbose logging (DEBUG log level) for all ArkoudaLoggers
""""""
for logger in loggers.values():
logger.enableVerbose()
",[],0,[],/logger.py_enableVerbose
303,/home/amandapotts/git/arkouda/arkouda/logger.py_disableVerbose,"def disableVerbose(logLevel: LogLevel = LogLevel.INFO) -> None:
""""""
Disables verbose logging (DEBUG log level) for all ArkoudaLoggers, setting
the log level for each to the logLevel parameter
Parameters
----------
logLevel : LogLevel
The new log level, defaultts to LogLevel.INFO
Raises
------
TypeError
Raised if logLevel is not a LogLevel enum
""""""
for logger in loggers.values():
logger.disableVerbose(logLevel)
",[],0,[],/logger.py_disableVerbose
304,/home/amandapotts/git/arkouda/arkouda/logger.py_write_log,"def write_log(log_msg: str, tag: str = ""ClientGeneratedLog"", log_lvl: LogLevel = LogLevel.INFO):
""""""
Allows the user to write custom logs.
Parameters
-----------
log_msg: str
The message to be added to the server log
tag: str
The tag to use in the log. This takes the place of the server function name.
Allows for easy identification of custom logs.
Defaults to ""ClientGeneratedLog""
log_lvl: LogLevel
The type of log to be written
Defaults to LogLevel.INFO
See Also
---------
LogLevel
""""""
from arkouda.client import generic_msg
generic_msg(cmd=""clientlog"", args={""log_msg"": log_msg, ""log_lvl"": log_lvl.name, ""tag"": tag})
",[],0,[],/logger.py_write_log
305,/home/amandapotts/git/arkouda/arkouda/io.py_get_filetype,"def get_filetype(filenames: Union[str, List[str]]) -> str:
""""""
Get the type of a file accessible to the server. Supported
file types and possible return strings are 'HDF5' and 'Parquet'.
Parameters
----------
filenames : Union[str, List[str]]
A file or list of files visible to the arkouda server
Returns
-------
str
Type of the file returned as a string, either 'HDF5', 'Parquet' or 'CSV
Raises
------
ValueError
Raised if filename is empty or contains only whitespace
Notes
-----
- When list provided, it is assumed that all files are the same type
- CSV Files without the Arkouda Header are not supported
See Also
--------
read_parquet, read_hdf
""""""
if isinstance(filenames, list):
fname = filenames[0]
else:
fname = filenames
if not (fname and fname.strip()):
raise ValueError(""filename cannot be an empty string"")
return cast(str, generic_msg(cmd=""getfiletype"", args={""filename"": fname}))
",[],0,[],/io.py_get_filetype
306,/home/amandapotts/git/arkouda/arkouda/io.py_ls,"def ls(filename: str, col_delim: str = "","", read_nested: bool = True) -> List[str]:
""""""
This function calls the h5ls utility on a HDF5 file visible to the
arkouda server or calls a function that imitates the result of h5ls
on a Parquet file.
Parameters
----------
filename : str
The name of the file to pass to the server
col_delim : str
The delimiter used to separate columns if the file is a csv
read_nested: bool
Default True, when True, SegArray objects will be read from the file. When False,
SegArray (or other nested Parquet columns) will be ignored.
Only used for Parquet files.
Returns
-------
str
The string output of the datasets from the server
Raises
------
TypeError
Raised if filename is not a str
ValueError
Raised if filename is empty or contains only whitespace
RuntimeError
Raised if error occurs in executing ls on an HDF5 file
Notes
- This will need to be updated because Parquet will not technically support this when we update.
Similar functionality will be added for Parquet in the future
- For CSV files without headers, please use ls_csv
See Also
---------
ls_csv
""""""
if not (filename and filename.strip()):
raise ValueError(""filename cannot be an empty string"")
cmd = ""lsany""
return json.loads(
cast(
str,
generic_msg(
cmd=cmd,
args={""filename"": filename, ""col_delim"": col_delim, ""read_nested"": read_nested},
),
)
)
",[],0,[],/io.py_ls
307,/home/amandapotts/git/arkouda/arkouda/io.py_get_null_indices,"def get_null_indices(
filenames: Union[str, List[str]], datasets: Optional[Union[str, List[str]]] = None
",[],0,[],/io.py_get_null_indices
308,/home/amandapotts/git/arkouda/arkouda/io.py__file_type_to_int,"def _file_type_to_int(file_type: str) -> int:
""""""
Convert a string to integer representing the format to save the file in
Parameters
----------
file_type: str (single | distribute)
The string representation of the format for saving the file
Returns
-------
int representing the format
Raises
------
ValueError
If mode is not 'single' or 'distribute'
""""""
if file_type.lower() == ""single"":
return 0
elif file_type.lower() == ""distribute"":
return 1
else:
raise ValueError(f""File Type expected to be 'single' or 'distributed'. Got {file_type}"")
",[],0,[],/io.py__file_type_to_int
309,/home/amandapotts/git/arkouda/arkouda/io.py__mode_str_to_int,"def _mode_str_to_int(mode: str) -> int:
""""""
Convert string to integer representing the mode to write
Parameters
----------
mode: str (truncate | append)
The string representation of the write mode to be converted to integer
Returns
-------
int representing the mode
Raises
------
ValueError
If mode is not 'truncate' or 'append'
""""""
if mode.lower() == ""truncate"":
return 0
elif mode.lower() == ""append"":
return 1
else:
raise ValueError(f""Write Mode expected to be 'truncate' or 'append'. Got {mode}."")
",[],0,[],/io.py__mode_str_to_int
310,/home/amandapotts/git/arkouda/arkouda/io.py_get_datasets,"def get_datasets(
filenames: Union[str, List[str]],
allow_errors: bool = False,
column_delim: str = "","",
read_nested: bool = True,
",[],0,[],/io.py_get_datasets
311,/home/amandapotts/git/arkouda/arkouda/io.py_ls_csv,"def ls_csv(filename: str, col_delim: str = "","") -> List[str]:
""""""
Used for identifying the datasets within a file when a CSV does not
have a header.
Parameters
----------
filename : str
The name of the file to pass to the server
col_delim : str
The delimiter used to separate columns if the file is a csv
Returns
-------
str
The string output of the datasets from the server
See Also
---------
ls
""""""
if not (filename and filename.strip()):
raise ValueError(""filename cannot be an empty string"")
return json.loads(
cast(
str,
generic_msg(
cmd=""lscsv"",
args={""filename"": filename, ""col_delim"": col_delim},
),
)
)
",[],0,[],/io.py_ls_csv
312,/home/amandapotts/git/arkouda/arkouda/io.py_get_columns,"def get_columns(
filenames: Union[str, List[str]], col_delim: str = "","", allow_errors: bool = False
",[],0,[],/io.py_get_columns
313,/home/amandapotts/git/arkouda/arkouda/io.py__prep_datasets,"def _prep_datasets(
filenames: Union[str, List[str]],
datasets: Optional[Union[str, List[str]]] = None,
allow_errors: bool = False,
read_nested: bool = True,
",[],0,[],/io.py__prep_datasets
314,/home/amandapotts/git/arkouda/arkouda/io.py__parse_errors,"def _parse_errors(rep_msg, allow_errors: bool = False):
""""""
Helper function to parse error messages from a read operation
Parameters
----------
rep_msg
The server response from a read operation
allow_errors: bool
Default: False
Whether or not errors are to be allowed during read operation
""""""
file_errors = rep_msg[""file_errors""] if ""file_errors"" in rep_msg else []
if allow_errors and file_errors:
file_error_count = rep_msg[""file_error_count""] if ""file_error_count"" in rep_msg else -1
warn(
f""There were {file_error_count} errors reading files on the server. ""
+ f""Sample error messages {file_errors}"",
RuntimeWarning,
)
",[],0,[],/io.py__parse_errors
315,/home/amandapotts/git/arkouda/arkouda/io.py__parse_obj,"def _parse_obj(
obj: Dict,
",[],0,[],/io.py__parse_obj
316,/home/amandapotts/git/arkouda/arkouda/io.py__dict_recombine_segarrays_categoricals,"def _dict_recombine_segarrays_categoricals(df_dict):
seg_cols = [""_"".join(col.split(""_"")[:-1]) for col in df_dict.keys() if col.endswith(""_segments"")]
cat_cols = [""."".join(col.split(""."")[:-1]) for col in df_dict.keys() if col.endswith("".categories"")]
df_dict_keys = {
""_"".join(col.split(""_"")[:-1])
if col.endswith(""_segments"") or col.endswith(""_values"")
else ""."".join(col.split(""."")[:-1])
if col.endswith(""._akNAcode"")
or col.endswith("".categories"")
or col.endswith("".codes"")
or col.endswith("".permutation"")
or col.endswith("".segments"")
else col
for col in df_dict.keys()
}
if len(seg_cols) > 0 or len(cat_cols) > 0:
df_dict = {
col: SegArray(df_dict[col + ""_segments""], df_dict[col + ""_values""])
if col in seg_cols
else Categorical.from_codes(
df_dict[f""{col}.codes""],
df_dict[f""{col}.categories""],
permutation=df_dict[f""{col}.permutation""]
if f""{col}.permutation"" in df_dict_keys
else None,
segments=df_dict[f""{col}.segments""] if f""{col}.segments"" in df_dict_keys else None,
_akNAcode=df_dict[f""{col}._akNAcode""],
)
if col in cat_cols
else df_dict[col]
for col in df_dict_keys
}
return df_dict
",[],0,[],/io.py__dict_recombine_segarrays_categoricals
317,/home/amandapotts/git/arkouda/arkouda/io.py__build_objects,"def _build_objects(
rep_msg: Dict,
",[],0,[],/io.py__build_objects
318,/home/amandapotts/git/arkouda/arkouda/io.py_read_hdf,"def read_hdf(
filenames: Union[str, List[str]],
datasets: Optional[Union[str, List[str]]] = None,
iterative: bool = False,
strict_types: bool = True,
allow_errors: bool = False,
calc_string_offsets: bool = False,
tag_data=False,
",[],0,[],/io.py_read_hdf
319,/home/amandapotts/git/arkouda/arkouda/io.py_read_parquet,"def read_parquet(
filenames: Union[str, List[str]],
datasets: Optional[Union[str, List[str]]] = None,
iterative: bool = False,
strict_types: bool = True,
allow_errors: bool = False,
tag_data: bool = False,
read_nested: bool = True,
",[],0,[],/io.py_read_parquet
320,/home/amandapotts/git/arkouda/arkouda/io.py_read_csv,"def read_csv(
filenames: Union[str, List[str]],
datasets: Optional[Union[str, List[str]]] = None,
column_delim: str = "","",
allow_errors: bool = False,
",[],0,[],/io.py_read_csv
321,/home/amandapotts/git/arkouda/arkouda/io.py_import_data,"def import_data(read_path: str, write_file: str = None, return_obj: bool = True, index: bool = False):
""""""
Import data from a file saved by Pandas (HDF5/Parquet) to Arkouda object and/or
a file formatted to be read by Arkouda.
Parameters
__________
read_path: str
path to file where pandas data is stored. This can be glob expression for parquet formats.
write_file: str, optional
path to file to write arkouda formatted data to. Only write file if provided
return_obj: bool, optional
Default True. When True return the Arkouda DataFrame object, otherwise return None
index: bool, optional
Default False. When True, maintain the indexes loaded from the pandas file
Raises
______
RuntimeWarning
- Export attempted on Parquet file. Arkouda formatted Parquet files are readable by pandas.
RuntimeError
- Unsupported file type
Returns
_______
pd.DataFrame
When `return_obj=True`
See Also
________
pandas.DataFrame.to_parquet, pandas.DataFrame.to_hdf,
pandas.DataFrame.read_parquet, pandas.DataFrame.read_hdf,
ak.export
Notes
_____
- Import can only be performed from hdf5 or parquet files written by pandas.
""""""
from arkouda.dataframe import DataFrame
is_glob = not os.path.isfile(read_path)
file_list = glob.glob(read_path)
if len(file_list) == 0:
raise FileNotFoundError(f""Invalid read_path, {read_path}. No files found."")
file = read_path if not is_glob else glob.glob(read_path)[0]
filetype = get_filetype(file)
if filetype == ""HDF5"":
if is_glob:
raise RuntimeError(
""Pandas HDF5 import supports valid file path only. Only supports the local file system,""
"" remote URLs and file-like objects are not supported.""
)
df_def = pd.read_hdf(read_path)
elif filetype == ""Parquet"":
df_def = pd.read_parquet(read_path)
else:
raise RuntimeError(
""File type not supported. Import is only supported for HDF5 and Parquet file formats.""
)
df = DataFrame(df_def)
if write_file:
df.to_hdf(write_file, index=index) if filetype == ""HDF5"" else df.to_parquet(
write_file, index=index
)
if return_obj:
return df
",[],0,[],/io.py_import_data
322,/home/amandapotts/git/arkouda/arkouda/io.py_export,"def export(
read_path: str,
dataset_name: str = ""ak_data"",
write_file: str = None,
return_obj: bool = True,
index: bool = False,
",[],0,[],/io.py_export
323,/home/amandapotts/git/arkouda/arkouda/io.py__bulk_write_prep,"def _bulk_write_prep(
columns: Union[
Mapping[str, Union[pdarray, Strings, SegArray, ArrayView]],
List[Union[pdarray, Strings, SegArray, ArrayView]],
],
names: List[str] = None,
convert_categoricals: bool = False,
",[],0,[],/io.py__bulk_write_prep
324,/home/amandapotts/git/arkouda/arkouda/io.py_to_parquet,"def to_parquet(
columns: Union[
Mapping[str, Union[pdarray, Strings, SegArray, ArrayView]],
List[Union[pdarray, Strings, SegArray, ArrayView]],
],
prefix_path: str,
names: List[str] = None,
mode: str = ""truncate"",
compression: Optional[str] = None,
convert_categoricals: bool = False,
",[],0,[],/io.py_to_parquet
325,/home/amandapotts/git/arkouda/arkouda/io.py_to_hdf,"def to_hdf(
columns: Union[
Mapping[str, Union[pdarray, Strings, SegArray, ArrayView]],
List[Union[pdarray, Strings, SegArray, ArrayView]],
],
prefix_path: str,
names: List[str] = None,
mode: str = ""truncate"",
file_type: str = ""distribute"",
",[],0,[],/io.py_to_hdf
326,/home/amandapotts/git/arkouda/arkouda/io.py__get_hdf_filetype,"def _get_hdf_filetype(filename: str) -> str:
if not (filename and filename.strip()):
raise ValueError(""filename cannot be an empty string"")
cmd = ""hdffileformat""
return cast(
str,
generic_msg(
cmd=cmd,
args={""filename"": filename},
),
)
",[],0,[],/io.py__get_hdf_filetype
327,/home/amandapotts/git/arkouda/arkouda/io.py__repack_hdf,"def _repack_hdf(prefix_path: str):
""""""
Overwrites the existing hdf5 file with a copy that removes any inaccessible datasets
""""""
file_type = _get_hdf_filetype(prefix_path + ""*"")
dset_list = ls(prefix_path + ""*"")
if len(dset_list) == 1:
return
data = read_hdf(prefix_path + ""*"")
if not isinstance(data, dict):
data = [data]  # type: ignore
to_hdf(data, prefix_path, names=dset_list, file_type=file_type)  # type: ignore
",[],0,[],/io.py__repack_hdf
328,/home/amandapotts/git/arkouda/arkouda/io.py_update_hdf,"def update_hdf(
columns: Union[
Mapping[str, Union[pdarray, Strings, SegArray, ArrayView]],
List[Union[pdarray, Strings, SegArray, ArrayView]],
],
prefix_path: str,
names: List[str] = None,
repack: bool = True,
",[],0,[],/io.py_update_hdf
329,/home/amandapotts/git/arkouda/arkouda/io.py_to_csv,"def to_csv(
columns: Union[Mapping[str, Union[pdarray, Strings]], List[Union[pdarray, Strings]]],
prefix_path: str,
names: List[str] = None,
col_delim: str = "","",
overwrite: bool = False,
",[],0,[],/io.py_to_csv
330,/home/amandapotts/git/arkouda/arkouda/io.py_save_all,"def save_all(
columns: Union[
Mapping[str, Union[pdarray, Strings, SegArray, ArrayView]],
List[Union[pdarray, Strings, SegArray, ArrayView]],
],
prefix_path: str,
names: List[str] = None,
file_format=""HDF5"",
mode: str = ""truncate"",
file_type: str = ""distribute"",
compression: Optional[str] = None,
",[],0,[],/io.py_save_all
331,/home/amandapotts/git/arkouda/arkouda/io.py_load,"def load(
path_prefix: str,
file_format: str = ""INFER"",
dataset: str = ""array"",
calc_string_offsets: bool = False,
column_delim: str = "","",
",[],0,[],/io.py_load
332,/home/amandapotts/git/arkouda/arkouda/io.py_load_all,"def load_all(
path_prefix: str, file_format: str = ""INFER"", column_delim: str = "","", read_nested=True
",[],0,[],/io.py_load_all
333,/home/amandapotts/git/arkouda/arkouda/io.py_read,"def read(
filenames: Union[str, List[str]],
datasets: Optional[Union[str, List[str]]] = None,
iterative: bool = False,
strictTypes: bool = True,
allow_errors: bool = False,
calc_string_offsets=False,
column_delim: str = "","",
read_nested: bool = True,
",[],0,[],/io.py_read
334,/home/amandapotts/git/arkouda/arkouda/io.py_read_tagged_data,"def read_tagged_data(
filenames: Union[str, List[str]],
datasets: Optional[Union[str, List[str]]] = None,
strictTypes: bool = True,
allow_errors: bool = False,
calc_string_offsets=False,
read_nested: bool = True,
",[],0,[],/io.py_read_tagged_data
335,/home/amandapotts/git/arkouda/arkouda/io.py_snapshot,"def snapshot(filename):
""""""
Create a snapshot of the current Arkouda namespace. All currently accessible variables containing
Arkouda objects will be written to an HDF5 file.
Unlike other save/load functions, this maintains the integrity of dataframes.
Current Variable names are used as the dataset name when saving.
Parameters
----------
filename: str
Name to use when storing file
Returns
--------
None
See Also
---------
ak.restore
""""""
import inspect
from types import ModuleType
from arkouda.dataframe import DataFrame
filename = filename + ""_SNAPSHOT""
mode = ""TRUNCATE""
callers_local_vars = inspect.currentframe().f_back.f_locals.items()
for name, val in [
(n, v) for n, v in callers_local_vars if not n.startswith(""__"") and not isinstance(v, ModuleType)
]:
if isinstance(val, (pdarray, Categorical, SegArray, Strings, DataFrame, GroupBy)):
if isinstance(val, DataFrame):
val._to_hdf_snapshot(filename, dataset=name, mode=mode)
else:
val.to_hdf(filename, dataset=name, mode=mode)
mode = ""APPEND""
",[],0,[],/io.py_snapshot
336,/home/amandapotts/git/arkouda/arkouda/io.py_restore,"def restore(filename):
""""""
Return data saved using `ak.snapshot`
Parameters
----------
filename: str
Name used to create snapshot to be read
Returns
--------
Dict
Notes
------
Unlike other save/load methods using snapshot restore will save DataFrames alongside other
objects in HDF5. Thus, they are returned within the dictionary as a dataframe.
""""""
restore_files = glob.glob(f""{filename}_SNAPSHOT_LOCALE*"")
return read_hdf(sorted(restore_files))
",[],0,[],/io.py_restore
337,/home/amandapotts/git/arkouda/arkouda/io.py_receive,"def receive(hostname: str, port):
""""""
Receive a pdarray sent by `pdarray.transfer()`.
Parameters
----------
hostname : str
The hostname of the pdarray that sent the array
port : int_scalars
The port to send the array over. This needs to be an
open port (i.e., not one that the Arkouda server is
running on). This will open up `numLocales` ports,
each of which in succession, so will use ports of the
range {port..(port+numLocales)} (e.g., running an
Arkouda server of 4 nodes, port 1234 is passed as
`port`, Arkouda will use ports 1234, 1235, 1236,
and 1237 to send the array data).
This port much match the port passed to the call to
`pdarray.transfer()`.
Returns
-------
pdarray
The pdarray sent from the sending server to the current
receiving server.
Raises
------
ValueError
Raised if the op is not within the pdarray.BinOps set
TypeError
Raised if other is not a pdarray or the pdarray.dtype is not
a supported dtype
""""""
rep_msg = generic_msg(cmd=""receiveArray"", args={""hostname"": hostname, ""port"": port})
rep = json.loads(rep_msg)
return _build_objects(rep)
",[],0,[],/io.py_receive
338,/home/amandapotts/git/arkouda/arkouda/io.py_receive_dataframe,"def receive_dataframe(hostname: str, port):
""""""
Receive a pdarray sent by `dataframe.transfer()`.
Parameters
----------
hostname : str
The hostname of the dataframe that sent the array
port : int_scalars
The port to send the dataframe over. This needs to be an
open port (i.e., not one that the Arkouda server is
running on). This will open up `numLocales` ports,
each of which in succession, so will use ports of the
range {port..(port+numLocales)} (e.g., running an
Arkouda server of 4 nodes, port 1234 is passed as
`port`, Arkouda will use ports 1234, 1235, 1236,
and 1237 to send the array data).
This port much match the port passed to the call to
`pdarray.send_array()`.
Returns
-------
pdarray
The dataframe sent from the sending server to the
current receiving server.
Raises
------
ValueError
Raised if the op is not within the pdarray.BinOps set
TypeError
Raised if other is not a pdarray or the pdarray.dtype is not
a supported dtype
""""""
rep_msg = generic_msg(cmd=""receiveDataframe"", args={""hostname"": hostname, ""port"": port})
rep = json.loads(rep_msg)
return DataFrame(_build_objects(rep))
",[],0,[],/io.py_receive_dataframe
339,/home/amandapotts/git/arkouda/arkouda/alignment.py_unsqueeze,"def unsqueeze(p):
if isinstance(p, pdarray) or isinstance(p, Strings) or isinstance(p, Categorical):
return [p]
else:
return p
",[],0,[],/alignment.py_unsqueeze
340,/home/amandapotts/git/arkouda/arkouda/alignment.py_zero_up,"def zero_up(vals):
""""""
Map an array of sparse values to 0-up indices.
Parameters
----------
vals : pdarray
Array to map to dense index
Returns
-------
aligned : pdarray
Array with values replaced by 0-up indices
""""""
g = GroupBy(vals)
unique_size = g.unique_keys.size if not isinstance(vals, Sequence) else g.unique_keys[0].size
uniqueInds = arange(unique_size)
idinds = g.broadcast(uniqueInds, permute=True)
return idinds
",[],0,[],/alignment.py_zero_up
341,/home/amandapotts/git/arkouda/arkouda/alignment.py_align,"def align(*args):
""""""
Map multiple arrays of sparse identifiers to a common 0-up index.
Parameters
----------
Arrays to map to dense index
Returns
-------
aligned : list of pdarrays
Arrays with values replaced by 0-up indices
""""""
if not any(isinstance(arg, Sequence) for arg in args):
key = concatenate([full(arg.size, i, akint64) for i, arg in enumerate(args)], ordered=False)
inds = zero_up(concatenate(args, ordered=False))
else:
if not all(isinstance(arg, Sequence) for arg in args):
raise TypeError(""If any of the arguments are a sequence of pdarray, they all have to be"")
key = concatenate([full(arg[0].size, i, akint64) for i, arg in enumerate(args)], ordered=False)
inds = zero_up([concatenate(x, ordered=False) for x in zip(*args)])
return [inds[key == i] for i in range(len(args))]
",[],0,[],/alignment.py_align
342,/home/amandapotts/git/arkouda/arkouda/alignment.py_right_align,"def right_align(left, right):
""""""
Map two arrays of sparse values to the 0-up index set implied by the right array,
discarding values from left that do not appear in right.
Parameters
----------
left : pdarray or a sequence of pdarrays
Left-hand identifiers
right : pdarray or a sequence of pdarrays
Right-hand identifiers that define the index
Returns
-------
keep : pdarray, bool
Logical index of left-hand values that survived
aligned : (pdarray, pdarray)
Left and right arrays with values replaced by 0-up indices
""""""
is_sequence = isinstance(left, Sequence) and isinstance(right, Sequence)
uright = unique(right)
keep = in1d(left, uright)
fleft = left[keep] if not is_sequence else [lf[keep] for lf in left]
return keep, align(fleft, right)
",[],0,[],/alignment.py_right_align
343,/home/amandapotts/git/arkouda/arkouda/alignment.py_left_align,"def left_align(left, right):
""""""
Map two arrays of sparse identifiers to the 0-up index set implied by the left array,
discarding values from right that do not appear in left.
""""""
return right_align(right, left)
",[],0,[],/alignment.py_left_align
344,/home/amandapotts/git/arkouda/arkouda/alignment.py_find,"def find(query, space):
""""""
Return indices of query items in a search list of items (-1 if not found).
Parameters
----------
query : (sequence of) array-like
The items to search for. If multiple arrays, each ""row"" is an item.
space : (sequence of) array-like
The set of items in which to search. Must have same shape/dtype as query.
Returns
-------
indices : pdarray, int64
For each item in query, its index in space or -1 if not found.
""""""
if isinstance(query, (pdarray, Strings, Categorical)):
if type(query) is not type(space):
raise TypeError(""Arguments must have same type"")
c = concatenate((space, query), ordered=False)
spacesize = space.size
querysize = query.size
else:
if len(query) != len(space):
raise TypeError(""Multi-array arguments must have same number of arrays"")
spacesize = {s.size for s in space}
querysize = {q.size for q in query}
if len(spacesize) != 1 or len(querysize) != 1:
raise TypeError(""Multi-array arguments must be non-empty and have equal-length arrays"")
spacesize = spacesize.pop()
querysize = querysize.pop()
atypes = np.array([ai.dtype for ai in query])
btypes = np.array([bi.dtype for bi in space])
if not (atypes == btypes).all():
raise TypeError(""Array dtypes of arguments must match"")
c = [concatenate((si, qi), ordered=False) for si, qi in zip(space, query)]
i = concatenate((arange(spacesize), arange(spacesize, spacesize + querysize)), ordered=False)
g = GroupBy(c)
space_multiplicity = g.sum(i < spacesize)[1]
if (space_multiplicity > 1).any():
warn(
""Duplicate terms present in search space. Only first instance of each query term\
will be reported.""
)
uspaceidx = g.min(i)[1]
uspaceidx = where(uspaceidx >= spacesize, -1, uspaceidx)
spaceidx = g.broadcast(uspaceidx)
return spaceidx[i >= spacesize]
","['array', 'array']",2,"['array([ai.dtype for ai in query])', 'array([bi.dtype for bi in space])']",/alignment.py_find
345,/home/amandapotts/git/arkouda/arkouda/alignment.py_lookup,"def lookup(keys, values, arguments, fillvalue=-1):
""""""
Apply the function defined by the mapping keys --> values to arguments.
Parameters
----------
keys : (sequence of) array-like
The domain of the function. Entries must be unique (if a sequence of
arrays is given, each row is treated as a tuple-valued entry).
values : pdarray
The range of the function. Must be same length as keys.
arguments : (sequence of) array-like
The arguments on which to evaluate the function. Must have same dtype
(or tuple of dtypes, for a sequence) as keys.
fillvalue : scalar
The default value to return for arguments not in keys.
Returns
-------
evaluated : pdarray
The result of evaluating the function over arguments.
Notes
-----
While the values cannot be Strings (or other complex objects), the same
result can be achieved by passing an arange as the values, then using
the return as indices into the desired object.
Examples
--------
>>> keys1 = ak.array(['twenty' for _ in range(5)])
>>> keys2 = ak.array(['one', 'two', 'three', 'four', 'five'])
>>> values = ak.array([21, 22, 23, 24, 25])
>>> args1 = ak.array(['twenty', 'thirty', 'twenty'])
>>> args2 = ak.array(['four', 'two', 'two'])
>>> aku.lookup([keys1, keys2], values, [args1, args2])
array([24, -1, 22])
>>> revkeys = values
>>> revindices = ak.arange(values.size)
>>> revargs = ak.array([24, 21, 22])
>>> idx = aku.lookup(revkeys, revindices, revargs)
>>> keys1[idx], keys2[idx]
(array(['twenty', 'twenty', 'twenty']),
array(['four', 'one', 'two']))
""""""
if isinstance(values, Categorical):
codes = lookup(keys, values.codes, arguments, fillvalue=values._NAcode)
return Categorical.from_codes(codes, values.categories, NAvalue=values.NAvalue)
idx = find(arguments, keys)
retvals = full(idx.size, fillvalue, dtype=values.dtype)
found = idx >= 0
retvals[found] = values[idx[found]]
return retvals
",[],0,[],/alignment.py_lookup
346,/home/amandapotts/git/arkouda/arkouda/alignment.py_in1d_intervals,"def in1d_intervals(vals, intervals, symmetric=False):
""""""
Test each value for membership in *any* of a set of half-open (pythonic)
intervals.
Parameters
----------
vals : pdarray(int, float)
Values to test for membership in intervals
intervals : 2-tuple of pdarrays
Non-overlapping, half-open intervals, as a tuple of
(lower_bounds_inclusive, upper_bounds_exclusive)
symmetric : bool
If True, also return boolean pdarray indicating which intervals
contained one or more query values.
Returns
-------
pdarray(bool)
Array of same length as <vals>, True if corresponding value is
included in any of the ranges defined by (low[i], high[i]) inclusive.
pdarray(bool) (if symmetric=True)
Array of same length as number of intervals, True if corresponding
interval contains any of the values in <vals>.
Notes
-----
First return array is equivalent to the following:
((vals >= intervals[0][0]) & (vals < intervals[1][0])) |
((vals >= intervals[0][1]) & (vals < intervals[1][1])) |
...
((vals >= intervals[0][-1]) & (vals < intervals[1][-1]))
But much faster when testing many ranges.
Second (optional) return array is equivalent to:
((intervals[0] <= vals[0]) & (intervals[1] > vals[0])) |
((intervals[0] <= vals[1]) & (intervals[1] > vals[1])) |
...
((intervals[0] <= vals[-1]) & (intervals[1] > vals[-1]))
But much faster when vals is non-trivial size.
""""""
idx = search_intervals(vals, intervals)
found = idx > -1
if symmetric:
containresult = in1d(arange(intervals[0].size), idx)
return found, containresult
else:
return found
",[],0,[],/alignment.py_in1d_intervals
347,/home/amandapotts/git/arkouda/arkouda/alignment.py_is_cosorted,"def is_cosorted(arrays):
""""""
Return True iff the arrays are cosorted, i.e., if the arrays were columns in a table
then the rows are sorted.
Parameters
----------
arrays : list-like of pdarrays
Arrays to check for cosortedness
Returns
-------
bool
True iff arrays are cosorted.
Raises
------
ValueError
Raised if arrays are not the same length
TypeError
Raised if arrays is not a list-like of pdarrays
""""""
if not isinstance(arrays, Sequence) or not all(isinstance(array, pdarray) for array in arrays):
raise TypeError(""Input must be a list-like of pdarrays"")
if len({array.size for array in arrays}) > 1:
raise ValueError(""Arrays must all be same length"")
if not arrays[0].is_sorted():
return False
boundary = arrays[0][:-1] != arrays[0][1:]
for array in arrays[1:]:
left = array[:-1]
right = array[1:]
_ = left <= right
if not (_ | boundary).all():
return False
boundary = boundary | (left != right)
return True
",[],0,[],/alignment.py_is_cosorted
348,/home/amandapotts/git/arkouda/arkouda/alignment.py_interval_lookup,"def interval_lookup(keys, values, arguments, fillvalue=-1, tiebreak=None, hierarchical=False):
""""""
Apply a function defined over intervals to an array of arguments.
Parameters
----------
keys : 2-tuple of (sequences of) pdarrays
Tuple of closed intervals expressed as (lower_bounds_inclusive, upper_bounds_inclusive).
Must have same dtype(s) as vals.
values : pdarray
Function value to return for each entry in keys.
arguments : (sequences of) pdarray
Values to search for in intervals. If multiple arrays, each ""row"" is an item.
fillvalue : scalar
Default value to return when argument is not in any interval.
tiebreak : (optional) pdarray, numeric
When an argument is present in more than one key interval, the interval with the
lowest tiebreak value will be chosen. If no tiebreak is given, the
first valid key interval will be chosen.
Returns
-------
pdarray
Value of function corresponding to the keys interval
containing each argument, or fillvalue if argument not
in any interval.
""""""
if isinstance(values, Categorical):
codes = interval_lookup(keys, values.codes, arguments, fillvalue=values._NAcode)
return Categorical.from_codes(codes, values.categories, NAvalue=values.NAvalue)
idx = search_intervals(arguments, keys, tiebreak=tiebreak, hierarchical=hierarchical)
arguments_size = arguments.size if isinstance(arguments, pdarray) else arguments[0].size
res = zeros(arguments_size, dtype=values.dtype)
if fillvalue is not None:
res.fill(fillvalue)
found = idx > -1
res[found] = values[idx[found]]
return res
",[],0,[],/alignment.py_interval_lookup
349,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_BitVectorizer,"def BitVectorizer(width=64, reverse=False):
""""""
Make a callback (i.e. function) that can be called on an
array to create a BitVector.
Parameters
----------
width : int
The number of bit fields in the vector
reverse : bool
If True, display bits from least significant (left) to most
significant (right). By default, the most significant bit
is the left-most bit.
Returns
-------
bitvectorizer : callable
A function that takes an array and returns a BitVector instance
""""""
return partial(BitVector, width=width, reverse=reverse)
",[],0,[],/client_dtypes.py_BitVectorizer
350,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py___init__,"def __init__(self, values, width=64, reverse=False):
self.registered_name = None
if not isinstance(values, pdarray) or values.dtype not in intTypes:
self.name = None  # This is needed to silence warnings of missing name during failed creation
raise TypeError(""Argument must be integer pdarray"")
self.width = width
self.reverse = reverse
self.values = akcast(values, bitType)
super().__init__(
self.values.name,
self.values.dtype.name,
self.values.size,
self.values.ndim,
self.values.shape,
self.values.itemsize,
)
",[],0,[],/client_dtypes.py___init__
351,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_format,"def format(self, x):
""""""
Format a single binary vector as a string.
""""""
fmt = ""{{:0{}b}}"".format(self.width).format(x).replace(""0"", ""."").replace(""1"", ""|"")
if self.reverse:
return fmt[::-1]
else:
return fmt
",[],0,[],/client_dtypes.py_format
352,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py___str__,"def __str__(self):
from arkouda.client import pdarrayIterThresh
if self.size <= pdarrayIterThresh:
vals = [self.format(self.values[i]) for i in range(self.size)]
else:
vals = [self.format(self.values[i]) for i in range(3)]
vals.append(""..."")
vals.extend([self.format(self.values[i]) for i in range(self.size - 3, self.size)])
spaces = "" "" * (len(self.__class__.__name__) + 1)
return ""{}([{}],\n{}width={}, reverse={})"".format(
self.__class__.__name__, "",\n{} "".format(spaces).join(vals), spaces, self.width, self.reverse
)
",[],0,[],/client_dtypes.py___str__
353,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py___repr__,"def __repr__(self):
return self.__str__()
",[],0,[],/client_dtypes.py___repr__
354,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_to_ndarray,"def to_ndarray(self):
""""""
Export data to a numpy array of string-formatted bit vectors.
""""""
return np.array([self.format(x) for x in self.values.to_ndarray()])
",['array'],1,['array([self.format(x) for x in self.values.to_ndarray()])'],/client_dtypes.py_to_ndarray
355,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_to_list,"def to_list(self):
""""""
Export data to a list of string-formatted bit vectors.
""""""
return self.to_ndarray().tolist()
",[],0,[],/client_dtypes.py_to_list
356,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py__cast,"def _cast(self, values):
return self.__class__(values, width=self.width, reverse=self.reverse)
",[],0,[],/client_dtypes.py__cast
357,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py___getitem__,"def __getitem__(self, key):
if isSupportedInt(key):
return self.format(self.values[key])
else:
return self._cast(self.values[key])
",[],0,[],/client_dtypes.py___getitem__
358,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py___setitem__,"def __setitem__(self, key, value):
if isinstance(value, self.__class__):
self.values[key] = value.values
elif isSupportedInt(key) and isSupportedInt(value):
self.values[key] = value
else:
return NotImplemented
",[],0,[],/client_dtypes.py___setitem__
359,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py__binop,"def _binop(self, other, op):
if isSupportedInt(other):
otherdata = other
elif isinstance(other, self.__class__):
otherdata = other.values
elif isinstance(other, pdarray) and other.dtype in intTypes:
otherdata = other
else:
return NotImplemented
if op in self.conserves:
return self._cast(self.values._binop(otherdata, op))
else:
return self.values._binop(otherdata, op)
",[],0,[],/client_dtypes.py__binop
360,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py__r_binop,"def _r_binop(self, other, op):
if isSupportedInt(other):
if op in self.conserves:
return self._cast(self.values._r_binop(other, op))
else:
return self.values._r_binop(other, op)
elif isinstance(other, pdarray) and other.dtype in intTypes:
if op in self.conserves:
return self._cast(other._binop(self.values, op))
else:
return other._binop(self.values, op)
else:
return NotImplemented
",[],0,[],/client_dtypes.py__r_binop
361,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_opeq,"def opeq(self, other, op):
if isSupportedInt(other):
otherdata = other
elif isinstance(other, self.__class__):
otherdata = other.values
elif isinstance(other, pdarray) and other.dtype in intTypes:
otherdata = other
else:
return NotImplemented
self.values.opeq(otherdata, op)
",[],0,[],/client_dtypes.py_opeq
362,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_register,"def register(self, user_defined_name):
""""""
Register this BitVector object and underlying components with the Arkouda server
Parameters
----------
user_defined_name : str
user defined name the BitVector is to be registered under,
this will be the root name for underlying components
Returns
-------
BitVector
The same BitVector which is now registered with the arkouda server and has an updated name.
This is an in-place modification, the original is returned to support
a fluid programming style.
Please note you cannot register two different BitVectors with the same name.
Raises
------
TypeError
Raised if user_defined_name is not a str
RegistrationError
If the server was unable to register the BitVector with the user_defined_name
See also
--------
unregister, attach, is_registered
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.client import generic_msg
if self.registered_name is not None and self.is_registered():
raise RegistrationError(f""This object is already registered as {self.registered_name}"")
generic_msg(
cmd=""register"",
args={
""name"": user_defined_name,
""objType"": self.special_objType,
""values"": self.values.name,
""width"": self.width,
""reverse"": self.reverse,
},
)
self.registered_name = user_defined_name
return self
",[],0,[],/client_dtypes.py_register
363,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_from_return_msg,"def from_return_msg(cls, rep_msg):
import json
data = json.loads(rep_msg)
return cls(
create_pdarray(data[""values""]),
width=data[""width""],
reverse=json.loads(data[""reverse""].lower()),
)
",[],0,[],/client_dtypes.py_from_return_msg
364,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py___init__,"def __init__(self, values, names, MSB_left=True, pad=""-"", separator="""", show_int=True):
self.names = tuple(names)
self.name = None  # This is needed to silence warnings of missing name during failed creation
if len(self.names) > 63:
raise ValueError(""Cannot represent more than 63 fields"")
if len(self.names) != len(set(self.names)):
raise ValueError(""Field names must be unique"")
if any(name == """" for name in self.names):
raise ValueError(""Names cannot be empty strings"")
if (separator != """") and (separator in self.names):
raise ValueError(""Separator cannot be a field name"")
self.namewidth = max(len(n) for n in self.names)
if (self.namewidth > 1) and (separator == """"):
raise ValueError(
""A non-empty separator must be specified when field names have more than one character""
)
if len(pad) > 1:
raise ValueError(""Pad must be single character or empty string"")
self.padchar = pad
self.pad = self.namewidth * self.padchar
self.separator = separator
width = len(self.names)
self.MSB_left = MSB_left
if self.MSB_left:
self.shifts = range(width - 1, -1, -1)
else:
self.shifts = range(width)
self.show_int = show_int
if isinstance(values, Strings):
values = self._convert_strings(values)
super().__init__(values, width=width, reverse=not MSB_left)
",[],0,[],/client_dtypes.py___init__
365,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py__convert_strings,"def _convert_strings(self, s):
""""""
Convert string field names to binary vectors.
""""""
values = zeros(s.size, dtype=bitType)
if self.separator == """":
for name, shift in zip(self.names, self.shifts):
bit = s.contains(name)
values = values | akcast(where(bit, 1 << shift, 0), bitType)
else:
sf, segs = s.flatten(self.separator, return_segments=True)
orig = broadcast(segs, arange(segs.size), sf.size)
g = GroupBy(orig)
for name, shift in zip(self.names, self.shifts):
bit = g.any(sf == name)[1]
values = values | akcast(where(bit, 1 << shift, 0), bitType)
return values
",[],0,[],/client_dtypes.py__convert_strings
366,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py__parse_scalar,"def _parse_scalar(self, s):
""""""
Convert a string of named fields to a binary value.
""""""
val = 0
if self.separator == """":
for name, shift in zip(self.names, self.shifts):
if name in s:
val |= 1 << shift
else:
fields = s.split(self.separator)
for name, shift in zip(self.names, self.shifts):
if name in fields:
val |= 1 << shift
return val
",[],0,[],/client_dtypes.py__parse_scalar
367,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_format,"def format(self, x):
""""""
Format a single binary value as a string of named fields.
""""""
s = """"
for i, shift in enumerate(self.shifts):
bitset = ((int(x) >> shift) & 1) == 1
if bitset:
s += ""{{:^{}s}}"".format(self.namewidth).format(self.names[i])
else:
s += self.pad
s += self.separator
if self.show_int:
s += "" ({:n})"".format(x)
return s
",[],0,[],/client_dtypes.py_format
368,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py___setitem__,"def __setitem__(self, key, value):
if isinstance(value, str):
v = self._parse_scalar(value)
return super().__setitem__(key, v)
else:
return super().__setitem__(key, value)
",[],0,[],/client_dtypes.py___setitem__
369,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py__cast,"def _cast(self, values):
return self.__class__(
values,
self.names,
MSB_left=self.MSB_left,
pad=self.padchar,
separator=self.separator,
show_int=self.show_int,
)
",[],0,[],/client_dtypes.py__cast
370,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py__binop,"def _binop(self, other, op):
if isinstance(other, str):
o = self._parse_scalar(other)
return super()._binop(o, op)
else:
return super()._binop(other, op)
",[],0,[],/client_dtypes.py__binop
371,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py__r_binop,"def _r_binop(self, other, op):
if isinstance(other, str):
o = self._parse_scalar(other)
return super()._r_binop(o, op)
else:
return super()._r_binop(other, op)
",[],0,[],/client_dtypes.py__r_binop
372,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_opeq,"def opeq(self, other, op):
if isinstance(other, str):
o = self._parse_scalar(other)
return super().opeq(o, op)
else:
return super().opeq(other, op)
",[],0,[],/client_dtypes.py_opeq
373,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_ip_address,"def ip_address(values):
""""""
Convert values to an Arkouda array of IP addresses.
Parameters
----------
values : list-like, integer pdarray, or IPv4
The integer IP addresses or IPv4 object.
Returns
-------
IPv4
The same IP addresses as an Arkouda array
Notes
-----
This helper is intended to help future proof changes made to
accomodate IPv6 and to prevent errors if a user inadvertently
casts a IPv4 instead of a int64 pdarray. It can also be used
for importing Python lists of IP addresses into Arkouda.
""""""
if isinstance(values, IPv4):
return values
if isinstance(values, pdarray):
return IPv4(values)
if isinstance(values, Strings):
raise NotImplementedError(""Strings to IP address not yet implemented"")
try:
return IPv4(array([int(_ip_address(x)) for x in values]))
except Exception as e:
raise RuntimeError(""Error converting non-arkouda object to list of IP addresses"") from e
",[],0,[],/client_dtypes.py_ip_address
374,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py___init__,"def __init__(self, values):
if not isinstance(values, pdarray) or values.dtype not in intTypes:
self.name = None  # This is needed to silence warnings of missing name during failed creation
raise TypeError(""Argument must be int64 pdarray"")
self.values = akcast(values, bitType)
super().__init__(
self.values.name,
self.values.dtype.name,
self.values.size,
self.values.ndim,
self.values.shape,
self.values.itemsize,
)
",[],0,[],/client_dtypes.py___init__
375,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_export_uint,"def export_uint(self):
return akcast(self.values, akuint64)
",[],0,[],/client_dtypes.py_export_uint
376,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_format,"def format(self, x):
""""""
Format a single integer IP address as a string.
""""""
if not isSupportedInt(x):
raise TypeError(""Argument must be an integer scalar"")
return str(_ip_address(int(x)))
",[],0,[],/client_dtypes.py_format
377,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_normalize,"def normalize(self, x):
""""""
Take in an IP address as a string, integer, or IPAddress object,
and convert it to an integer.
""""""
if not isSupportedInt(x):
x = int(_ip_address(x))
if x < 0:
raise ValueError(f""Not an IP address: {_ip_address(x)}"")
return x
",[],0,[],/client_dtypes.py_normalize
378,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py__is_supported_scalar,"def _is_supported_scalar(self, x):
try:
return True, self.normalize(x)
except ValueError:
return False, None
",[],0,[],/client_dtypes.py__is_supported_scalar
379,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py___str__,"def __str__(self):
from arkouda.client import pdarrayIterThresh
if self.size <= pdarrayIterThresh:
vals = [self.format(self.values[i]) for i in range(self.size)]
else:
vals = [self.format(self.values[i]) for i in range(3)]
vals.append(""..."")
vals.extend([self.format(self.values[i]) for i in range(self.size - 3, self.size)])
spaces = "" "" * (len(self.__class__.__name__) + 1)
return ""{}([{}],\n{})"".format(
self.__class__.__name__, "",\n{} "".format(spaces).join(vals), spaces
)
",[],0,[],/client_dtypes.py___str__
380,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py___repr__,"def __repr__(self):
return self.__str__()
",[],0,[],/client_dtypes.py___repr__
381,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_to_ndarray,"def to_ndarray(self):
""""""
Export array as a numpy array of integers.
""""""
return np.array([self.format(x) for x in self.values.to_ndarray()])
",['array'],1,['array([self.format(x) for x in self.values.to_ndarray()])'],/client_dtypes.py_to_ndarray
382,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_to_list,"def to_list(self):
""""""
Export array as a list of integers.
""""""
return self.to_ndarray().tolist()
",[],0,[],/client_dtypes.py_to_list
383,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py___getitem__,"def __getitem__(self, key):
if isSupportedInt(key):
return self.format(self.values[key])
else:
return self.__class__(self.values[key])
",[],0,[],/client_dtypes.py___getitem__
384,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py___setitem__,"def __setitem__(self, key, value):
isscalar, scalarval = self._is_supported_scalar(value)
if isscalar:
self.values[key] = scalarval
elif isinstance(value, self.__class__):
self.values[key] = value.values
else:
return NotImplemented
",[],0,[],/client_dtypes.py___setitem__
385,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py__binop,"def _binop(self, other, op):
isscalar, scalarval = self._is_supported_scalar(other)
if isscalar:
otherdata = scalarval
elif isinstance(other, self.__class__):
otherdata = other.values
elif isinstance(other, pdarray) and other.dtype in intTypes:
otherdata = other
else:
return NotImplemented
return self.values._binop(otherdata, op)
",[],0,[],/client_dtypes.py__binop
386,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py__r_binop,"def _r_binop(self, other, op):
isscalar, scalarval = self._is_supported_scalar(other)
if isscalar:
return self.values._r_binop(scalarval, op)
elif isinstance(other, pdarray) and other.dtype in intTypes:
return other._binop(self.values, op)
else:
return NotImplemented
",[],0,[],/client_dtypes.py__r_binop
387,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_opeq,"def opeq(self, other, op):
isscalar, scalarval = self._is_supported_scalar(other)
if isscalar:
otherdata = scalarval
elif isinstance(other, self.__class__):
otherdata = other.values
elif isinstance(other, pdarray) and other.dtype in intTypes:
otherdata = other
else:
return NotImplemented
self.values.opeq(otherdata, op)
",[],0,[],/client_dtypes.py_opeq
388,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_register,"def register(self, user_defined_name):
""""""
Register this IPv4 object and underlying components with the Arkouda server
Parameters
----------
user_defined_name : str
user defined name the IPv4 is to be registered under,
this will be the root name for underlying components
Returns
-------
IPv4
The same IPv4 which is now registered with the arkouda server and has an updated name.
This is an in-place modification, the original is returned to support
a fluid programming style.
Please note you cannot register two different IPv4s with the same name.
Raises
------
TypeError
Raised if user_defined_name is not a str
RegistrationError
If the server was unable to register the IPv4 with the user_defined_name
See also
--------
unregister, attach, is_registered
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.client import generic_msg
if self.registered_name is not None and self.is_registered():
raise RegistrationError(f""This object is already registered as {self.registered_name}"")
generic_msg(
cmd=""register"",
args={
""name"": user_defined_name,
""objType"": self.special_objType,
""array"": self.values,
},
)
self.registered_name = user_defined_name
return self
",[],0,[],/client_dtypes.py_register
389,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_to_hdf,"def to_hdf(
self,
prefix_path: str,
dataset: str = ""array"",
mode: str = ""truncate"",
file_type: str = ""distribute"",
",[],0,[],/client_dtypes.py_to_hdf
390,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_update_hdf,"def update_hdf(self, prefix_path: str, dataset: str = ""array"", repack: bool = True):
""""""
Override the pdarray implementation so that the special object type will be used.
""""""
from arkouda.client import generic_msg
from arkouda.io import (
_file_type_to_int,
_get_hdf_filetype,
_mode_str_to_int,
_repack_hdf,
)
file_type = _get_hdf_filetype(prefix_path + ""*"")
generic_msg(
cmd=""tohdf"",
args={
""values"": self,
""dset"": dataset,
""write_mode"": _mode_str_to_int(""append""),
""filename"": prefix_path,
""dtype"": self.dtype,
""objType"": self.special_objType,
""file_format"": _file_type_to_int(file_type),
""overwrite"": True,
},
)
if repack:
_repack_hdf(prefix_path)
",[],0,[],/client_dtypes.py_update_hdf
391,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_is_ipv4,"def is_ipv4(ip: Union[pdarray, IPv4], ip2: Optional[pdarray] = None) -> pdarray:
""""""
Indicate which values are ipv4 when passed data containing IPv4 and IPv6 values.
Parameters
----------
ip: pdarray (int64) or ak.IPv4
IPv4 value. High Bits of IPv6 if IPv6 is passed in.
ip2: pdarray (int64), Optional
Low Bits of IPv6. This is added for support when dealing with data that contains IPv6 as well.
Returns
-------
pdarray of bools indicating which indexes are IPv4.
See Also
--------
ak.is_ipv6
""""""
if isinstance(ip, IPv4):
ip = ip.values
if ip.dtype not in intTypes or (ip2 is not None and ip2.dtype not in intTypes):
raise TypeError(""ip and ip2 must be int64 pdarrays. ip2 is Optional."")
if ip2 is not None and ip.size != ip2.size:
raise RuntimeError(""When supplying a value for ip2, ip and ip2 must be the same size."")
if ip2 is not None:
ans = ip < 2**32
ans2 = ip2 == 0
return ans & ans2
else:
return ip < 2**32
",[],0,[],/client_dtypes.py_is_ipv4
392,/home/amandapotts/git/arkouda/arkouda/client_dtypes.py_is_ipv6,"def is_ipv6(ip: Union[pdarray, IPv4], ip2: Optional[pdarray] = None) -> pdarray:
""""""
Indicate which values are ipv6 when passed data containing IPv4 and IPv6 values.
Parameters
----------
ip: pdarray (int64) or ak.IPv4
High Bits of IPv6.
ip2: pdarray (int64), Optional
Low Bits of IPv6
Returns
-------
pdarray of bools indicating which indexes are IPv6.
See Also
--------
ak.is_ipv4
""""""
if isinstance(ip, IPv4):
ip = ip.values
if ip.dtype not in intTypes or (ip2 is not None and ip2.dtype not in intTypes):
raise TypeError(""ip and ip2 must be int64 pdarrays. ip2 is Optional."")
if ip2 is not None and ip.size != ip2.size:
raise RuntimeError(""When supplying a value for ip2, ip and ip2 must be the same size."")
if ip2 is not None:
ans = ip >= 2**32
ans2 = ip2 != 0
return ans | ans2
else:
return ip >= 2**32
",[],0,[],/client_dtypes.py_is_ipv6
393,/home/amandapotts/git/arkouda/arkouda/io_util.py_get_directory,"def get_directory(path: str) -> Path:
""""""
Creates the directory if it does not exist and then
returns the corresponding Path object
Parameters
----------
path : str
The path to the directory
Returns
-------
str
Path object corresponding to the directory
Raises
------
ValueError
Raised if there's an error in reading an
existing directory or creating a new one
""""""
try:
Path(path).mkdir(parents=True, exist_ok=True)
return Path(path)
except Exception as e:
raise ValueError(e)
",[],0,[],/io_util.py_get_directory
394,/home/amandapotts/git/arkouda/arkouda/io_util.py_write_line_to_file,"def write_line_to_file(path: str, line: str) -> None:
""""""
Writes a line to the requested file. Note: if the file
does not exist, the file is created first and then
the specified line is written to it.
Parameters
----------
path : str
Path to the target file
line : str
Line to be written to the file
Returns
-------
None
Raises
------
UnsupportedOption
Raised if there's an error in creating or
writing to the file
""""""
with open(path, ""a"") as f:
f.write("""".join([line, ""\n""]))
",[],0,[],/io_util.py_write_line_to_file
395,/home/amandapotts/git/arkouda/arkouda/io_util.py_delimited_file_to_dict,"def delimited_file_to_dict(path: str, delimiter: str = "","") -> Dict[str, str]:
""""""
Returns a dictionary populated by lines from a file where
the first delimited element of each line is the key and
the second delimited element is the value.
Parameters
----------
path : str
Path to the file
delimiter : str
Delimiter separating key and value
Returns
-------
Mapping[str,str]
Dictionary containing key,value pairs derived from each
line of delimited strings
Raises
------
UnsupportedOperation
Raised if there's an error in reading the file
""""""
values: Dict[str, str] = {}
with open(path, ""a+"") as f:
f.seek(0)
for line in f:
line = line.rstrip()
key, value = line.split(delimiter)
values[key] = value
return values
",[],0,[],/io_util.py_delimited_file_to_dict
396,/home/amandapotts/git/arkouda/arkouda/io_util.py_dict_to_delimited_file,"def dict_to_delimited_file(path: str, values: Mapping[Any, Any], delimiter: str = "","") -> None:
""""""
Writes a dictionary to delimited lines in a file where
the first delimited element of each line is the dict key
and the second delimited element is the dict value. If the
file does not exist, it is created and then written to.
Parameters
----------
path : str
Path to the file
delimiter
Delimiter separating key and value
Returns
-------
None
Raises
------
OError
Raised if there's an error opening or writing to the
specified file
ValueError
Raised if the delimiter is not supported
""""""
if "","" == delimiter:
with open(path, ""w+"") as f:
for key, value in values.items():
f.write(f""{key},{value}\n"")
else:
raise ValueError(f""the delimiter {delimiter} is not supported"")
",[],0,[],/io_util.py_dict_to_delimited_file
397,/home/amandapotts/git/arkouda/arkouda/util.py_identity,"def identity(x):
return x
",[],0,[],/util.py_identity
398,/home/amandapotts/git/arkouda/arkouda/util.py_get_callback,"def get_callback(x):
if type(x) in {Datetime, Timedelta, IPv4}:
return type(x)
elif hasattr(x, ""_cast""):
return x._cast
elif isinstance(x, BitVector):
return BitVectorizer(width=x.width, reverse=x.reverse)
else:
return identity
",[],0,[],/util.py_get_callback
399,/home/amandapotts/git/arkouda/arkouda/util.py_concatenate,"def concatenate(items, ordered=True):
warn(
""This function is deprecated and will be removed in a later version of Arkouda.""
"" Use arkouda.util.generic_concat(items, ordered) instead."",
DeprecationWarning,
)
return generic_concat(items, ordered=ordered)
",[],0,[],/util.py_concatenate
400,/home/amandapotts/git/arkouda/arkouda/util.py_generic_concat,"def generic_concat(items, ordered=True):
from arkouda.pdarraysetops import concatenate as pdarrayconcatenate
types = {type(x) for x in items}
if len(types) != 1:
raise TypeError(f""Items must all have same type: {types}"")
t = types.pop()
return (
t.concat(items, ordered=ordered)
if hasattr(t, ""concat"")
else pdarrayconcatenate(items, ordered=ordered)
)
",[],0,[],/util.py_generic_concat
401,/home/amandapotts/git/arkouda/arkouda/util.py_report_mem,"def report_mem(pre=""""):
cfg = get_config()
used = get_mem_used() / (cfg[""numLocales""] * cfg[""physicalMemory""])
print(f""{pre} mem use: {get_mem_used()/(1024**4): .2f} TB ({used:.1%})"")
",[],0,[],/util.py_report_mem
402,/home/amandapotts/git/arkouda/arkouda/util.py_enrich_inplace,"def enrich_inplace(data, keynames, aggregations, **kwargs):
warn(
""This function is deprecated and will be removed in a later version of Arkouda."",
DeprecationWarning,
)
try:
keys = data[keynames]
except (KeyError, TypeError):
keys = [data[k] for k in keynames]
g = GroupBy(keys, **kwargs)
for resname, (reduction, values) in aggregations.items():
try:
values = data[values]
except (KeyError, TypeError):
pass
if reduction == ""count"":
pergroupval = g.count()[1]
else:
pergroupval = g.aggregate(values, reduction)[1]
data[resname] = g.broadcast(pergroupval, permute=True)
",[],0,[],/util.py_enrich_inplace
403,/home/amandapotts/git/arkouda/arkouda/util.py_expand,"def expand(size, segs, vals):
""""""
Expand an array with values placed into the indicated segments.
Parameters
----------
size : ak.pdarray
The size of the array to be expanded
segs : ak.pdarray
The indices where the values should be placed
vals : ak.pdarray
The values to be placed in each segment
Returns
-------
pdarray
The expanded array.
Notes
-----
This function (with different order of arguments) is now in arkouda
proper as ak.broadcast. It is retained here for backwards compatibility.
""""""
warn(
""This function is deprecated and will be removed in a later version of Arkouda.""
"" Use arkouda.broadcast(segments, values, size) instead."",
DeprecationWarning,
)
return broadcast(segs, vals, size=size)
",[],0,[],/util.py_expand
404,/home/amandapotts/git/arkouda/arkouda/util.py_invert_permutation,"def invert_permutation(perm):
""""""
Find the inverse of a permutation array.
Parameters
----------
perm : ak.pdarray
The permutation array.
Returns
-------
ak.array
The inverse of the permutation array.
""""""
if unique(perm).size != perm.size:
raise ValueError(""The array is not a permutation."")
return coargsort([perm, arange(0, perm.size)])
",[],0,[],/util.py_invert_permutation
405,/home/amandapotts/git/arkouda/arkouda/util.py_most_common,"def most_common(g, values):
warn(
""This function is deprecated and will be removed in a later version of Arkouda.""
"" Use arkouda.GroupBy.most_common(values) instead."",
DeprecationWarning,
)
return g.most_common(values)
",[],0,[],/util.py_most_common
406,/home/amandapotts/git/arkouda/arkouda/util.py_convert_if_categorical,"def convert_if_categorical(values):
""""""
Convert a Categorical array to Strings for display
""""""
if isinstance(values, Categorical):
values = values.categories[values.codes]
return values
",[],0,[],/util.py_convert_if_categorical
407,/home/amandapotts/git/arkouda/arkouda/util.py_register,"def register(obj, name):
""""""
Register an arkouda object with a user-specified name. Backwards compatible
with earlier arkouda versions.
""""""
return obj.register(name)
",[],0,[],/util.py_register
408,/home/amandapotts/git/arkouda/arkouda/util.py_attach,"def attach(name: str):
from arkouda.dataframe import DataFrame
from arkouda.pdarrayclass import pdarray
from arkouda.index import Index, MultiIndex
from arkouda.series import Series
rep_msg = json.loads(cast(str, generic_msg(cmd=""attach"", args={""name"": name})))
rtn_obj = None
if rep_msg[""objType""].lower() == pdarray.objType.lower():
rtn_obj = create_pdarray(rep_msg[""create""])
elif rep_msg[""objType""].lower() == Strings.objType.lower():
rtn_obj = Strings.from_return_msg(rep_msg[""create""])
elif rep_msg[""objType""].lower() == Datetime.special_objType.lower():
rtn_obj = Datetime(create_pdarray(rep_msg[""create""]))
elif rep_msg[""objType""].lower() == Timedelta.special_objType.lower():
rtn_obj = Timedelta(create_pdarray(rep_msg[""create""]))
elif rep_msg[""objType""].lower() == IPv4.special_objType.lower():
rtn_obj = IPv4(create_pdarray(rep_msg[""create""]))
elif rep_msg[""objType""].lower() == SegArray.objType.lower():
rtn_obj = SegArray.from_return_msg(rep_msg[""create""])
elif rep_msg[""objType""].lower() == DataFrame.objType.lower():
rtn_obj = DataFrame.from_return_msg(rep_msg[""create""])
elif rep_msg[""objType""].lower() == GroupBy.objType.lower():
rtn_obj = GroupBy.from_return_msg(rep_msg[""create""])
elif rep_msg[""objType""].lower() == Categorical.objType.lower():
rtn_obj = Categorical.from_return_msg(rep_msg[""create""])
elif (
rep_msg[""objType""].lower() == Index.objType.lower()
or rep_msg[""objType""].lower() == MultiIndex.objType.lower()
):
rtn_obj = Index.from_return_msg(rep_msg[""create""])
elif rep_msg[""objType""].lower() == Series.objType.lower():
rtn_obj = Series.from_return_msg(rep_msg[""create""])
elif rep_msg[""objType""].lower() == BitVector.special_objType.lower():
rtn_obj = BitVector.from_return_msg(rep_msg[""create""])
if rtn_obj is not None:
rtn_obj.registered_name = name
return rtn_obj
",[],0,[],/util.py_attach
409,/home/amandapotts/git/arkouda/arkouda/util.py_unregister,"def unregister(name: str):
rep_msg = cast(str, generic_msg(cmd=""unregister"", args={""name"": name}))
return rep_msg
",[],0,[],/util.py_unregister
410,/home/amandapotts/git/arkouda/arkouda/util.py_is_registered,"def is_registered(name: str, as_component: bool = False) -> bool:
""""""
Determine if the name provided is associated with a registered Object
Parameters
----------
name: str
The name to check for in the registry
as_component: bool
Default: False
When True, the name will be checked to determine if it is registered as a component of
a registered object
Return
-------
bool
""""""
return name in list_registry()[""Components"" if as_component else ""Objects""]
",[],0,[],/util.py_is_registered
411,/home/amandapotts/git/arkouda/arkouda/util.py_register_all,"def register_all(data: dict):
""""""
Register all objects in the provided dictionary
Parameters
-----------
data: dict
Maps name to register the object to the object. For example, {""MyArray"": ak.array([0, 1, 2])
Returns
--------
None
""""""
for reg_name, obj in data.items():
register(obj, reg_name)
",[],0,[],/util.py_register_all
412,/home/amandapotts/git/arkouda/arkouda/util.py_unregister_all,"def unregister_all(names: list):
""""""
Unregister all names provided
Parameters
-----------
names : list
List of names used to register objects to be unregistered
Returns
--------
None
""""""
for n in names:
unregister(n)
",[],0,[],/util.py_unregister_all
413,/home/amandapotts/git/arkouda/arkouda/util.py_attach_all,"def attach_all(names: list):
""""""
Attach to all objects registered with the names provide
Parameters
-----------
names: list
List of names to attach to
Returns
--------
dict
""""""
return {n: attach(n) for n in names}
",[],0,[],/util.py_attach_all
414,/home/amandapotts/git/arkouda/arkouda/util.py_broadcast_dims,"def broadcast_dims(sa: Sequence[int], sb: Sequence[int]) -> Tuple[int, ...]:
""""""
Algorithm to determine shape of broadcasted PD array given two array shapes
see: https://data-apis.org/array-api/latest/API_specification/broadcasting.html#algorithm
""""""
Na = len(sa)
Nb = len(sb)
N = max(Na, Nb)
shapeOut = [0 for i in range(N)]
i = N - 1
while i >= 0:
n1 = Na - N + i
n2 = Nb - N + i
d1 = sa[n1] if n1 >= 0 else 1
d2 = sb[n2] if n2 >= 0 else 1
if d1 == 1:
shapeOut[i] = d2
elif d2 == 1:
shapeOut[i] = d1
elif d1 == d2:
shapeOut[i] = d1
else:
raise ValueError(""Incompatible dimensions for broadcasting"")
i -= 1
return tuple(shapeOut)
",[],0,[],/util.py_broadcast_dims
415,/home/amandapotts/git/arkouda/arkouda/pdarraycreation.py_from_series,"def from_series(series: pd.Series, dtype: Optional[Union[type, str]] = None) -> Union[pdarray, Strings]:
""""""
Converts a Pandas Series to an Arkouda pdarray or Strings object. If
dtype is None, the dtype is inferred from the Pandas Series. Otherwise,
the dtype parameter is set if the dtype of the Pandas Series is to be
overridden or is  unknown (for example, in situations where the Series
dtype is object).
Parameters
----------
series : Pandas Series
The Pandas Series with a dtype of bool, float64, int64, or string
dtype : Optional[type]
The valid dtype types are np.bool, np.float64, np.int64, and np.str
Returns
-------
Union[pdarray,Strings]
Raises
------
TypeError
Raised if series is not a Pandas Series object
ValueError
Raised if the Series dtype is not bool, float64, int64, string, datetime, or timedelta
Examples
--------
>>> ak.from_series(pd.Series(np.random.randint(0,10,5)))
array([9, 0, 4, 7, 9])
>>> ak.from_series(pd.Series(['1', '2', '3', '4', '5']),dtype=np.int64)
array([1, 2, 3, 4, 5])
>>> ak.from_series(pd.Series(np.random.uniform(low=0.0,high=1.0,size=3)))
array([0.57600036956445599, 0.41619265571741659, 0.6615356693784662])
>>> ak.from_series(pd.Series(['0.57600036956445599', '0.41619265571741659',
'0.6615356693784662']), dtype=np.float64)
array([0.57600036956445599, 0.41619265571741659, 0.6615356693784662])
>>> ak.from_series(pd.Series(np.random.choice([True, False],size=5)))
array([True, False, True, True, True])
>>> ak.from_series(pd.Series(['True', 'False', 'False', 'True', 'True']), dtype=np.bool)
array([True, True, True, True, True])
>>> ak.from_series(pd.Series(['a', 'b', 'c', 'd', 'e'], dtype=""string""))
array(['a', 'b', 'c', 'd', 'e'])
>>> ak.from_series(pd.Series(['a', 'b', 'c', 'd', 'e']),dtype=np.str)
array(['a', 'b', 'c', 'd', 'e'])
>>> ak.from_series(pd.Series(pd.to_datetime(['1/1/2018', np.datetime64('2018-01-01')])))
array([1514764800000000000, 1514764800000000000])
Notes
-----
The supported datatypes are bool, float64, int64, string, and datetime64[ns]. The
data type is either inferred from the the Series or is set via the dtype parameter.
Series of datetime or timedelta are converted to Arkouda arrays of dtype int64 (nanoseconds)
A Pandas Series containing strings has a dtype of object. Arkouda assumes the Series
contains strings and sets the dtype to str
""""""
if not dtype:
dt = series.dtype.name
else:
dt = str(dtype)
try:
""""""
If the Series has a object dtype, set dtype to string to comply with method
signature that does not require a dtype
non-str dtypes from the input np or Python array.
""""""
if dt == ""object"":
dt = ""string""
n_array = series.to_numpy(dtype=SeriesDTypes[dt])
except KeyError:
raise ValueError(
f""dtype {dt} is unsupported. Supported dtypes are bool, float64, int64, string, ""
f""datetime64[ns], and timedelta64[ns]""
)
return array(n_array)
","['bool', 'float64', 'int64', 'str', 'random.randint', 'int64', 'random.uniform', 'float64', 'random.choice', 'bool', 'str', 'datetime64']",12,"['random.randint(0,10,5)))', 'random.uniform(low=0.0,high=1.0,size=3)))', 'random.choice([True, False],size=5)))', ""datetime64('2018-01-01')])))""]",/pdarraycreation.py_from_series
416,/home/amandapotts/git/arkouda/arkouda/pdarraycreation.py__array_memview,"def _array_memview(a) -> memoryview:
if (get_byteorder(a.dtype) == ""<"" and get_server_byteorder() == ""big"") or (
get_byteorder(a.dtype) == "">"" and get_server_byteorder() == ""little""
):
return memoryview(a.byteswap())
else:
return memoryview(a)
",[],0,[],/pdarraycreation.py__array_memview
417,/home/amandapotts/git/arkouda/arkouda/pdarraycreation.py_bigint_from_uint_arrays,"def bigint_from_uint_arrays(arrays, max_bits=-1):
""""""
Create a bigint pdarray from an iterable of uint pdarrays.
The first item in arrays will be the highest 64 bits and
the last item will be the lowest 64 bits.
Parameters
----------
arrays : Sequence[pdarray]
An iterable of uint pdarrays used to construct the bigint pdarray.
The first item in arrays will be the highest 64 bits and
the last item will be the lowest 64 bits.
max_bits : int
Specifies the maximum number of bits
Returns
-------
pdarray
bigint pdarray constructed from uint arrays
Raises
------
TypeError
Raised if any pdarray in arrays has a dtype other than uint or
if the pdarrays are not the same size.
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
pdarray.bigint_to_uint_arrays
Examples
--------
>>> a = ak.bigint_from_uint_arrays([ak.ones(5, dtype=ak.uint64), ak.arange(5, dtype=ak.uint64)])
>>> a
array([""18446744073709551616"" ""18446744073709551617"" ""18446744073709551618""
""18446744073709551619"" ""18446744073709551620""])
>>> a.dtype
dtype(bigint)
>>> all(a[i] == 2**64 + i for i in range(5))
True
""""""
if not all(isinstance(a, pdarray) and a.dtype == akuint64 for a in arrays):
raise TypeError(""Sequence must contain only uint pdarrays"")
if len({a.size for a in arrays}) != 1:
raise TypeError(""All pdarrays must be same size"")
if not isinstance(arrays, list):
arrays = list(arrays)
if max_bits != -1:
max_num_arrays = (max_bits // 64) + (max_bits % 64 != 0)
if len(arrays) > max_num_arrays:
arrays = arrays[-max_num_arrays:]
return create_pdarray(
generic_msg(
cmd=""big_int_creation"",
args={
""arrays"": arrays,
""num_arrays"": len(arrays),
""len"": arrays[0].size,
""max_bits"": max_bits,
},
)
)
",[],0,[],/pdarraycreation.py_bigint_from_uint_arrays
418,/home/amandapotts/git/arkouda/arkouda/pdarraycreation.py_zeros,"def zeros(
size: Union[int_scalars, str],
dtype: Union[np.dtype, type, str, BigInt] = float64,
max_bits: Optional[int] = None,
",['dtype'],1,[],/pdarraycreation.py_zeros
419,/home/amandapotts/git/arkouda/arkouda/pdarraycreation.py_ones,"def ones(
size: Union[int_scalars, str],
dtype: Union[np.dtype, type, str, BigInt] = float64,
max_bits: Optional[int] = None,
",['dtype'],1,[],/pdarraycreation.py_ones
420,/home/amandapotts/git/arkouda/arkouda/pdarraycreation.py_full,"def full(
size: Union[int_scalars, str],
fill_value: Union[numeric_scalars, str],
dtype: Union[np.dtype, type, str, BigInt] = float64,
max_bits: Optional[int] = None,
",['dtype'],1,[],/pdarraycreation.py_full
421,/home/amandapotts/git/arkouda/arkouda/pdarraycreation.py__full_string,"def _full_string(
size: Union[int_scalars, str],
fill_value: str,
",[],0,[],/pdarraycreation.py__full_string
422,/home/amandapotts/git/arkouda/arkouda/pdarraycreation.py_zeros_like,"def zeros_like(pda: pdarray) -> pdarray:
""""""
Create a zero-filled pdarray of the same size and dtype as an existing
pdarray.
Parameters
----------
pda : pdarray
Array to use for size and dtype
Returns
-------
pdarray
Equivalent to ak.zeros(pda.size, pda.dtype)
Raises
------
TypeError
Raised if the pda parameter is not a pdarray.
See Also
--------
zeros, ones_like
Examples
--------
>>> zeros = ak.zeros(5, dtype=ak.int64)
>>> ak.zeros_like(zeros)
array([0, 0, 0, 0, 0])
>>> zeros = ak.zeros(5, dtype=ak.float64)
>>> ak.zeros_like(zeros)
array([0, 0, 0, 0, 0])
>>> zeros = ak.zeros(5, dtype=ak.bool)
>>> ak.zeros_like(zeros)
array([False, False, False, False, False])
""""""
return zeros(pda.size, pda.dtype, pda.max_bits)
",[],0,[],/pdarraycreation.py_zeros_like
423,/home/amandapotts/git/arkouda/arkouda/pdarraycreation.py_ones_like,"def ones_like(pda: pdarray) -> pdarray:
""""""
Create a one-filled pdarray of the same size and dtype as an existing
pdarray.
Parameters
----------
pda : pdarray
Array to use for size and dtype
Returns
-------
pdarray
Equivalent to ak.ones(pda.size, pda.dtype)
Raises
------
TypeError
Raised if the pda parameter is not a pdarray.
See Also
--------
ones, zeros_like
Notes
-----
Logic for generating the pdarray is delegated to the ak.ones method.
Accordingly, the supported dtypes match are defined by the ak.ones method.
Examples
--------
>>> ones = ak.ones(5, dtype=ak.int64)
>>> ak.ones_like(ones)
array([1, 1, 1, 1, 1])
>>> ones = ak.ones(5, dtype=ak.float64)
>>> ak.ones_like(ones)
array([1, 1, 1, 1, 1])
>>> ones = ak.ones(5, dtype=ak.bool)
>>> ak.ones_like(ones)
array([True, True, True, True, True])
""""""
return ones(pda.size, pda.dtype, pda.max_bits)
",[],0,[],/pdarraycreation.py_ones_like
424,/home/amandapotts/git/arkouda/arkouda/pdarraycreation.py_full_like,"def full_like(pda: pdarray, fill_value: numeric_scalars) -> pdarray:
""""""
Create a pdarray filled with fill_value of the same size and dtype as an existing
pdarray.
Parameters
----------
pda: pdarray
Array to use for size and dtype
fill_value: int_scalars
Value with which the array will be filled
Returns
-------
pdarray
Equivalent to ak.full(pda.size, fill_value, pda.dtype)
Raises
------
TypeError
Raised if the pda parameter is not a pdarray.
See Also
--------
ones_like, zeros_like
Notes
-----
Logic for generating the pdarray is delegated to the ak.full method.
Accordingly, the supported dtypes match are defined by the ak.full method.
Examples
--------
>>> full = ak.full(5, 7, dtype=ak.int64)
>>> ak.full_like(full)
array([7, 7, 7, 7, 7])
>>> full = ak.full(5, 9, dtype=ak.float64)
>>> ak.full_like(full)
array([9, 9, 9, 9, 9])
>>> full = ak.full(5, 5, dtype=ak.bool)
>>> ak.full_like(full)
array([True, True, True, True, True])
""""""
return full(pda.size, fill_value, pda.dtype, pda.max_bits)
",[],0,[],/pdarraycreation.py_full_like
425,/home/amandapotts/git/arkouda/arkouda/pdarraycreation.py_arange,"def arange(*args, **kwargs) -> pdarray:
""""""
arange([start,] stop[, stride,] dtype=int64)
Create a pdarray of consecutive integers within the interval [start, stop).
If only one arg is given then arg is the stop parameter. If two args are
given, then the first arg is start and second is stop. If three args are
given, then the first arg is start, second is stop, third is stride.
The return value is cast to type dtype
Parameters
----------
start: int_scalars, optional
Starting value (inclusive)
stop: int_scalars
Stopping value (exclusive)
stride: int_scalars, optional
The difference between consecutive elements, the default stride is 1,
if stride is specified then start must also be specified.
dtype: np.dtype, type, or str
The target dtype to cast values to
max_bits: int
Specifies the maximum number of bits
Returns
-------
pdarray, dtype
Integers from start (inclusive) to stop (exclusive) by stride
Raises
------
TypeError
Raised if start, stop, or stride is not an int object
ZeroDivisionError
Raised if stride == 0
See Also
--------
linspace, zeros, ones, randint
Notes
-----
Negative strides result in decreasing values. Currently, only int64
pdarrays can be created with this method. For float64 arrays, use
the linspace method.
Examples
--------
>>> ak.arange(0, 5, 1)
array([0, 1, 2, 3, 4])
>>> ak.arange(5, 0, -1)
array([5, 4, 3, 2, 1])
>>> ak.arange(0, 10, 2)
array([0, 2, 4, 6, 8])
>>> ak.arange(-5, -10, -1)
array([-5, -6, -7, -8, -9])
""""""
if len(args) == 1:
start = 0
stop = args[0]
stride = 1
if len(args) == 2:
start = args[0]
stop = args[1]
stride = 1
if len(args) == 3:
start = args[0]
stop = args[1]
stride = args[2]
if stride == 0:
raise ZeroDivisionError(""division by zero"")
dtype = akint64 if ""dtype"" not in kwargs.keys() else kwargs[""dtype""]
if isSupportedInt(start) and isSupportedInt(stop) and isSupportedInt(stride):
arg_dtypes = [resolve_scalar_dtype(arg) for arg in (start, stop, stride)]
max_bits = -1 if ""max_bits"" not in kwargs.keys() else kwargs[""max_bits""]
arg_dtype = ""int64""
if dtype in [""bigint"", bigint] or ""bigint"" in arg_dtypes or max_bits != -1:
arg_dtype = ""bigint""
elif ""uint64"" in arg_dtypes:
arg_dtype = ""uint64""
if stride < 0:
stop = stop + 2
repMsg = generic_msg(
cmd=""arange"", args={""start"": start, ""stop"": stop, ""stride"": stride, ""dtype"": arg_dtype}
)
return (
create_pdarray(repMsg, max_bits=max_bits)
if dtype == akint64
else array(create_pdarray(repMsg), max_bits=max_bits, dtype=dtype)
)
else:
raise TypeError(
f""start,stop,stride must be type int, np.int64, or np.uint64 {start} {stop} {stride}""
)
","['dtype', 'int64', 'uint64']",3,[],/pdarraycreation.py_arange
426,/home/amandapotts/git/arkouda/arkouda/pdarraycreation.py_linspace,"def linspace(start: numeric_scalars, stop: numeric_scalars, length: int_scalars) -> pdarray:
""""""
Create a pdarray of linearly-spaced floats in a closed interval.
Parameters
----------
start : numeric_scalars
Start of interval (inclusive)
stop : numeric_scalars
End of interval (inclusive)
length : int_scalars
Number of points
Returns
-------
pdarray, float64
Array of evenly spaced float values along the interval
Raises
------
TypeError
Raised if start or stop is not a float or int or if length is not an int
See Also
--------
arange
Notes
-----
If that start is greater than stop, the pdarray values are generated
in descending order.
Examples
--------
>>> ak.linspace(0, 1, 5)
array([0, 0.25, 0.5, 0.75, 1])
>>> ak.linspace(start=1, stop=0, length=5)
array([1, 0.75, 0.5, 0.25, 0])
>>> ak.linspace(start=-5, stop=0, length=5)
array([-5, -3.75, -2.5, -1.25, 0])
""""""
if not isSupportedNumber(start) or not isSupportedNumber(stop):
raise TypeError(""both start and stop must be an int, np.int64, float, or np.float64"")
if not isSupportedNumber(length):
raise TypeError(""length must be an int or int64"")
repMsg = generic_msg(cmd=""linspace"", args={""start"": start, ""stop"": stop, ""len"": length})
return create_pdarray(repMsg)
","['int64', 'float64']",2,[],/pdarraycreation.py_linspace
427,/home/amandapotts/git/arkouda/arkouda/pdarraycreation.py_randint,"def randint(
low: numeric_scalars,
high: numeric_scalars,
size: Union[int_scalars, Tuple[int_scalars, ...]] = 1,
dtype=akint64,
seed: int_scalars = None,
",[],0,[],/pdarraycreation.py_randint
428,/home/amandapotts/git/arkouda/arkouda/pdarraycreation.py_uniform,"def uniform(
size: int_scalars,
low: numeric_scalars = float(0.0),
high: numeric_scalars = 1.0,
seed: Union[None, int_scalars] = None,
",[],0,[],/pdarraycreation.py_uniform
429,/home/amandapotts/git/arkouda/arkouda/pdarraycreation.py_standard_normal,"def standard_normal(size: int_scalars, seed: Union[None, int_scalars] = None) -> pdarray:
""""""
Draw real numbers from the standard normal distribution.
Parameters
----------
size : int_scalars
The number of samples to draw (size of the returned array)
seed : int_scalars
Value used to initialize the random number generator
Returns
-------
pdarray, float64
The array of random numbers
Raises
------
TypeError
Raised if size is not an int
ValueError
Raised if size < 0
See Also
--------
randint
Notes
-----
For random samples from :math:`N(\\mu, \\sigma^2)`, use:
``(sigma * standard_normal(size)) + mu``
Examples
--------
>>> ak.standard_normal(3,1)
array([-0.68586185091150265, 1.1723810583573375, 0.567584107142031])
""""""
if size < 0:
raise ValueError(""The size parameter must be > 0"")
return create_pdarray(
generic_msg(
cmd=""randomNormal"", args={""size"": NUMBER_FORMAT_STRINGS[""int64""].format(size), ""seed"": seed}
)
)
",[],0,[],/pdarraycreation.py_standard_normal
430,/home/amandapotts/git/arkouda/arkouda/pdarraycreation.py_random_strings_uniform,"def random_strings_uniform(
minlen: int_scalars,
maxlen: int_scalars,
size: int_scalars,
characters: str = ""uppercase"",
seed: Union[None, int_scalars] = None,
",[],0,[],/pdarraycreation.py_random_strings_uniform
431,/home/amandapotts/git/arkouda/arkouda/pdarraycreation.py_random_strings_lognormal,"def random_strings_lognormal(
logmean: numeric_scalars,
logstd: numeric_scalars,
size: int_scalars,
characters: str = ""uppercase"",
seed: Optional[int_scalars] = None,
",[],0,[],/pdarraycreation.py_random_strings_lognormal
432,/home/amandapotts/git/arkouda/arkouda/pdarraysetops.py__in1d_single,"def _in1d_single(
pda1: Union[pdarray, Strings, ""Categorical""],  # type: ignore
pda2: Union[pdarray, Strings, ""Categorical""],  # type: ignore
invert: bool = False,
",[],0,[],/pdarraysetops.py__in1d_single
433,/home/amandapotts/git/arkouda/arkouda/pdarraysetops.py_in1d,"def in1d(
pda1: groupable,
pda2: groupable,
assume_unique: bool = False,
symmetric: bool = False,
invert: bool = False,
",[],0,[],/pdarraysetops.py_in1d
434,/home/amandapotts/git/arkouda/arkouda/pdarraysetops.py_in1dmulti,"def in1dmulti(a, b, assume_unique=False, symmetric=False):
""""""
Alias for in1d to maintain backwards compatibility.
Calls in1d.
""""""
return in1d(a, b, assume_unique=assume_unique, symmetric=symmetric)
",[],0,[],/pdarraysetops.py_in1dmulti
435,/home/amandapotts/git/arkouda/arkouda/pdarraysetops.py_indexof1d,"def indexof1d(keys: groupable, arr: groupable) -> Union[pdarray, groupable]:
""""""
Returns an integer array of the index values where the values of the first
array appear in the second.
Parameters
----------
keys : pdarray or Strings or Categorical
Input array of values to find the indices of in `arr`.
arr : pdarray or Strings or Categorical
The values to search.
Returns
-------
pdarray, int
The indices of the values of `keys` in `arr`.
Raises
------
TypeError
Raised if either `keys` or `arr` is not a pdarray, Strings, or
Categorical object
RuntimeError
Raised if the dtype of either array is not supported
""""""
from arkouda.categorical import Categorical as Categorical_
if isinstance(keys, (pdarray, Strings, Categorical_)):
if isinstance(keys, (Strings, Categorical_)) and not isinstance(arr, (Strings, Categorical_)):
raise TypeError(""Arguments must have compatible types, Strings/Categorical"")
elif isinstance(keys, pdarray) and not isinstance(arr, pdarray):
raise TypeError(""If keys is pdarray, arr must also be pdarray"")
repMsg = generic_msg(
cmd=""indexof1d"",
args={""keys"": keys, ""arr"": arr},
)
return create_pdarray(cast(str, repMsg))
",[],0,[],/pdarraysetops.py_indexof1d
436,/home/amandapotts/git/arkouda/arkouda/pdarraysetops.py_concatenate,"def concatenate(
arrays: Sequence[Union[pdarray, Strings, ""Categorical"", ]],  # type: ignore
ordered: bool = True,
",[],0,[],/pdarraysetops.py_concatenate
437,/home/amandapotts/git/arkouda/arkouda/pdarraysetops.py_multiarray_setop_validation,"def multiarray_setop_validation(
pda1: Sequence[groupable_element_type], pda2: Sequence[groupable_element_type]
",[],0,[],/pdarraysetops.py_multiarray_setop_validation
438,/home/amandapotts/git/arkouda/arkouda/pdarraysetops.py_union1d,"def union1d(
pda1: groupable,
pda2: groupable,
",[],0,[],/pdarraysetops.py_union1d
439,/home/amandapotts/git/arkouda/arkouda/pdarraysetops.py_intersect1d,"def intersect1d(
pda1: groupable, pda2: groupable, assume_unique: bool = False
",[],0,[],/pdarraysetops.py_intersect1d
440,/home/amandapotts/git/arkouda/arkouda/pdarraysetops.py_setdiff1d,"def setdiff1d(
pda1: groupable, pda2: groupable, assume_unique: bool = False
",[],0,[],/pdarraysetops.py_setdiff1d
441,/home/amandapotts/git/arkouda/arkouda/pdarraysetops.py_setxor1d,"def setxor1d(pda1: groupable, pda2: groupable, assume_unique: bool = False) -> Union[pdarray, groupable]:
""""""
Find the set exclusive-or (symmetric difference) of two arrays.
Return the sorted, unique values that are in only one (not both) of the
input arrays.
Parameters
----------
pda1 : pdarray/Sequence[pdarray, Strings, Categorical]
Input array/Sequence of groupable objects
pda2 : pdarray/List
Input array/sequence of groupable objects
assume_unique : bool
If True, the input arrays are both assumed to be unique, which
can speed up the calculation.  Default is False.
Returns
-------
pdarray/groupable
Sorted 1D array/List of sorted pdarrays of unique values that are in only one of the input
arrays.
Raises
------
TypeError
Raised if either pda1 or pda2 is not a pdarray
RuntimeError
Raised if the dtype of either pdarray is not supported
Notes
-----
ak.setxor1d is not supported for bool or float64 pdarrays
Examples
--------
>>> a = ak.array([1, 2, 3, 2, 4])
>>> b = ak.array([2, 3, 5, 7, 5])
>>> ak.setxor1d(a,b)
array([1, 4, 5, 7])
>>> a = ak.arange(1, 6)
>>> b = ak.array([1, 5, 3, 4, 2])
>>> c = ak.array([1, 4, 3, 2, 5])
>>> d = ak.array([1, 2, 3, 5, 4])
>>> multia = [a, a, a]
>>> multib = [b, c, d]
>>> ak.setxor1d(multia, multib)
[array([2, 2, 4, 4, 5, 5]), array([2, 5, 2, 4, 4, 5]), array([2, 4, 5, 4, 2, 5])]
""""""
from arkouda.categorical import Categorical as Categorical_
if (
isinstance(pda1, (pdarray, Strings, Categorical_))
and isinstance(pda2, (pdarray, Strings, Categorical_))
and type(pda1) is type(pda2)
):
if pda1.size == 0:
return pda2  # return other pdarray if pda1 is empty
if pda2.size == 0:
return pda1  # return other pdarray if pda2 is empty
if (pda1.dtype == int and pda2.dtype == int) or (
pda1.dtype == akuint64 and pda2.dtype == akuint64
):
repMsg = generic_msg(
cmd=""setxor1d"", args={""arg1"": pda1, ""arg2"": pda2, ""assume_unique"": assume_unique}
)
return create_pdarray(cast(str, repMsg))
if not assume_unique:
pda1 = cast(pdarray, unique(pda1))
pda2 = cast(pdarray, unique(pda2))
aux = concatenate((pda1, pda2), ordered=False)
aux_sort_indices = argsort(aux)
aux = aux[aux_sort_indices]
flag = concatenate((array([True]), aux[1:] != aux[:-1], array([True])))
return aux[flag[1:] & flag[:-1]]
elif (isinstance(pda1, list) or isinstance(pda1, tuple)) and (
isinstance(pda2, list) or isinstance(pda2, tuple)
):
multiarray_setop_validation(pda1, pda2)
if not assume_unique:
ag = GroupBy(pda1)
ua = ag.unique_keys
bg = GroupBy(pda2)
ub = bg.unique_keys
else:
ua = pda1
ub = pda2
isa = concatenate(
(ones(ua[0].size, dtype=akbool), zeros(ub[0].size, dtype=akbool)), ordered=False
)
c = [concatenate(x, ordered=False) for x in zip(ua, ub)]
g = GroupBy(c)
if assume_unique:
if (g.sum(isa)[1] > 1).any():
raise ValueError(""Called with assume_unique=True, but first argument is not unique"")
if (g.sum(~isa)[1] > 1).any():
raise ValueError(""Called with assume_unique=True, but second argument is not unique"")
k, ct = g.count()
single = ct == 1
return [x[single] for x in k]
else:
raise TypeError(
f""Both pda1 and pda2 must be pdarray, List, or Tuple. Received {type(pda1)} and {type(pda2)}""
)
",[],0,[],/pdarraysetops.py_setxor1d
442,/home/amandapotts/git/arkouda/arkouda/index.py___init__,"def __init__(
self,
values: Union[List, pdarray, Strings, Categorical, pd.Index, ""Index""],
name: Optional[str] = None,
",[],0,[],/index.py___init__
443,/home/amandapotts/git/arkouda/arkouda/index.py___getitem__,"def __getitem__(self, key):
from arkouda.series import Series
if isinstance(key, Series):
key = key.values
if isinstance(key, int):
return self.values[key]
return Index(self.values[key])
",[],0,[],/index.py___getitem__
444,/home/amandapotts/git/arkouda/arkouda/index.py___repr__,"def __repr__(self):
return f""Index({repr(self.index)}, dtype='{self.dtype}')""
",[],0,[],/index.py___repr__
445,/home/amandapotts/git/arkouda/arkouda/index.py___len__,"def __len__(self):
return len(self.index)
",[],0,[],/index.py___len__
446,/home/amandapotts/git/arkouda/arkouda/index.py___eq__,"def __eq__(self, v):
if isinstance(v, Index):
return self.index == v.index
return self.index == v
",[],0,[],/index.py___eq__
447,/home/amandapotts/git/arkouda/arkouda/index.py_index,"def index(self):
""""""
This is maintained to support older code
""""""
return self.values
",[],0,[],/index.py_index
448,/home/amandapotts/git/arkouda/arkouda/index.py_shape,"def shape(self):
return (self.size,)
",[],0,[],/index.py_shape
449,/home/amandapotts/git/arkouda/arkouda/index.py_ndim,"def ndim(self):
return 1
",[],0,[],/index.py_ndim
450,/home/amandapotts/git/arkouda/arkouda/index.py_names,"def names(self):
return [self.name]
",[],0,[],/index.py_names
451,/home/amandapotts/git/arkouda/arkouda/index.py_is_unique,"def is_unique(self):
""""""
Property indicating if all values in the index are unique
Returns
-------
bool - True if all values are unique, False otherwise.
""""""
g = GroupBy(self.values)
key, ct = g.count()
return (ct == 1).all()
",[],0,[],/index.py_is_unique
452,/home/amandapotts/git/arkouda/arkouda/index.py_factory,"def factory(index):
t = type(index)
if isinstance(index, Index):
return index
elif t != list and t != tuple:
return Index(index)
else:
return MultiIndex(index)
",[],0,[],/index.py_factory
453,/home/amandapotts/git/arkouda/arkouda/index.py_from_return_msg,"def from_return_msg(cls, rep_msg):
data = json.loads(rep_msg)
idx = []
for d in data:
i_comps = d.split(""+|+"")
if i_comps[0].lower() == pdarray.objType.lower():
idx.append(create_pdarray(i_comps[1]))
elif i_comps[0].lower() == Strings.objType.lower():
idx.append(Strings.from_return_msg(i_comps[1]))
elif i_comps[0].lower() == Categorical.objType.lower():
idx.append(Categorical.from_return_msg(i_comps[1]))
return cls.factory(idx) if len(idx) > 1 else cls.factory(idx[0])
",[],0,[],/index.py_from_return_msg
454,/home/amandapotts/git/arkouda/arkouda/index.py_to_pandas,"def to_pandas(self):
val = convert_if_categorical(self.values).to_ndarray()
return pd.Index(data=val, dtype=val.dtype, name=self.name)
",[],0,[],/index.py_to_pandas
455,/home/amandapotts/git/arkouda/arkouda/index.py_to_ndarray,"def to_ndarray(self):
val = convert_if_categorical(self.values)
return val.to_ndarray()
",[],0,[],/index.py_to_ndarray
456,/home/amandapotts/git/arkouda/arkouda/index.py_to_list,"def to_list(self):
return self.to_ndarray().tolist()
",[],0,[],/index.py_to_list
457,/home/amandapotts/git/arkouda/arkouda/index.py_set_dtype,"def set_dtype(self, dtype):
""""""Change the data type of the index
Currently only aku.ip_address and ak.array are supported.
""""""
new_idx = dtype(self.values)
self.values = new_idx
return self
",[],0,[],/index.py_set_dtype
458,/home/amandapotts/git/arkouda/arkouda/index.py_register,"def register(self, user_defined_name):
""""""
Register this Index object and underlying components with the Arkouda server
Parameters
----------
user_defined_name : str
user defined name the Index is to be registered under,
this will be the root name for underlying components
Returns
-------
Index
The same Index which is now registered with the arkouda server and has an updated name.
This is an in-place modification, the original is returned to support
a fluid programming style.
Please note you cannot register two different Indexes with the same name.
Raises
------
TypeError
Raised if user_defined_name is not a str
RegistrationError
If the server was unable to register the Index with the user_defined_name
See also
--------
unregister, attach, is_registered
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.client import generic_msg
if self.registered_name is not None and self.is_registered():
raise RegistrationError(f""This object is already registered as {self.registered_name}"")
generic_msg(
cmd=""register"",
args={
""name"": user_defined_name,
""objType"": self.objType,
""num_idxs"": 1,
""idx_names"": [
json.dumps(
{
""codes"": self.values.codes.name,
""categories"": self.values.categories.name,
""NA_codes"": self.values._akNAcode.name,
{""permutation"": self.values.permutation.name}
if self.values.permutation is not None
else {}
),
{""segments"": self.values.segments.name}
if self.values.segments is not None
else {}
),
}
)
if isinstance(self.values, Categorical)
else self.values.name
],
""idx_types"": [self.values.objType],
},
)
self.registered_name = user_defined_name
return self
",[],0,[],/index.py_register
459,/home/amandapotts/git/arkouda/arkouda/index.py_unregister,"def unregister(self):
""""""
Unregister this Index object in the arkouda server which was previously
registered using register() and/or attached to using attach()
Raises
------
RegistrationError
If the object is already unregistered or if there is a server error
when attempting to unregister
See also
--------
register, attach, is_registered
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.util import unregister
if not self.registered_name:
raise RegistrationError(""This object is not registered"")
unregister(self.registered_name)
self.registered_name = None
",[],0,[],/index.py_unregister
460,/home/amandapotts/git/arkouda/arkouda/index.py_is_registered,"def is_registered(self):
""""""
Return True iff the object is contained in the registry or is a component of a
registered object.
Returns
-------
numpy.bool
Indicates if the object is contained in the registry
Raises
------
RegistrationError
Raised if there's a server-side error or a mis-match of registered components
See Also
--------
register, attach, unregister
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.util import is_registered
if self.registered_name is None:
if not isinstance(self.values, Categorical):
return is_registered(self.values.name, as_component=True)
else:
result = True
result &= is_registered(self.values.codes.name, as_component=True)
result &= is_registered(self.values.categories.name, as_component=True)
result &= is_registered(self.values._akNAcode.name, as_component=True)
if self.values.permutation is not None and self.values.segments is not None:
result &= is_registered(self.values.permutation.name, as_component=True)
result &= is_registered(self.values.segments.name, as_component=True)
return result
else:
return is_registered(self.registered_name)
",[],0,[],/index.py_is_registered
461,/home/amandapotts/git/arkouda/arkouda/index.py_to_dict,"def to_dict(self, label):
data = {}
if label is None:
label = ""idx""
elif isinstance(label, list):
label = label[0]
data[label] = self.index
return data
",[],0,[],/index.py_to_dict
462,/home/amandapotts/git/arkouda/arkouda/index.py__check_types,"def _check_types(self, other):
if not isinstance(other, list):
other = [other]
for item in other:
if type(self) is not type(item):
raise TypeError(""Index Types must match"")
",[],0,[],/index.py__check_types
463,/home/amandapotts/git/arkouda/arkouda/index.py__merge,"def _merge(self, other):
self._check_types(other)
callback = get_callback(self.values)
idx = generic_concat([self.values, other.values], ordered=False)
return Index(callback(unique(idx)))
",[],0,[],/index.py__merge
464,/home/amandapotts/git/arkouda/arkouda/index.py__merge_all,"def _merge_all(self, idx_list):
idx = self.values
callback = get_callback(idx)
for other in idx_list:
self._check_types(other)
idx = generic_concat([idx, other.values], ordered=False)
return Index(callback(unique(idx)))
",[],0,[],/index.py__merge_all
465,/home/amandapotts/git/arkouda/arkouda/index.py__check_aligned,"def _check_aligned(self, other):
self._check_types(other)
length = len(self)
return len(other) == length and (self == other.values).sum() == length
",[],0,[],/index.py__check_aligned
466,/home/amandapotts/git/arkouda/arkouda/index.py_argsort,"def argsort(self, ascending=True):
if not ascending:
if isinstance(self.values, pdarray) and self.dtype in (akint64, akfloat64):
i = argsort(-self.values)
else:
i = argsort(self.values)[arange(self.size - 1, -1, -1)]
else:
i = argsort(self.values)
return i
",[],0,[],/index.py_argsort
467,/home/amandapotts/git/arkouda/arkouda/index.py_concat,"def concat(self, other):
self._check_types(other)
if not isinstance(other, list):
other = [other]
idx = generic_concat([self.values] + [item.values for item in other], ordered=True)
return Index(idx)
",[],0,[],/index.py_concat
468,/home/amandapotts/git/arkouda/arkouda/index.py_lookup,"def lookup(self, key):
if not isinstance(key, pdarray):
try:
key = array([key])
except Exception:
raise TypeError(""Lookup must be on an arkouda array"")
return in1d(self.values, key)
",[],0,[],/index.py_lookup
469,/home/amandapotts/git/arkouda/arkouda/index.py_to_hdf,"def to_hdf(
self,
prefix_path: str,
dataset: str = ""index"",
mode: str = ""truncate"",
file_type: str = ""distribute"",
",[],0,[],/index.py_to_hdf
470,/home/amandapotts/git/arkouda/arkouda/index.py_update_hdf,"def update_hdf(
self,
prefix_path: str,
dataset: str = ""index"",
repack: bool = True,
",[],0,[],/index.py_update_hdf
471,/home/amandapotts/git/arkouda/arkouda/index.py_to_parquet,"def to_parquet(
self,
prefix_path: str,
dataset: str = ""index"",
mode: str = ""truncate"",
compression: Optional[str] = None,
",[],0,[],/index.py_to_parquet
472,/home/amandapotts/git/arkouda/arkouda/index.py_to_csv,"def to_csv(
self,
prefix_path: str,
dataset: str = ""index"",
col_delim: str = "","",
overwrite: bool = False,
",[],0,[],/index.py_to_csv
473,/home/amandapotts/git/arkouda/arkouda/index.py_save,"def save(
self,
prefix_path: str,
dataset: str = ""index"",
mode: str = ""truncate"",
compression: Optional[str] = None,
file_format: str = ""HDF5"",
file_type: str = ""distribute"",
",[],0,[],/index.py_save
474,/home/amandapotts/git/arkouda/arkouda/index.py_append,"def append(self, other):
""""""
Append a collection of Index options together.
Parameters
----------
other : Index or list/tuple of indices
Returns
-------
Index
Examples
--------
>>> idx = pd.Index([1, 2, 3])
>>> idx.append(pd.Index([4]))
Index([1, 2, 3, 4], dtype='int64')
""""""
to_concat = [self]
if isinstance(other, (list, tuple)):
to_concat += list(other)
else:
to_concat.append(other)  # type: ignore[arg-type]
for obj in to_concat:
if not isinstance(obj, Index):
raise TypeError(""all inputs must be Index"")
names = {obj.name for obj in to_concat}
name = None if len(names) > 1 else self.name
return self._concat(to_concat, name)
",[],0,[],/index.py_append
475,/home/amandapotts/git/arkouda/arkouda/index.py__concat,"def _concat(self, to_concat, name: Hashable):
""""""
Concatenate multiple Index objects.
""""""
to_concat_vals = [x.values for x in to_concat]
from arkouda import concatenate
result = concatenate(to_concat_vals)
return result
",[],0,[],/index.py__concat
476,/home/amandapotts/git/arkouda/arkouda/index.py___init__,"def __init__(self, values, name=None, names=None):
self.registered_name: Optional[str] = None
if not (isinstance(values, list) or isinstance(values, tuple)):
raise TypeError(""MultiIndex should be an iterable"")
self.values = values
first = True
self.names = names
self.name = name
for col in self.values:
col_size = col.size if not isinstance(col, int) else 0
if first:
self.size = col_size
first = False
else:
if col_size != self.size:
raise ValueError(""All columns in MultiIndex must have same length"")
self.levels = len(self.values)
",[],0,[],/index.py___init__
477,/home/amandapotts/git/arkouda/arkouda/index.py___getitem__,"def __getitem__(self, key):
from arkouda.series import Series
if isinstance(key, Series):
key = key.values
return MultiIndex([i[key] for i in self.index])
",[],0,[],/index.py___getitem__
478,/home/amandapotts/git/arkouda/arkouda/index.py___repr__,"def __repr__(self):
return f""MultiIndex({repr(self.index)})""
",[],0,[],/index.py___repr__
479,/home/amandapotts/git/arkouda/arkouda/index.py___len__,"def __len__(self):
return len(self.index[0])
",[],0,[],/index.py___len__
480,/home/amandapotts/git/arkouda/arkouda/index.py___eq__,"def __eq__(self, v):
if not isinstance(v, (list, tuple, MultiIndex)):
raise TypeError(""Cannot compare MultiIndex to a scalar"")
retval = ones(len(self), dtype=akbool)
if isinstance(v, MultiIndex):
v = v.index
for a, b in zip(self.index, v):
retval &= a == b
return retval
",[],0,[],/index.py___eq__
481,/home/amandapotts/git/arkouda/arkouda/index.py_index,"def index(self):
return self.values
",[],0,[],/index.py_index
482,/home/amandapotts/git/arkouda/arkouda/index.py_to_pandas,"def to_pandas(self):
idx = [convert_if_categorical(i) for i in self.index]
mi = pd.MultiIndex.from_arrays([i.to_ndarray() for i in idx], names=self.names)
return pd.Series(index=mi, dtype=""float64"", name=self.name).index
",[],0,[],/index.py_to_pandas
483,/home/amandapotts/git/arkouda/arkouda/index.py_set_dtype,"def set_dtype(self, dtype):
""""""Change the data type of the index
Currently only aku.ip_address and ak.array are supported.
""""""
new_idx = [dtype(i) for i in self.index]
self.index = new_idx
return self
",[],0,[],/index.py_set_dtype
484,/home/amandapotts/git/arkouda/arkouda/index.py_to_ndarray,"def to_ndarray(self):
import numpy as np
return np.array([convert_if_categorical(val).to_ndarray() for val in self.values])
",['array'],1,['array([convert_if_categorical(val).to_ndarray() for val in self.values])'],/index.py_to_ndarray
485,/home/amandapotts/git/arkouda/arkouda/index.py_to_list,"def to_list(self):
return self.to_ndarray().tolist()
",[],0,[],/index.py_to_list
486,/home/amandapotts/git/arkouda/arkouda/index.py_register,"def register(self, user_defined_name):
""""""
Register this Index object and underlying components with the Arkouda server
Parameters
----------
user_defined_name : str
user defined name the Index is to be registered under,
this will be the root name for underlying components
Returns
-------
MultiIndex
The same Index which is now registered with the arkouda server and has an updated name.
This is an in-place modification, the original is returned to support
a fluid programming style.
Please note you cannot register two different Indexes with the same name.
Raises
------
TypeError
Raised if user_defined_name is not a str
RegistrationError
If the server was unable to register the Index with the user_defined_name
See also
--------
unregister, attach, is_registered
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.client import generic_msg
if self.registered_name is not None and self.is_registered():
raise RegistrationError(f""This object is already registered as {self.registered_name}"")
generic_msg(
cmd=""register"",
args={
""name"": user_defined_name,
""objType"": self.objType,
""num_idxs"": len(self.values),
""idx_names"": [
json.dumps(
{
""codes"": v.codes.name,
""categories"": v.categories.name,
""NA_codes"": v._akNAcode.name,
}
)
if isinstance(v, Categorical)
else v.name
for v in self.values
],
""idx_types"": [v.objType for v in self.values],
},
)
self.registered_name = user_defined_name
return self
",[],0,[],/index.py_register
487,/home/amandapotts/git/arkouda/arkouda/index.py_unregister,"def unregister(self):
from arkouda.util import unregister
if not self.registered_name:
raise RegistrationError(""This object is not registered"")
unregister(self.registered_name)
self.registered_name = None
",[],0,[],/index.py_unregister
488,/home/amandapotts/git/arkouda/arkouda/index.py_is_registered,"def is_registered(self):
from arkouda.util import is_registered
if self.registered_name is None:
return False
return is_registered(self.registered_name)
",[],0,[],/index.py_is_registered
489,/home/amandapotts/git/arkouda/arkouda/index.py_to_dict,"def to_dict(self, labels):
data = {}
if labels is None:
labels = [f""idx_{i}"" for i in range(len(self.index))]
for i, value in enumerate(self.index):
data[labels[i]] = value
return data
",[],0,[],/index.py_to_dict
490,/home/amandapotts/git/arkouda/arkouda/index.py__merge,"def _merge(self, other):
self._check_types(other)
idx = [generic_concat([ix1, ix2], ordered=False) for ix1, ix2 in zip(self.index, other.index)]
return MultiIndex(GroupBy(idx).unique_keys)
",[],0,[],/index.py__merge
491,/home/amandapotts/git/arkouda/arkouda/index.py__merge_all,"def _merge_all(self, array):
idx = self.index
for other in array:
self._check_types(other)
idx = [generic_concat([ix1, ix2], ordered=False) for ix1, ix2 in zip(idx, other.index)]
return MultiIndex(GroupBy(idx).unique_keys)
",[],0,[],/index.py__merge_all
492,/home/amandapotts/git/arkouda/arkouda/index.py_argsort,"def argsort(self, ascending=True):
i = coargsort(self.index)
if not ascending:
i = i[arange(self.size - 1, -1, -1)]
return i
",[],0,[],/index.py_argsort
493,/home/amandapotts/git/arkouda/arkouda/index.py_concat,"def concat(self, other):
self._check_types(other)
idx = [generic_concat([ix1, ix2], ordered=True) for ix1, ix2 in zip(self.index, other.index)]
return MultiIndex(idx)
",[],0,[],/index.py_concat
494,/home/amandapotts/git/arkouda/arkouda/index.py_lookup,"def lookup(self, key):
if not isinstance(key, list) and not isinstance(key, tuple):
raise TypeError(""MultiIndex lookup failure"")
if not isinstance(key[0], pdarray):
dt = self.values[0].dtype if isinstance(self.values[0], pdarray) else akint64
key = [akcast(array([x]), dt) for x in key]
return in1d(self.index, key)
",[],0,[],/index.py_lookup
495,/home/amandapotts/git/arkouda/arkouda/index.py_to_hdf,"def to_hdf(
self,
prefix_path: str,
dataset: str = ""index"",
mode: str = ""truncate"",
file_type: str = ""distribute"",
",[],0,[],/index.py_to_hdf
496,/home/amandapotts/git/arkouda/arkouda/index.py_update_hdf,"def update_hdf(
self,
prefix_path: str,
dataset: str = ""index"",
repack: bool = True,
",[],0,[],/index.py_update_hdf
497,/home/amandapotts/git/arkouda/arkouda/index.py_get_objs_combined_axis,"def get_objs_combined_axis(
objs,
intersect: bool = False,
axis: Union[int, Literal[""index"", ""columns"", ""rows""]] = 0,
sort: bool = True,
",[],0,[],/index.py_get_objs_combined_axis
498,/home/amandapotts/git/arkouda/arkouda/index.py__get_distinct_objs,"def _get_distinct_objs(objs: list[Index]) -> list[Index]:
""""""
Return a list with distinct elements of ""objs"" (different ids).
Preserves order.
""""""
ids: set[int] = set()
res = []
for obj in objs:
if id(obj) not in ids:
ids.add(id(obj))
res.append(obj)
return res
",[],0,[],/index.py__get_distinct_objs
499,/home/amandapotts/git/arkouda/arkouda/index.py__get_combined_index,"def _get_combined_index(
indexes: list[Index],
intersect: bool = False,
sort: bool = False,
",[],0,[],/index.py__get_combined_index
500,/home/amandapotts/git/arkouda/arkouda/index.py_union_indexes,"def union_indexes(indexes, sort: bool | None = True) -> Index:
""""""
Return the union of indexes.
The behavior of sort and names is not consistent.
Parameters
----------
indexes : list of Index or list objects
sort : bool, default True
Whether the result index should come out sorted or not.
Returns
-------
Index
""""""
if len(indexes) == 0:
raise AssertionError(""Must have at least 1 Index to union"")
if len(indexes) == 1:
result = indexes[0]
if isinstance(result, list):
if not sort:
result = Index(result)
else:
result = Index(sorted(result))
return result
indexes, kind = _sanitize_and_check(indexes)
",[],0,[],/index.py_union_indexes
501,/home/amandapotts/git/arkouda/arkouda/index.py__unique_indices,"def _unique_indices(inds, dtype) -> Index:
""""""
Concatenate indices and remove duplicates.
Parameters
----------
inds : list of Index or list objects
dtype : dtype to set for the resulting Index
Returns
-------
Index
""""""
if all(isinstance(ind, Index) for ind in inds):
inds = [ind.astype(dtype, copy=False) for ind in inds]
result = inds[0].unique()
other = inds[1].append(inds[2:])
diff = other[result.get_indexer_for(other) == -1]
if len(diff):
result = result.append(diff.unique())
if sort:
result = result.sort_values()
return result
",[],0,[],/index.py__unique_indices
502,/home/amandapotts/git/arkouda/arkouda/index.py_conv,"def conv(i):
if isinstance(i, Index):
i = i.tolist()
return i
",[],0,[],/index.py_conv
503,/home/amandapotts/git/arkouda/arkouda/index.py__find_common_index_dtype,"def _find_common_index_dtype(inds):
""""""
Finds a common type for the indexes to pass through to resulting index.
Parameters
----------
inds: list of Index or list objects
Returns
-------
The common type or None if no indexes were given
""""""
dtypes = [idx.dtype for idx in indexes if isinstance(idx, Index)]
if dtypes:
dtype = find_common_type(dtypes)
else:
dtype = None
return dtype
",[],0,[],/index.py__find_common_index_dtype
504,/home/amandapotts/git/arkouda/arkouda/index.py__sanitize_and_check,"def _sanitize_and_check(indexes):
""""""
Verify the type of indexes and convert lists to Index.
Cases:
- [list, list, ...]: Return ([list, list, ...], 'list')
- [list, Index, ...]: Return _sanitize_and_check([Index, Index, ...])
Lists are sorted and converted to Index.
- [Index, Index, ...]: Return ([Index, Index, ...], TYPE)
TYPE = 'special' if at least one special type, 'array' otherwise.
Parameters
----------
indexes : list of Index or list objects
Returns
-------
sanitized_indexes : list of Index or list objects
type : {'list', 'array', 'special'}
""""""
kinds = list({type(index) for index in indexes})
if list in kinds:
if len(kinds) > 1:
indexes = [Index(list(x)) if not isinstance(x, Index) else x for x in indexes]
kinds.remove(list)
else:
return indexes, ""list""
if len(kinds) > 1 or Index not in kinds:
return indexes, ""special""
else:
return indexes, ""array""
",[],0,[],/index.py__sanitize_and_check
505,/home/amandapotts/git/arkouda/arkouda/index.py_all_indexes_same,"def all_indexes_same(indexes) -> bool:
""""""
Determine if all indexes contain the same elements.
Parameters
----------
indexes : iterable of Index objects
Returns
-------
bool
True if all indexes contain the same elements, False otherwise.
""""""
itr = iter(indexes)
first = next(itr)
return all(first.equals(index) for index in itr)
",[],0,[],/index.py_all_indexes_same
506,/home/amandapotts/git/arkouda/arkouda/index.py_default_index,"def default_index(n: int) -> Index:
from arkouda import arange
return Index(arange(n))
",[],0,[],/index.py_default_index
507,/home/amandapotts/git/arkouda/arkouda/index.py_ensure_index,"def ensure_index(
index_like: Union[int, Literal[""index"", ""columns"", ""rows""]], copy: bool = False
",[],0,[],/index.py_ensure_index
508,/home/amandapotts/git/arkouda/arkouda/index.py_get_unanimous_names,"def get_unanimous_names(*indexes: Index) -> tuple[Hashable, ...]:
""""""
Return common name if all indices agree, otherwise None (level-by-level).
Parameters
----------
indexes : list of Index objects
Returns
-------
list
A list representing the unanimous 'names' found.
""""""
name_tups = [tuple(i.names) for i in indexes]
name_sets = [{*ns} for ns in zip_longest(*name_tups)]
names = tuple(ns.pop() if len(ns) == 1 else None for ns in name_sets)
return names
",[],0,[],/index.py_get_unanimous_names
509,/home/amandapotts/git/arkouda/arkouda/join.py_join_on_eq_with_dt,"def join_on_eq_with_dt(
a1: pdarray,
a2: pdarray,
t1: pdarray,
t2: pdarray,
dt: Union[int, np.int64],
pred: str,
result_limit: Union[int, np.int64] = 1000,
","['int64', 'int64']",2,[],/join.py_join_on_eq_with_dt
510,/home/amandapotts/git/arkouda/arkouda/join.py_gen_ranges,"def gen_ranges(starts, ends, stride=1):
""""""
Generate a segmented array of variable-length, contiguous ranges between pairs of
start- and end-points.
Parameters
----------
starts : pdarray, int64
The start value of each range
ends : pdarray, int64
The end value (exclusive) of each range
stride: int
Difference between successive elements of each range
Returns
-------
segments : pdarray, int64
The starting index of each range in the resulting array
ranges : pdarray, int64
The actual ranges, flattened into a single array
""""""
if starts.size != ends.size:
raise ValueError(""starts and ends must be same length"")
if starts.size == 0:
return zeros(0, dtype=akint64), zeros(0, dtype=akint64)
lengths = (ends - starts) // stride
if not (lengths >= 0).all():
raise ValueError(""all ends must be greater than or equal to starts"")
non_empty = lengths != 0
segs = cumsum(lengths) - lengths
totlen = lengths.sum()
slices = ones(totlen, dtype=akint64)
non_empty_starts = starts[non_empty]
non_empty_lengths = lengths[non_empty]
diffs = concatenate(
(
array([non_empty_starts[0]]),
non_empty_starts[1:] - non_empty_starts[:-1] - (non_empty_lengths[:-1] - 1) * stride,
)
)
slices[segs[non_empty]] = diffs
return segs, cumsum(slices)
",[],0,[],/join.py_gen_ranges
511,/home/amandapotts/git/arkouda/arkouda/join.py_compute_join_size,"def compute_join_size(a: pdarray, b: pdarray) -> Tuple[int, int]:
""""""
Compute the internal size of a hypothetical join between a and b. Returns
both the number of elements and number of bytes required for the join.
""""""
bya = GroupBy(a)
ua, asize = bya.count()
byb = GroupBy(b)
ub, bsize = byb.count()
afact = asize[in1d(ua, ub)]
bfact = bsize[in1d(ub, ua)]
nelem = (afact * bfact).sum()
nbytes = 3 * 8 * nelem
return nelem, nbytes
",[],0,[],/join.py_compute_join_size
512,/home/amandapotts/git/arkouda/arkouda/join.py_inner_join,"def inner_join(
left: Union[pdarray, Strings, Categorical, Sequence[Union[pdarray, Strings]]],
right: Union[pdarray, Strings, Categorical, Sequence[Union[pdarray, Strings]]],
wherefunc: Callable = None,
whereargs: Tuple[
Union[pdarray, Strings, Categorical, Sequence[Union[pdarray, Strings]]],
Union[pdarray, Strings, Categorical, Sequence[Union[pdarray, Strings]]],
] = None,
",[],0,[],/join.py_inner_join
513,/home/amandapotts/git/arkouda/arkouda/numeric.py_cast,"def cast(
pda: Union[pdarray, Strings, Categorical],  # type: ignore
dt: Union[np.dtype, type, str, BigInt],
errors: ErrorMode = ErrorMode.strict,
",['dtype'],1,[],/numeric.py_cast
514,/home/amandapotts/git/arkouda/arkouda/numeric.py_abs,"def abs(pda: pdarray) -> pdarray:
""""""
Return the element-wise absolute value of the array.
Parameters
----------
pda : pdarray
Returns
-------
pdarray
A pdarray containing absolute values of the input array elements
Raises
------
TypeError
Raised if the parameter is not a pdarray
Examples
--------
>>> ak.abs(ak.arange(-5,-1))
array([5, 4, 3, 2])
>>> ak.abs(ak.linspace(-5,-1,5))
array([5, 4, 3, 2, 1])
""""""
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""abs"",
""array"": pda,
},
)
return create_pdarray(type_cast(str, repMsg))
",[],0,[],/numeric.py_abs
515,/home/amandapotts/git/arkouda/arkouda/numeric.py_ceil,"def ceil(pda: pdarray) -> pdarray:
""""""
Return the element-wise ceiling of the array.
Parameters
----------
pda : pdarray
Returns
-------
pdarray
A pdarray containing ceiling values of the input array elements
Raises
------
TypeError
Raised if the parameter is not a pdarray
Examples
--------
>>> ak.ceil(ak.linspace(1.1,5.5,5))
array([2, 3, 4, 5, 6])
""""""
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""ceil"",
""array"": pda,
},
)
return create_pdarray(type_cast(str, repMsg))
",[],0,[],/numeric.py_ceil
516,/home/amandapotts/git/arkouda/arkouda/numeric.py_floor,"def floor(pda: pdarray) -> pdarray:
""""""
Return the element-wise floor of the array.
Parameters
----------
pda : pdarray
Returns
-------
pdarray
A pdarray containing floor values of the input array elements
Raises
------
TypeError
Raised if the parameter is not a pdarray
Examples
--------
>>> ak.floor(ak.linspace(1.1,5.5,5))
array([1, 2, 3, 4, 5])
""""""
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""floor"",
""array"": pda,
},
)
return create_pdarray(type_cast(str, repMsg))
",[],0,[],/numeric.py_floor
517,/home/amandapotts/git/arkouda/arkouda/numeric.py_round,"def round(pda: pdarray) -> pdarray:
""""""
Return the element-wise rounding of the array.
Parameters
----------
pda : pdarray
Returns
-------
pdarray
A pdarray containing input array elements rounded to the nearest integer
Raises
------
TypeError
Raised if the parameter is not a pdarray
Examples
--------
>>> ak.round(ak.array([1.1, 2.5, 3.14159]))
array([1, 3, 3])
""""""
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""round"",
""array"": pda,
},
)
return create_pdarray(type_cast(str, repMsg))
",[],0,[],/numeric.py_round
518,/home/amandapotts/git/arkouda/arkouda/numeric.py_trunc,"def trunc(pda: pdarray) -> pdarray:
""""""
Return the element-wise truncation of the array.
Parameters
----------
pda : pdarray
Returns
-------
pdarray
A pdarray containing input array elements truncated to the nearest integer
Raises
------
TypeError
Raised if the parameter is not a pdarray
Examples
--------
>>> ak.trunc(ak.array([1.1, 2.5, 3.14159]))
array([1, 2, 3])
""""""
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""trunc"",
""array"": pda,
},
)
return create_pdarray(type_cast(str, repMsg))
",[],0,[],/numeric.py_trunc
519,/home/amandapotts/git/arkouda/arkouda/numeric.py_sign,"def sign(pda: pdarray) -> pdarray:
""""""
Return the element-wise sign of the array.
Parameters
----------
pda : pdarray
Returns
-------
pdarray
A pdarray containing sign values of the input array elements
Raises
------
TypeError
Raised if the parameter is not a pdarray
Examples
--------
>>> ak.sign(ak.array([-10, -5, 0, 5, 10]))
array([-1, -1, 0, 1, 1])
""""""
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""sign"",
""array"": pda,
},
)
return create_pdarray(type_cast(str, repMsg))
",[],0,[],/numeric.py_sign
520,/home/amandapotts/git/arkouda/arkouda/numeric.py_isfinite,"def isfinite(pda: pdarray) -> pdarray:
""""""
Return the element-wise isfinite check applied to the array.
Parameters
----------
pda : pdarray
Returns
-------
pdarray
A pdarray containing boolean values indicating whether the
input array elements are finite
Raises
------
TypeError
Raised if the parameter is not a pdarray
RuntimeError
if the underlying pdarray is not float-based
Examples
--------
>>> ak.isfinite(ak.array[1.0, 2.0, ak.inf])
array([True, True, False])
""""""
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""isfinite"",
""array"": pda,
},
)
return create_pdarray(type_cast(str, repMsg))
",[],0,[],/numeric.py_isfinite
521,/home/amandapotts/git/arkouda/arkouda/numeric.py_isinf,"def isinf(pda: pdarray) -> pdarray:
""""""
Return the element-wise isinf check applied to the array.
Parameters
----------
pda : pdarray
Returns
-------
pdarray
A pdarray containing boolean values indicating whether the
input array elements are infinite
Raises
------
TypeError
Raised if the parameter is not a pdarray
RuntimeError
if the underlying pdarray is not float-based
Examples
--------
>>> ak.isinf(ak.array[1.0, 2.0, ak.inf])
array([False, False, True])
""""""
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""isinf"",
""array"": pda,
},
)
return create_pdarray(type_cast(str, repMsg))
",[],0,[],/numeric.py_isinf
522,/home/amandapotts/git/arkouda/arkouda/numeric.py_isnan,"def isnan(pda: pdarray) -> pdarray:
""""""
Return the element-wise isnan check applied to the array.
Parameters
----------
pda : pdarray
Returns
-------
pdarray
A pdarray containing boolean values indicating whether the
input array elements are NaN
Raises
------
TypeError
Raised if the parameter is not a pdarray
RuntimeError
if the underlying pdarray is not float-based
Examples
--------
>>> ak.isnan(ak.array[1.0, 2.0, 1.0 / 0.0])
array([False, False, True])
""""""
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""isnan"",
""array"": pda,
},
)
return create_pdarray(type_cast(str, repMsg))
",[],0,[],/numeric.py_isnan
523,/home/amandapotts/git/arkouda/arkouda/numeric.py_log,"def log(pda: pdarray) -> pdarray:
""""""
Return the element-wise natural log of the array.
Parameters
----------
pda : pdarray
Returns
-------
pdarray
A pdarray containing natural log values of the input
array elements
Raises
------
TypeError
Raised if the parameter is not a pdarray
Notes
-----
Logarithms with other bases can be computed as follows:
Examples
--------
>>> A = ak.array([1, 10, 100])
>>> ak.log(A)
array([0, 2.3025850929940459, 4.6051701859880918])
>>> ak.log(A) / np.log(10)
array([0, 1, 2])
>>> ak.log(A) / np.log(2)
array([0, 3.3219280948873626, 6.6438561897747253])
""""""
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""log"",
""array"": pda,
},
)
return create_pdarray(type_cast(str, repMsg))
","['log', 'log']",2,"['log(10)', 'log(2)']",/numeric.py_log
524,/home/amandapotts/git/arkouda/arkouda/numeric.py_log10,"def log10(x: pdarray) -> pdarray:
""""""
Return the element-wise base 10 log of the array.
Parameters
__________
x : pdarray
array to compute on
Returns
_______
pdarray contain values of the base 10 log
""""""
repMsg = generic_msg(
cmd=f""efunc{x.ndim}D"",
args={
""func"": ""log10"",
""array"": x,
},
)
return create_pdarray(type_cast(str, repMsg))
",[],0,[],/numeric.py_log10
525,/home/amandapotts/git/arkouda/arkouda/numeric.py_log2,"def log2(x: pdarray) -> pdarray:
""""""
Return the element-wise base 2 log of the array.
Parameters
__________
x : pdarray
array to compute on
Returns
_______
pdarray contain values of the base 2 log
""""""
repMsg = generic_msg(
cmd=f""efunc{x.ndim}D"",
args={
""func"": ""log2"",
""array"": x,
},
)
return create_pdarray(type_cast(str, repMsg))
",[],0,[],/numeric.py_log2
526,/home/amandapotts/git/arkouda/arkouda/numeric.py_log1p,"def log1p(x: pdarray) -> pdarray:
""""""
Return the element-wise natural log of one plus the array.
Parameters
__________
x : pdarray
array to compute on
Returns
_______
pdarray contain values of the natural log of one plus the array
""""""
repMsg = generic_msg(
cmd=f""efunc{x.ndim}D"",
args={
""func"": ""log1p"",
""array"": x,
},
)
return create_pdarray(repMsg)
",[],0,[],/numeric.py_log1p
527,/home/amandapotts/git/arkouda/arkouda/numeric.py_exp,"def exp(pda: pdarray) -> pdarray:
""""""
Return the element-wise exponential of the array.
Parameters
----------
pda : pdarray
Returns
-------
pdarray
A pdarray containing exponential values of the input
array elements
Raises
------
TypeError
Raised if the parameter is not a pdarray
Examples
--------
>>> ak.exp(ak.arange(1,5))
array([2.7182818284590451, 7.3890560989306504, 20.085536923187668, 54.598150033144236])
>>> ak.exp(ak.uniform(5,1.0,5.0))
array([11.84010843172504, 46.454368507659211, 5.5571769623557188,
33.494295836924771, 13.478894913238722])
""""""
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""exp"",
""array"": pda,
},
)
return create_pdarray(type_cast(str, repMsg))
",[],0,[],/numeric.py_exp
528,/home/amandapotts/git/arkouda/arkouda/numeric.py_expm1,"def expm1(pda: pdarray) -> pdarray:
""""""
Return the element-wise exponential of the array minus one.
Parameters
----------
pda : pdarray
Returns
-------
pdarray
A pdarray containing exponential values of the input
array elements minus one
Raises
------
TypeError
Raised if the parameter is not a pdarray
Examples
--------
>>> ak.exp1m(ak.arange(1,5))
array([1.7182818284590451, 6.3890560989306504, 19.085536923187668, 53.598150033144236])
>>> ak.exp1m(ak.uniform(5,1.0,5.0))
array([10.84010843172504, 45.454368507659211, 4.5571769623557188,
32.494295836924771, 12.478894913238722])
""""""
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""expm1"",
""array"": pda,
},
)
return create_pdarray(type_cast(str, repMsg))
",[],0,[],/numeric.py_expm1
529,/home/amandapotts/git/arkouda/arkouda/numeric.py_square,"def square(pda: pdarray) -> pdarray:
""""""
Return the element-wise square of the array.
Parameters
----------
pda : pdarray
Returns
-------
pdarray
A pdarray containing square values of the input
array elements
Raises
------
TypeError
Raised if the parameter is not a pdarray
Examples
--------
>>> ak.square(ak.arange(1,5))
array([1, 4, 9, 16])
""""""
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""square"",
""array"": pda,
},
)
return create_pdarray(type_cast(str, repMsg))
",[],0,[],/numeric.py_square
530,/home/amandapotts/git/arkouda/arkouda/numeric.py_cumsum,"def cumsum(pda: pdarray) -> pdarray:
""""""
Return the cumulative sum over the array.
The sum is inclusive, such that the ``i`` th element of the
result is the sum of elements up to and including ``i``.
Parameters
----------
pda : pdarray
Returns
-------
pdarray
A pdarray containing cumulative sums for each element
of the original pdarray
Raises
------
TypeError
Raised if the parameter is not a pdarray
Examples
--------
>>> ak.cumsum(ak.arange([1,5]))
array([1, 3, 6])
>>> ak.cumsum(ak.uniform(5,1.0,5.0))
array([3.1598310770203937, 5.4110385860243131, 9.1622479306453748,
12.710615785506533, 13.945880905466208])
>>> ak.cumsum(ak.randint(0, 1, 5, dtype=ak.bool))
array([0, 1, 1, 2, 3])
""""""
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""cumsum"",
""array"": pda,
},
)
return create_pdarray(type_cast(str, repMsg))
",[],0,[],/numeric.py_cumsum
531,/home/amandapotts/git/arkouda/arkouda/numeric.py_cumprod,"def cumprod(pda: pdarray) -> pdarray:
""""""
Return the cumulative product over the array.
The product is inclusive, such that the ``i`` th element of the
result is the product of elements up to and including ``i``.
Parameters
----------
pda : pdarray
Returns
-------
pdarray
A pdarray containing cumulative products for each element
of the original pdarray
Raises
------
TypeError
Raised if the parameter is not a pdarray
Examples
--------
>>> ak.cumprod(ak.arange(1,5))
array([1, 2, 6, 24]))
>>> ak.cumprod(ak.uniform(5,1.0,5.0))
array([1.5728783400481925, 7.0472855509390593, 33.78523998586553,
134.05309592737584, 450.21589865655358])
""""""
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""cumprod"",
""array"": pda,
},
)
return create_pdarray(type_cast(str, repMsg))
",[],0,[],/numeric.py_cumprod
532,/home/amandapotts/git/arkouda/arkouda/numeric.py_sin,"def sin(pda: pdarray, where: Union[bool, pdarray] = True) -> pdarray:
""""""
Return the element-wise sine of the array.
Parameters
----------
pda : pdarray
where : Boolean or pdarray
This condition is broadcast over the input. At locations where the condition is True,
the sine will be applied to the corresponding value. Elsewhere, it will retain
its original value. Default set to True.
Returns
-------
pdarray
A pdarray containing sin for each element
of the original pdarray
Raises
------
TypeError
Raised if the parameter is not a pdarray
""""""
return _trig_helper(pda, ""sin"", where)
",[],0,[],/numeric.py_sin
533,/home/amandapotts/git/arkouda/arkouda/numeric.py_cos,"def cos(pda: pdarray, where: Union[bool, pdarray] = True) -> pdarray:
""""""
Return the element-wise cosine of the array.
Parameters
----------
pda : pdarray
where : Boolean or pdarray
This condition is broadcast over the input. At locations where the condition is True,
the cosine will be applied to the corresponding value. Elsewhere, it will retain
its original value. Default set to True.
Returns
-------
pdarray
A pdarray containing cosine for each element
of the original pdarray
Raises
------
TypeError
Raised if the parameter is not a pdarray
""""""
return _trig_helper(pda, ""cos"", where)
",[],0,[],/numeric.py_cos
534,/home/amandapotts/git/arkouda/arkouda/numeric.py_tan,"def tan(pda: pdarray, where: Union[bool, pdarray] = True) -> pdarray:
""""""
Return the element-wise tangent of the array.
Parameters
----------
pda : pdarray
where : Boolean or pdarray
This condition is broadcast over the input. At locations where the condition is True,
the tangent will be applied to the corresponding value. Elsewhere, it will retain
its original value. Default set to True.
Returns
-------
pdarray
A pdarray containing tangent for each element
of the original pdarray
Raises
------
TypeError
Raised if the parameter is not a pdarray
""""""
return _trig_helper(pda, ""tan"", where)
",[],0,[],/numeric.py_tan
535,/home/amandapotts/git/arkouda/arkouda/numeric.py_arcsin,"def arcsin(pda: pdarray, where: Union[bool, pdarray] = True) -> pdarray:
""""""
Return the element-wise inverse sine of the array. The result is between -pi/2 and pi/2.
Parameters
----------
pda : pdarray
where : Boolean or pdarray
This condition is broadcast over the input. At locations where the condition is True,
the inverse sine will be applied to the corresponding value. Elsewhere, it will retain
its original value. Default set to True.
Returns
-------
pdarray
A pdarray containing inverse sine for each element
of the original pdarray
Raises
------
TypeError
Raised if the parameter is not a pdarray
""""""
return _trig_helper(pda, ""arcsin"", where)
",[],0,[],/numeric.py_arcsin
536,/home/amandapotts/git/arkouda/arkouda/numeric.py_arccos,"def arccos(pda: pdarray, where: Union[bool, pdarray] = True) -> pdarray:
""""""
Return the element-wise inverse cosine of the array. The result is between 0 and pi.
Parameters
----------
pda : pdarray
where : Boolean or pdarray
This condition is broadcast over the input. At locations where the condition is True,
the inverse cosine will be applied to the corresponding value. Elsewhere, it will retain
its original value. Default set to True.
Returns
-------
pdarray
A pdarray containing inverse cosine for each element
of the original pdarray
Raises
------
TypeError
Raised if the parameter is not a pdarray
""""""
return _trig_helper(pda, ""arccos"", where)
",[],0,[],/numeric.py_arccos
537,/home/amandapotts/git/arkouda/arkouda/numeric.py_arctan,"def arctan(pda: pdarray, where: Union[bool, pdarray] = True) -> pdarray:
""""""
Return the element-wise inverse tangent of the array. The result is between -pi/2 and pi/2.
Parameters
----------
pda : pdarray
where : Boolean or pdarray
This condition is broadcast over the input. At locations where the condition is True,
the inverse tangent will be applied to the corresponding value. Elsewhere, it will retain
its original value. Default set to True.
Returns
-------
pdarray
A pdarray containing inverse tangent for each element
of the original pdarray
Raises
------
TypeError
Raised if the parameter is not a pdarray
""""""
return _trig_helper(pda, ""arctan"", where)
",[],0,[],/numeric.py_arctan
538,/home/amandapotts/git/arkouda/arkouda/numeric.py_arctan2,"def arctan2(
num: Union[pdarray, numeric_scalars],
denom: Union[pdarray, numeric_scalars],
where: Union[bool, pdarray] = True,
",[],0,[],/numeric.py_arctan2
539,/home/amandapotts/git/arkouda/arkouda/numeric.py_sinh,"def sinh(pda: pdarray, where: Union[bool, pdarray] = True) -> pdarray:
""""""
Return the element-wise hyperbolic sine of the array.
Parameters
----------
pda : pdarray
where : Boolean or pdarray
This condition is broadcast over the input. At locations where the condition is True,
the hyperbolic sine will be applied to the corresponding value. Elsewhere, it will retain
its original value. Default set to True.
Returns
-------
pdarray
A pdarray containing hyperbolic sine for each element
of the original pdarray
Raises
------
TypeError
Raised if the parameter is not a pdarray
""""""
return _trig_helper(pda, ""sinh"", where)
",[],0,[],/numeric.py_sinh
540,/home/amandapotts/git/arkouda/arkouda/numeric.py_cosh,"def cosh(pda: pdarray, where: Union[bool, pdarray] = True) -> pdarray:
""""""
Return the element-wise hyperbolic cosine of the array.
Parameters
----------
pda : pdarray
where : Boolean or pdarray
This condition is broadcast over the input. At locations where the condition is True,
the hyperbolic cosine will be applied to the corresponding value. Elsewhere, it will retain
its original value. Default set to True.
Returns
-------
pdarray
A pdarray containing hyperbolic cosine for each element
of the original pdarray
Raises
------
TypeError
Raised if the parameter is not a pdarray
""""""
return _trig_helper(pda, ""cosh"", where)
",[],0,[],/numeric.py_cosh
541,/home/amandapotts/git/arkouda/arkouda/numeric.py_tanh,"def tanh(pda: pdarray, where: Union[bool, pdarray] = True) -> pdarray:
""""""
Return the element-wise hyperbolic tangent of the array.
Parameters
----------
pda : pdarray
where : Boolean or pdarray
This condition is broadcast over the input. At locations where the condition is True,
the hyperbolic tangent will be applied to the corresponding value. Elsewhere, it will retain
its original value. Default set to True.
Returns
-------
pdarray
A pdarray containing hyperbolic tangent for each element
of the original pdarray
Raises
------
TypeError
Raised if the parameter is not a pdarray
""""""
return _trig_helper(pda, ""tanh"", where)
",[],0,[],/numeric.py_tanh
542,/home/amandapotts/git/arkouda/arkouda/numeric.py_arcsinh,"def arcsinh(pda: pdarray, where: Union[bool, pdarray] = True) -> pdarray:
""""""
Return the element-wise inverse hyperbolic sine of the array.
Parameters
----------
pda : pdarray
where : Boolean or pdarray
This condition is broadcast over the input. At locations where the condition is True,
the inverse hyperbolic sine will be applied to the corresponding value. Elsewhere, it will retain
its original value. Default set to True.
Returns
-------
pdarray
A pdarray containing inverse hyperbolic sine for each element
of the original pdarray
Raises
------
TypeError
Raised if the parameter is not a pdarray
""""""
return _trig_helper(pda, ""arcsinh"", where)
",[],0,[],/numeric.py_arcsinh
543,/home/amandapotts/git/arkouda/arkouda/numeric.py_arccosh,"def arccosh(pda: pdarray, where: Union[bool, pdarray] = True) -> pdarray:
""""""
Return the element-wise inverse hyperbolic cosine of the array.
Parameters
----------
pda : pdarray
where : Boolean or pdarray
This condition is broadcast over the input. At locations where the condition is True,
the inverse hyperbolic cosine will be applied to the corresponding value. Elsewhere, it will
retain its original value. Default set to True.
Returns
-------
pdarray
A pdarray containing inverse hyperbolic cosine for each element
of the original pdarray
Raises
------
TypeError
Raised if the parameter is not a pdarray
""""""
return _trig_helper(pda, ""arccosh"", where)
",[],0,[],/numeric.py_arccosh
544,/home/amandapotts/git/arkouda/arkouda/numeric.py_arctanh,"def arctanh(pda: pdarray, where: Union[bool, pdarray] = True) -> pdarray:
""""""
Return the element-wise inverse hyperbolic tangent of the array.
Parameters
----------
pda : pdarray
where : Boolean or pdarray
This condition is broadcast over the input. At locations where the condition is True,
the inverse hyperbolic tangent will be applied to the corresponding value. Elsewhere,
it will retain its original value. Default set to True.
Returns
-------
pdarray
A pdarray containing inverse hyperbolic tangent for each element
of the original pdarray
Raises
------
TypeError
Raised if the parameters are not a pdarray or numeric scalar.
""""""
return _trig_helper(pda, ""arctanh"", where)
",[],0,[],/numeric.py_arctanh
545,/home/amandapotts/git/arkouda/arkouda/numeric.py__trig_helper,"def _trig_helper(pda: pdarray, func: str, where: Union[bool, pdarray] = True) -> pdarray:
""""""
Returns the result of the input trig function acting element-wise on the array.
Parameters
----------
pda : pdarray
func : string
The designated trig function that is passed in
where : Boolean or pdarray
This condition is applied over the input. At locations where the condition is True, the
corresponding value will be acted on by the respective trig function. Elsewhere,
it will retain its original value. Default set to True.
Returns
-------
pdarray
A pdarray with the trig function applied at each element of pda
Raises
------
TypeError
Raised if the parameter is not a pdarray
TypeError
Raised if where condition is not type Boolean
""""""
if where is True:
repMsg = type_cast(
str,
generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": func,
""array"": pda,
},
),
)
return create_pdarray(repMsg)
elif where is False:
return pda
else:
if where.dtype != bool:
raise TypeError(f""where must have dtype bool, got {where.dtype} instead"")
repMsg = type_cast(
str,
generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": func,
""array"": pda[where],
},
),
)
new_pda = pda[:]
ret = create_pdarray(repMsg)
new_pda = cast(new_pda, ret.dtype)
new_pda[where] = ret
return new_pda
",[],0,[],/numeric.py__trig_helper
546,/home/amandapotts/git/arkouda/arkouda/numeric.py_rad2deg,"def rad2deg(pda: pdarray, where: Union[bool, pdarray] = True) -> pdarray:
""""""
Converts angles element-wise from radians to degrees.
Parameters
----------
pda : pdarray
where : Boolean or pdarray
This condition is broadcast over the input. At locations where the condition is True, the
corresponding value will be converted from radians to degrees. Elsewhere, it will retain its
original value. Default set to True.
Returns
-------
pdarray
A pdarray containing an angle converted to degrees, from radians, for each element
of the original pdarray
Raises
------
TypeError
Raised if the parameter is not a pdarray
""""""
if where is True:
return 180 * (pda / np.pi)
elif where is False:
return pda
else:
new_pda = pda
ret = 180 * (pda[where] / np.pi)
new_pda = cast(new_pda, ret.dtype)
new_pda[where] = ret
return new_pda
","['pi', 'pi']",2,[],/numeric.py_rad2deg
547,/home/amandapotts/git/arkouda/arkouda/numeric.py_deg2rad,"def deg2rad(pda: pdarray, where: Union[bool, pdarray] = True) -> pdarray:
""""""
Converts angles element-wise from degrees to radians.
Parameters
----------
pda : pdarray
where : Boolean or pdarray
This condition is broadcast over the input. At locations where the condition is True, the
corresponding value will be converted from degrees to radians. Elsewhere, it will retain its
original value. Default set to True.
Returns
-------
pdarray
A pdarray containing an angle converted to radians, from degrees, for each element
of the original pdarray
Raises
------
TypeError
Raised if the parameter is not a pdarray
""""""
if where is True:
return np.pi * pda / 180
elif where is False:
return pda
else:
new_pda = pda
ret = np.pi * pda[where] / 180
new_pda = cast(new_pda, ret.dtype)
new_pda[where] = ret
return new_pda
","['pi', 'pi']",2,[],/numeric.py_deg2rad
548,/home/amandapotts/git/arkouda/arkouda/numeric.py__hash_helper,"def _hash_helper(a):
from arkouda import Categorical as Categorical_
from arkouda import SegArray as SegArray_
if isinstance(a, SegArray_):
return json.dumps(
{""segments"": a.segments.name, ""values"": a.values.name, ""valObjType"": a.values.objType}
)
elif isinstance(a, Categorical_):
return json.dumps({""categories"": a.categories.name, ""codes"": a.codes.name})
else:
return a.name
",[],0,[],/numeric.py__hash_helper
549,/home/amandapotts/git/arkouda/arkouda/numeric.py_hash,"def hash(
pda: Union[  # type: ignore
Union[pdarray, Strings, SegArray, Categorical],
List[Union[pdarray, Strings, SegArray, Categorical]],
],
full: bool = True,
",[],0,[],/numeric.py_hash
550,/home/amandapotts/git/arkouda/arkouda/numeric.py__hash_single,"def _hash_single(pda: pdarray, full: bool = True):
if pda.dtype == bigint:
return hash(pda.bigint_to_uint_arrays())
repMsg = type_cast(
str,
generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""hash128"" if full else ""hash64"",
""array"": pda,
},
),
)
if full:
a, b = repMsg.split(""+"")
return create_pdarray(a), create_pdarray(b)
else:
return create_pdarray(repMsg)
",[],0,[],/numeric.py__hash_single
551,/home/amandapotts/git/arkouda/arkouda/numeric.py__str_cat_where,"def _str_cat_where(
condition: pdarray,
A: Union[str, Strings, Categorical],
B: Union[str, Strings, Categorical],
",[],0,[],/numeric.py__str_cat_where
552,/home/amandapotts/git/arkouda/arkouda/numeric.py_where,"def where(
condition: pdarray,
A: Union[str, numeric_scalars, pdarray, Strings, Categorical],  # type: ignore
B: Union[str, numeric_scalars, pdarray, Strings, Categorical],  # type: ignore
",[],0,[],/numeric.py_where
553,/home/amandapotts/git/arkouda/arkouda/numeric.py_histogram,"def histogram(pda: pdarray, bins: int_scalars = 10) -> Tuple[pdarray, pdarray]:
""""""
Compute a histogram of evenly spaced bins over the range of an array.
Parameters
----------
pda : pdarray
The values to histogram
bins : int_scalars
The number of equal-size bins to use (default: 10)
Returns
-------
(pdarray, Union[pdarray, int64 or float64])
Bin edges and The number of values present in each bin
Raises
------
TypeError
Raised if the parameter is not a pdarray or if bins is
not an int.
ValueError
Raised if bins < 1
NotImplementedError
Raised if pdarray dtype is bool or uint8
See Also
--------
value_counts, histogram2d
Notes
-----
The bins are evenly spaced in the interval [pda.min(), pda.max()].
Examples
--------
>>> import matplotlib.pyplot as plt
>>> A = ak.arange(0, 10, 1)
>>> nbins = 3
>>> h, b = ak.histogram(A, bins=nbins)
>>> h
array([3, 3, 4])
>>> b
array([0., 3., 6., 9.])
>>> plt.plot(b.to_ndarray()[::-1], h.to_ndarray())
""""""
if bins < 1:
raise ValueError(""bins must be 1 or greater"")
b = linspace(pda.min(), pda.max(), bins + 1)
repMsg = generic_msg(cmd=""histogram"", args={""array"": pda, ""bins"": bins})
return create_pdarray(type_cast(str, repMsg)), b
",[],0,[],/numeric.py_histogram
554,/home/amandapotts/git/arkouda/arkouda/numeric.py_histogram2d,"def histogram2d(
x: pdarray, y: pdarray, bins: Union[int_scalars, Sequence[int_scalars]] = 10
",[],0,[],/numeric.py_histogram2d
555,/home/amandapotts/git/arkouda/arkouda/numeric.py_histogramdd,"def histogramdd(
sample: Sequence[pdarray], bins: Union[int_scalars, Sequence[int_scalars]] = 10
",[],0,[],/numeric.py_histogramdd
556,/home/amandapotts/git/arkouda/arkouda/numeric.py_value_counts,"def value_counts(
pda: pdarray,
",[],0,[],/numeric.py_value_counts
557,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py__get_grouping_keys,"def _get_grouping_keys(pda: groupable):
nkeys = 1
if hasattr(pda, ""_get_grouping_keys""):
grouping_keys = cast(list, cast(groupable_element_type, pda)._get_grouping_keys())
else:
nkeys = len(pda)
grouping_keys = []
for k in pda:
if k.size != pda[0].size:
raise ValueError(""Key arrays must all be same size"")
if not hasattr(k, ""_get_grouping_keys""):
raise TypeError(f""{type(k)} does not support grouping"")
grouping_keys.extend(cast(list, k._get_grouping_keys()))
return grouping_keys, nkeys
",[],0,[],/groupbyclass.py__get_grouping_keys
558,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_unique,"def unique(
pda: groupable,
return_groups: bool = False,
assume_sorted: bool = False,
return_indices: bool = False,
",[],0,[],/groupbyclass.py_unique
559,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py___str__,"def __str__(self) -> str:
""""""
Overridden method returns value, which is useful in outputting
a GroupByReductionType as a request parameter
""""""
return self.value
",[],0,[],/groupbyclass.py___str__
560,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py___repr__,"def __repr__(self) -> str:
""""""
Overridden method returns value, which is useful in outputting
a GroupByReductionType as a request parameter
""""""
return self.value
",[],0,[],/groupbyclass.py___repr__
561,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py___init__,"def __init__(
self,
keys: Optional[groupable] = None,
assume_sorted: bool = False,
dropna: bool = True,
",[],0,[],/groupbyclass.py___init__
562,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_drop_na_keys,"def drop_na_keys():
if self.dropna is True:
if isinstance(self.keys, pdarray) and self.keys.dtype == akfloat64:
self.keys = self.keys[~isnan(self.keys)]
elif isinstance(self.keys, list):
is_not_nan = [
~isnan(key)
for key in self.keys
if isinstance(key, pdarray) and key.dtype == akfloat64
]
if len(is_not_nan) > 0:
use_value = is_not_nan[0]
for bool_arry in is_not_nan:
use_value = use_value & bool_arry
self.keys = [key[use_value] for key in keys]
",[],0,[],/groupbyclass.py_drop_na_keys
563,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_from_return_msg,"def from_return_msg(rep_msg):
from arkouda.categorical import Categorical as Categorical_
data = json.loads(rep_msg)
perm = create_pdarray(data[""permutation""])
segs = create_pdarray(data[""segments""])
uki = create_pdarray(data[""uki""])
keys = []
for k in sorted(data.keys()):  # sort keys to ensure order
create_data = data[k]
if k == ""permutation"" or k == ""segments"" or k == ""uki"":
continue
comps = create_data.split(""+|+"")
if comps[0] == pdarray.objType.upper():
keys.append(create_pdarray(comps[1]))
elif comps[0] == Strings.objType.upper():
keys.append(Strings.from_return_msg(comps[1]))
elif comps[0] == Categorical_.objType.upper():
keys.append(Categorical_.from_return_msg(comps[1]))
if len(keys) == 1:
keys = keys[0]
return GroupBy(orig_keys=keys, permutation=perm, segments=segs, uki=uki)
",[],0,[],/groupbyclass.py_from_return_msg
564,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_to_hdf,"def to_hdf(
self,
prefix_path,
dataset=""groupby"",
mode=""truncate"",
file_type=""distribute"",
",[],0,[],/groupbyclass.py_to_hdf
565,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_update_hdf,"def update_hdf(
self,
prefix_path: str,
dataset: str = ""groupby"",
repack: bool = True,
",[],0,[],/groupbyclass.py_update_hdf
566,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_size,"def size(self) -> Tuple[groupable, pdarray]:
""""""
Count the number of elements in each group, i.e. the number of times
each key appears.  This counts the total number of rows (including NaN values).
Parameters
----------
none
Returns
-------
unique_keys : (list of) pdarray or Strings
The unique keys, in grouped order
counts : pdarray, int64
The number of times each unique key appears
See Also
--------
count
Examples
--------
>>> a = ak.randint(1,5,10)
>>> a
array([3, 2, 3, 1, 2, 4, 3, 4, 3, 4])
>>> g = ak.GroupBy(a)
>>> keys,counts = g.size()
>>> keys
array([1, 2, 3, 4])
>>> counts
array([1, 2, 4, 3])
""""""
repMsg = generic_msg(
cmd=""countReduction"",
args={""segments"": cast(pdarray, self.segments), ""size"": self.length},
)
self.logger.debug(repMsg)
return self.unique_keys, create_pdarray(repMsg)
",[],0,[],/groupbyclass.py_size
567,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_count,"def count(self) -> Tuple[groupable, pdarray]:
""""""
Count the number of elements in each group, i.e. the number of times
each key appears.  This counts the total number of rows (including NaN values).
Parameters
----------
none
Returns
-------
unique_keys : (list of) pdarray or Strings
The unique keys, in grouped order
counts : pdarray, int64
The number of times each unique key appears
Notes
-----
This alias is an alias of ""size"".
Examples
--------
>>> a = ak.randint(1,5,10)
>>> a
array([3, 2, 3, 1, 2, 4, 3, 4, 3, 4])
>>> g = ak.GroupBy(a)
>>> keys,counts = g.count()
>>> keys
array([1, 2, 3, 4])
>>> counts
array([1, 2, 4, 3])
""""""
return self.size()
",[],0,[],/groupbyclass.py_count
568,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_aggregate,"def aggregate(
self,
values: groupable,
operator: str,
skipna: bool = True,
ddof: int_scalars = 1,
",[],0,[],/groupbyclass.py_aggregate
569,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_sum,"def sum(self, values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]:
""""""
Using the permutation stored in the GroupBy instance, group
another array of values and sum each group's values.
Parameters
----------
values : pdarray
The values to group and sum
Returns
-------
unique_keys : (list of) pdarray or Strings
The unique keys, in grouped order
group_sums : pdarray
One sum per unique key in the GroupBy instance
skipna: bool
boolean which determines if NANs should be skipped
Raises
------
TypeError
Raised if the values array is not a pdarray object
ValueError
Raised if the key array size does not match the values size or
if the operator is not in the GroupBy.Reductions array
Notes
-----
The grouped sum of a boolean ``pdarray`` returns integers.
Examples
--------
>>> a = ak.randint(1,5,10)
>>> a
array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
>>> g = ak.GroupBy(a)
>>> g.keys
array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
>>> b = ak.randint(1,5,10)
>>> b
array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
>>> g.sum(b)
(array([2, 3, 4]), array([8, 14, 6]))
""""""
k, v = self.aggregate(values, ""sum"", skipna)
return k, cast(pdarray, v)
",[],0,[],/groupbyclass.py_sum
570,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_prod,"def prod(self, values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]:
""""""
Using the permutation stored in the GroupBy instance, group
another array of values and compute the product of each group's
values.
Parameters
----------
values : pdarray
The values to group and multiply
skipna: bool
boolean which determines if NANs should be skipped
Returns
-------
unique_keys : (list of) pdarray or Strings
The unique keys, in grouped order
group_products : pdarray, float64
One product per unique key in the GroupBy instance
Raises
------
TypeError
Raised if the values array is not a pdarray object
ValueError
Raised if the key array size does not match the values size
or if the operator is not in the GroupBy.Reductions array
RuntimeError
Raised if prod is not supported for the values dtype
Notes
-----
The return dtype is always float64.
Examples
--------
>>> a = ak.randint(1,5,10)
>>> a
array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
>>> g = ak.GroupBy(a)
>>> g.keys
array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
>>> b = ak.randint(1,5,10)
>>> b
array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
>>> g.prod(b)
(array([2, 3, 4]), array([12, 108.00000000000003, 8.9999999999999982]))
""""""
k, v = self.aggregate(values, ""prod"", skipna)
return k, cast(pdarray, v)
",[],0,[],/groupbyclass.py_prod
571,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_var,"def var(
self, values: pdarray, skipna: bool = True, ddof: int_scalars = 1
",[],0,[],/groupbyclass.py_var
572,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_std,"def std(
self, values: pdarray, skipna: bool = True, ddof: int_scalars = 1
",[],0,[],/groupbyclass.py_std
573,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_mean,"def mean(self, values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]:
""""""
Using the permutation stored in the GroupBy instance, group
another array of values and compute the mean of each group's
values.
Parameters
----------
values : pdarray
The values to group and average
skipna: bool
boolean which determines if NANs should be skipped
Returns
-------
unique_keys : (list of) pdarray or Strings
The unique keys, in grouped order
group_means : pdarray, float64
One mean value per unique key in the GroupBy instance
Raises
------
TypeError
Raised if the values array is not a pdarray object
ValueError
Raised if the key array size does not match the values size
or if the operator is not in the GroupBy.Reductions array
Notes
-----
The return dtype is always float64.
Examples
--------
>>> a = ak.randint(1,5,10)
>>> a
array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
>>> g = ak.GroupBy(a)
>>> g.keys
array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
>>> b = ak.randint(1,5,10)
>>> b
array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
>>> g.mean(b)
(array([2, 3, 4]), array([2.6666666666666665, 2.7999999999999998, 3]))
""""""
k, v = self.aggregate(values, ""mean"", skipna)
return k, cast(pdarray, v)
",[],0,[],/groupbyclass.py_mean
574,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_median,"def median(self, values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]:
""""""
Using the permutation stored in the GroupBy instance, group
another array of values and compute the median of each group's
values.
Parameters
----------
values : pdarray
The values to group and find median
skipna: bool
boolean which determines if NANs should be skipped
Returns
-------
unique_keys : (list of) pdarray or Strings
The unique keys, in grouped order
group_medians : pdarray, float64
One median value per unique key in the GroupBy instance
Raises
------
TypeError
Raised if the values array is not a pdarray object
ValueError
Raised if the key array size does not match the values size
or if the operator is not in the GroupBy.Reductions array
Notes
-----
The return dtype is always float64.
Examples
--------
>>> a = ak.randint(1,5,9)
>>> a
array([4 1 4 3 2 2 2 3 3])
>>> g = ak.GroupBy(a)
>>> g.keys
array([4 1 4 3 2 2 2 3 3])
>>> b = ak.linspace(-5,5,9)
>>> b
array([-5 -3.75 -2.5 -1.25 0 1.25 2.5 3.75 5])
>>> g.median(b)
(array([1 2 3 4]), array([-3.75 1.25 3.75 -3.75]))
""""""
k, v = self.aggregate(values, ""median"", skipna)
return k, cast(pdarray, v)
",[],0,[],/groupbyclass.py_median
575,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_min,"def min(self, values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]:
""""""
Using the permutation stored in the GroupBy instance, group
another array of values and return the minimum of each group's
values.
Parameters
----------
values : pdarray
The values to group and find minima
skipna: bool
boolean which determines if NANs should be skipped
Returns
-------
unique_keys : (list of) pdarray or Strings
The unique keys, in grouped order
group_minima : pdarray
One minimum per unique key in the GroupBy instance
Raises
------
TypeError
Raised if the values array is not a pdarray object or if min is
not supported for the values dtype
ValueError
Raised if the key array size does not match the values size
or if the operator is not in the GroupBy.Reductions array
RuntimeError
Raised if min is not supported for the values dtype
Examples
--------
>>> a = ak.randint(1,5,10)
>>> a
array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
>>> g = ak.GroupBy(a)
>>> g.keys
array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
>>> b = ak.randint(1,5,10)
>>> b
array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
>>> g.min(b)
(array([2, 3, 4]), array([1, 1, 3]))
""""""
if values.dtype == bool:
raise TypeError(""min is only supported for pdarrays of dtype float64, uint64, and int64"")
k, v = self.aggregate(values, ""min"", skipna)
return k, cast(pdarray, v)
",[],0,[],/groupbyclass.py_min
576,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_max,"def max(self, values: pdarray, skipna: bool = True) -> Tuple[groupable, pdarray]:
""""""
Using the permutation stored in the GroupBy instance, group
another array of values and return the maximum of each
group's values.
Parameters
----------
values : pdarray
The values to group and find maxima
skipna: bool
boolean which determines if NANs should be skipped
Returns
-------
unique_keys : (list of) pdarray or Strings
The unique keys, in grouped order
group_maxima : pdarray
One maximum per unique key in the GroupBy instance
Raises
------
TypeError
Raised if the values array is not a pdarray object or if max is
not supported for the values dtype
ValueError
Raised if the key array size does not match the values size or
if the operator is not in the GroupBy.Reductions array
RuntimeError
Raised if max is not supported for the values dtype
Examples
--------
>>> a = ak.randint(1,5,10)
>>> a
array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
>>> g = ak.GroupBy(a)
>>> g.keys
array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
>>> b = ak.randint(1,5,10)
>>> b
array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
>>> g.max(b)
(array([2, 3, 4]), array([4, 4, 3]))
""""""
if values.dtype == bool:
raise TypeError(""max is only supported for pdarrays of dtype float64, uint64, and int64"")
k, v = self.aggregate(values, ""max"", skipna)
return k, cast(pdarray, v)
",[],0,[],/groupbyclass.py_max
577,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_argmin,"def argmin(self, values: pdarray) -> Tuple[groupable, pdarray]:
""""""
Using the permutation stored in the GroupBy instance, group
another array of values and return the location of the first
minimum of each group's values.
Parameters
----------
values : pdarray
The values to group and find argmin
Returns
-------
unique_keys : (list of) pdarray or Strings
The unique keys, in grouped order
group_argminima : pdarray, int64
One index per unique key in the GroupBy instance
Raises
------
TypeError
Raised if the values array is not a pdarray object or if argmax
is not supported for the values dtype
ValueError
Raised if the key array size does not match the values
size or if the operator is not in the GroupBy.Reductions array
RuntimeError
Raised if argmin is not supported for the values dtype
Notes
-----
The returned indices refer to the original values array as
passed in, not the permutation applied by the GroupBy instance.
Examples
--------
>>> a = ak.randint(1,5,10)
>>> a
array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
>>> g = ak.GroupBy(a)
>>> g.keys
array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
>>> b = ak.randint(1,5,10)
>>> b
array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
>>> g.argmin(b)
(array([2, 3, 4]), array([5, 4, 2]))
""""""
k, v = self.aggregate(values, ""argmin"")
return k, cast(pdarray, v)
",[],0,[],/groupbyclass.py_argmin
578,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_argmax,"def argmax(self, values: pdarray) -> Tuple[groupable, pdarray]:
""""""
Using the permutation stored in the GroupBy instance, group
another array of values and return the location of the first
maximum of each group's values.
Parameters
----------
values : pdarray
The values to group and find argmax
Returns
-------
unique_keys : (list of) pdarray or Strings
The unique keys, in grouped order
group_argmaxima : pdarray, int64
One index per unique key in the GroupBy instance
Raises
------
TypeError
Raised if the values array is not a pdarray object or if argmax
is not supported for the values dtype
ValueError
Raised if the key array size does not match the values size or
if the operator is not in the GroupBy.Reductions array
Notes
-----
The returned indices refer to the original values array as passed in,
not the permutation applied by the GroupBy instance.
Examples
--------
>>> a = ak.randint(1,5,10)
>>> a
array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
>>> g = ak.GroupBy(a)
>>> g.keys
array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
>>> b = ak.randint(1,5,10)
>>> b
array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
>>> g.argmax(b)
(array([2, 3, 4]), array([9, 3, 2]))
""""""
k, v = self.aggregate(values, ""argmax"")
return k, cast(pdarray, v)
",[],0,[],/groupbyclass.py_argmax
579,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py__nested_grouping_helper,"def _nested_grouping_helper(self, values: groupable) -> groupable:
unique_key_idx = self.broadcast(arange(self.ngroups), permute=True)
if hasattr(values, ""_get_grouping_keys""):
if isinstance(values, pdarray) and values.dtype == akfloat64:
raise TypeError(""grouping/uniquing unsupported for float64 arrays"")
togroup = [unique_key_idx, values]
else:
for v in values:
if isinstance(v, pdarray) and v.dtype not in [
akint64,
akuint64,
bigint,
]:
raise TypeError(""grouping/uniquing unsupported for this dtype"")
togroup = [unique_key_idx] + list(values)
return togroup
",[],0,[],/groupbyclass.py__nested_grouping_helper
580,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_nunique,"def nunique(self, values: groupable) -> Tuple[groupable, pdarray]:
""""""
Using the permutation stored in the GroupBy instance, group another
array of values and return the number of unique values in each group.
Parameters
----------
values : pdarray, int64
The values to group and find unique values
Returns
-------
unique_keys : groupable
The unique keys, in grouped order
group_nunique : groupable
Number of unique values per unique key in the GroupBy instance
Raises
------
TypeError
Raised if the dtype(s) of values array(s) does/do not support
the nunique method
ValueError
Raised if the key array size does not match the values size or
if the operator is not in the GroupBy.Reductions array
RuntimeError
Raised if nunique is not supported for the values dtype
Examples
--------
>>> data = ak.array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
>>> data
array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
>>> labels = ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
>>> labels
ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
>>> g = ak.GroupBy(labels)
>>> g.keys
ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
>>> g.nunique(data)
array([1,2,3,4]), array([2, 2, 3, 1])
""""""
togroup = self._nested_grouping_helper(values)
g = GroupBy(togroup)
g2 = GroupBy(g.unique_keys[0], assume_sorted=False)
keyorder, nuniq = g2.count()
if not is_sorted(keyorder):
perm = argsort(keyorder)
nuniq = nuniq[perm]
return self.unique_keys, nuniq
",[],0,[],/groupbyclass.py_nunique
581,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_any,"def any(self, values: pdarray) -> Tuple[Union[pdarray, List[Union[pdarray, Strings]]], pdarray]:
""""""
Using the permutation stored in the GroupBy instance, group another
array of values and perform an ""or"" reduction on each group.
Parameters
----------
values : pdarray, bool
The values to group and reduce with ""or""
Returns
-------
unique_keys : (list of) pdarray or Strings
The unique keys, in grouped order
group_any : pdarray, bool
One bool per unique key in the GroupBy instance
Raises
------
TypeError
Raised if the values array is not a pdarray or if the pdarray
dtype is not bool
ValueError
Raised if the key array size does not match the values size or
if the operator is not in the GroupBy.Reductions array
""""""
if values.dtype != bool:
raise TypeError(""any is only supported for pdarrays of dtype bool"")
return self.aggregate(values, ""any"")  # type: ignore
",[],0,[],/groupbyclass.py_any
582,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_all,"def all(self, values: pdarray) -> Tuple[Union[pdarray, List[Union[pdarray, Strings]]], pdarray]:
""""""
Using the permutation stored in the GroupBy instance, group
another array of values and perform an ""and"" reduction on
each group.
Parameters
----------
values : pdarray, bool
The values to group and reduce with ""and""
Returns
-------
unique_keys : (list of) pdarray or Strings
The unique keys, in grouped order
group_any : pdarray, bool
One bool per unique key in the GroupBy instance
Raises
------
TypeError
Raised if the values array is not a pdarray or if the pdarray
dtype is not bool
ValueError
Raised if the key array size does not match the values size or
if the operator is not in the GroupBy.Reductions array
RuntimeError
Raised if all is not supported for the values dtype
""""""
if values.dtype != bool:
raise TypeError(""all is only supported for pdarrays of dtype bool"")
return self.aggregate(values, ""all"")  # type: ignore
",[],0,[],/groupbyclass.py_all
583,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_OR,"def OR(self, values: pdarray) -> Tuple[Union[pdarray, List[Union[pdarray, Strings]]], pdarray]:
""""""
Bitwise OR of values in each segment.
Using the permutation stored in the GroupBy instance, group
another array of values and perform a bitwise OR reduction on
each group.
Parameters
----------
values : pdarray, int64
The values to group and reduce with OR
Returns
-------
unique_keys : (list of) pdarray or Strings
The unique keys, in grouped order
result : pdarray, int64
Bitwise OR of values in segments corresponding to keys
Raises
------
TypeError
Raised if the values array is not a pdarray or if the pdarray
dtype is not int64
ValueError
Raised if the key array size does not match the values size or
if the operator is not in the GroupBy.Reductions array
RuntimeError
Raised if all is not supported for the values dtype
""""""
if values.dtype not in [akint64, akuint64, bigint]:
raise TypeError(""OR is only supported for pdarrays of dtype int64, uint64, or bigint"")
return self.aggregate(values, ""or"")  # type: ignore
",[],0,[],/groupbyclass.py_OR
584,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_AND,"def AND(self, values: pdarray) -> Tuple[Union[pdarray, List[Union[pdarray, Strings]]], pdarray]:
""""""
Bitwise AND of values in each segment.
Using the permutation stored in the GroupBy instance, group
another array of values and perform a bitwise AND reduction on
each group.
Parameters
----------
values : pdarray, int64
The values to group and reduce with AND
Returns
-------
unique_keys : (list of) pdarray or Strings
The unique keys, in grouped order
result : pdarray, int64
Bitwise AND of values in segments corresponding to keys
Raises
------
TypeError
Raised if the values array is not a pdarray or if the pdarray
dtype is not int64
ValueError
Raised if the key array size does not match the values size or
if the operator is not in the GroupBy.Reductions array
RuntimeError
Raised if all is not supported for the values dtype
""""""
if values.dtype not in [akint64, akuint64, bigint]:
raise TypeError(""AND is only supported for pdarrays of dtype int64, uint64, or bigint"")
return self.aggregate(values, ""and"")  # type: ignore
",[],0,[],/groupbyclass.py_AND
585,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_XOR,"def XOR(self, values: pdarray) -> Tuple[Union[pdarray, List[Union[pdarray, Strings]]], pdarray]:
""""""
Bitwise XOR of values in each segment.
Using the permutation stored in the GroupBy instance, group
another array of values and perform a bitwise XOR reduction on
each group.
Parameters
----------
values : pdarray, int64
The values to group and reduce with XOR
Returns
-------
unique_keys : (list of) pdarray or Strings
The unique keys, in grouped order
result : pdarray, int64
Bitwise XOR of values in segments corresponding to keys
Raises
------
TypeError
Raised if the values array is not a pdarray or if the pdarray
dtype is not int64
ValueError
Raised if the key array size does not match the values size or
if the operator is not in the GroupBy.Reductions array
RuntimeError
Raised if all is not supported for the values dtype
""""""
if values.dtype not in [akint64, akuint64]:
raise TypeError(""XOR is only supported for pdarrays of dtype int64 or uint64"")
return self.aggregate(values, ""xor"")  # type: ignore
",[],0,[],/groupbyclass.py_XOR
586,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_first,"def first(self, values: groupable_element_type) -> Tuple[groupable, groupable_element_type]:
""""""
First value in each group.
Parameters
----------
values : pdarray-like
The values from which to take the first of each group
Returns
-------
unique_keys : (list of) pdarray-like
The unique keys, in grouped order
result : pdarray-like
The first value of each group
""""""
first_idx = self.permutation[self.segments]
return self.unique_keys, values[first_idx]  # type: ignore
",[],0,[],/groupbyclass.py_first
587,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_mode,"def mode(self, values: groupable) -> Tuple[groupable, groupable]:
""""""
Most common value in each group. If a group is multi-modal, return the
modal value that occurs first.
Parameters
----------
values : (list of) pdarray-like
The values from which to take the mode of each group
Returns
-------
unique_keys : (list of) pdarray-like
The unique keys, in grouped order
result : (list of) pdarray-like
The most common value of each group
""""""
togroup = self._nested_grouping_helper(values)
g = GroupBy(togroup)
keys_values, value_count = g.count()
first_rank = g.length - g.permutation[g.segments]
ki, unique_values = keys_values[0], keys_values[1:]
g2 = GroupBy(ki)
uki, mode_count = g2.max(value_count)
_, mode_idx = g2.argmax(first_rank * (value_count == g2.broadcast(mode_count)))
if not cast(pdarray, (uki == arange(self.ngroups))).all():
mode_idx = mode_idx[argsort(cast(pdarray, uki))]
if len(unique_values) == 1:
mode = unique_values[0][mode_idx]
else:
mode = [uv[mode_idx] for uv in unique_values]
return self.unique_keys, mode  # type: ignore
",[],0,[],/groupbyclass.py_mode
588,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_unique,"def unique(self, values: groupable):  # type: ignore
""""""
Return the set of unique values in each group, as a SegArray.
Parameters
----------
values : (list of) pdarray-like
The values to unique
Returns
-------
unique_keys : (list of) pdarray-like
The unique keys, in grouped order
result : (list of) SegArray
The unique values of each group
Raises
------
TypeError
Raised if values is or contains Strings or Categorical
""""""
from arkouda import Categorical
from arkouda.segarray import SegArray
if isinstance(values, (Strings, Categorical)) or (
isinstance(values, Sequence) and any([isinstance(v, (Strings, Categorical)) for v in values])
):
raise TypeError(""Groupby.unique not supported on Strings or Categorical"")
togroup = self._nested_grouping_helper(values)
g = GroupBy(togroup)
ki, unique_values = g.unique_keys[0], g.unique_keys[1:]
g2 = GroupBy(ki)
if not (g2.unique_keys == arange(self.ngroups)).all():
perm = argsort(cast(pdarray, g2.unique_keys))
reorder = True
else:
reorder = False
if len(unique_values) == 1:
ret = SegArray(g2.segments, unique_values[0])
if reorder:
ret = ret[perm]
else:
ret = [SegArray(g2.segments, uv) for uv in unique_values]  # type: ignore
if reorder:
ret = [r[perm] for r in ret]  # type: ignore
return self.unique_keys, ret  # type: ignore
",[],0,[],/groupbyclass.py_unique
589,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_broadcast,"def broadcast(
self, values: Union[pdarray, Strings], permute: bool = True
",[],0,[],/groupbyclass.py_broadcast
590,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_build_from_components,"def build_from_components(user_defined_name: str = None, **kwargs) -> GroupBy:
""""""
function to build a new GroupBy object from component keys and permutation.
Parameters
----------
user_defined_name : str (Optional) Passing a name will init the new GroupBy
and assign it the given name
kwargs : dict Dictionary of components required for rebuilding the GroupBy.
Expected keys are ""orig_keys"", ""permutation"", ""unique_keys"", and ""segments""
Returns
-------
GroupBy
The GroupBy object created by using the given components
""""""
if (
""orig_keys"" in kwargs
and ""permutation"" in kwargs
and ""unique_keys"" in kwargs
and ""segments"" in kwargs
):
g = GroupBy(None, **kwargs)
g.registered_name = user_defined_name
return g
else:
missingKeys = []
if ""orig_keys"" not in kwargs:
missingKeys.append(""orig_keys"")
if ""permutation"" not in kwargs:
missingKeys.append(""permutation"")
if ""unique_keys"" not in kwargs:
missingKeys.append(""unique_keys"")
if ""segments"" not in kwargs:
missingKeys.append(""segments"")
raise ValueError(f""Can't build GroupBy. kwargs is missing required keys: {missingKeys}."")
",[],0,[],/groupbyclass.py_build_from_components
591,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py__get_groupby_required_pieces,"def _get_groupby_required_pieces(self) -> Dict:
""""""
Internal function that returns a dictionary with all required components of self
Returns
-------
Dict
Dictionary of all required components of self
Components (keys, permutation)
""""""
requiredPieces = frozenset([""keys"", ""permutation"", ""unique_keys"", ""segments""])
return {piece_name: getattr(self, piece_name) for piece_name in requiredPieces}
",[],0,[],/groupbyclass.py__get_groupby_required_pieces
592,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_register,"def register(self, user_defined_name: str) -> GroupBy:
""""""
Register this GroupBy object and underlying components with the Arkouda server
Parameters
----------
user_defined_name : str
user defined name the GroupBy is to be registered under,
this will be the root name for underlying components
Returns
-------
GroupBy
The same GroupBy which is now registered with the arkouda server and has an updated name.
This is an in-place modification, the original is returned to support a
fluid programming style.
Please note you cannot register two different GroupBys with the same name.
Raises
------
TypeError
Raised if user_defined_name is not a str
RegistrationError
If the server was unable to register the GroupBy with the user_defined_name
See also
--------
unregister, attach, unregister_groupby_by_name, is_registered
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda import Categorical
if self.registered_name is not None and self.is_registered():
raise RegistrationError(f""This object is already registered as {self.registered_name}"")
if isinstance(self.keys, (pdarray, Strings, Categorical)):
key_data = [
self.keys
if not isinstance(self.keys, Categorical)
else json.dumps(
{
""codes"": self.keys.codes.name,
""categories"": self.keys.categories.name,
""NA_codes"": self.keys._akNAcode.name,
{""permutation"": self.keys.permutation.name}
if self.keys.permutation is not None
else {}
),
{""segments"": self.keys.segments.name}
if self.keys.segments is not None
else {}
),
}
)
]
else:
key_data = [
k.name
if not isinstance(k, Categorical)
else json.dumps(
{
""codes"": k.codes.name,
""categories"": k.categories.name,
""NA_codes"": k._akNAcode.name,
}
)
for k in self.keys
]
generic_msg(
cmd=""register"",
args={
""name"": user_defined_name,
""objType"": self.objType,
""segments"": self.segments,
""permutation"": self.permutation,
""uki"": self._uki,
""num_keys"": len(self.keys) if isinstance(self.keys, Sequence) else 1,
""keys"": key_data,
""key_objTypes"": [key.objType for key in self.keys]
if isinstance(self.keys, Sequence)
else [self.keys.objType],
},
)
self.registered_name = user_defined_name
return self
",[],0,[],/groupbyclass.py_register
593,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_unregister,"def unregister(self):
""""""
Unregister this GroupBy object in the arkouda server which was previously
registered using register() and/or attached to using attach()
Raises
------
RegistrationError
If the object is already unregistered or if there is a server error
when attempting to unregister
See also
--------
register, attach, unregister_groupby_by_name, is_registered
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.util import unregister
if not self.registered_name:
raise RegistrationError(
""This item does not have a name and does not appear to be registered.""
)
unregister(self.registered_name)
self.registered_name = None  # Clear our internal GroupBy object name
",[],0,[],/groupbyclass.py_unregister
594,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_is_registered,"def is_registered(self) -> bool:
""""""
Return True if the object is contained in the registry
Returns
-------
bool
Indicates if the object is contained in the registry
Raises
------
RegistrationError
Raised if there's a server-side error or a mismatch of registered components
See Also
--------
register, attach, unregister, unregister_groupby_by_name
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.util import is_registered
if self.registered_name is None:
return False
return is_registered(self.registered_name)
",[],0,[],/groupbyclass.py_is_registered
595,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_attach,"def attach(user_defined_name: str) -> GroupBy:
""""""
Function to return a GroupBy object attached to the registered name in the
arkouda server which was registered using register()
Parameters
----------
user_defined_name : str
user defined name which GroupBy object was registered under
Returns
-------
GroupBy
The GroupBy object created by re-attaching to the corresponding server components
Raises
------
RegistrationError
if user_defined_name is not registered
See Also
--------
register, is_registered, unregister, unregister_groupby_by_name
""""""
import warnings
from arkouda.util import attach
warnings.warn(
""ak.GroupBy.attach() is deprecated. Please use ak.attach() instead."",
DeprecationWarning,
)
return attach(user_defined_name)
",[],0,[],/groupbyclass.py_attach
596,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_unregister_groupby_by_name,"def unregister_groupby_by_name(user_defined_name: str) -> None:
""""""
Function to unregister GroupBy object by name which was registered
with the arkouda server via register()
Parameters
----------
user_defined_name : str
Name under which the GroupBy object was registered
Raises
-------
TypeError
if user_defined_name is not a string
RegistrationError
if there is an issue attempting to unregister any underlying components
See Also
--------
register, unregister, attach, is_registered
""""""
import warnings
from arkouda.util import unregister
warnings.warn(
""ak.GroupBy.unregister_groupby_by_name() is deprecated. Please use ak.unregister() instead."",
DeprecationWarning,
)
return unregister(user_defined_name)
",[],0,[],/groupbyclass.py_unregister_groupby_by_name
597,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_most_common,"def most_common(self, values):
""""""
(Deprecated) See `GroupBy.mode()`.
""""""
return self.mode(values)
",[],0,[],/groupbyclass.py_most_common
598,/home/amandapotts/git/arkouda/arkouda/groupbyclass.py_broadcast,"def broadcast(
segments: pdarray,
values: Union[pdarray, Strings],
size: Union[int, np.int64, np.uint64] = -1,
permutation: Union[pdarray, None] = None,
","['int64', 'uint64']",2,[],/groupbyclass.py_broadcast
599,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_parse_single_value,"def parse_single_value(msg: str) -> object:
""""""
Attempt to convert a scalar return value from the arkouda server to a
numpy scalar in Python. The user should not call this function directly.
Parameters
----------
msg : str
scalar value in string form to be converted to a numpy scalar
Returns
-------
object numpy scalar
""""""
",[],0,[],/pdarrayclass.py_parse_single_value
600,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_unescape,"def unescape(s):
escaping = False
res = """"
for c in s:
if escaping:
res += c
escaping = False
elif c == ""\\"":
escaping = True
else:
res += c
return res
",[],0,[],/pdarrayclass.py_unescape
601,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___init__,"def __init__(
self,
name: str,
mydtype: Union[np.dtype, str],
size: int_scalars,
ndim: int_scalars,
shape: Sequence[int],
itemsize: int_scalars,
max_bits: Optional[int] = None,
",['dtype'],1,[],/pdarrayclass.py___init__
602,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___del__,"def __del__(self):
try:
logger.debug(f""deleting pdarray with name {self.name}"")
generic_msg(cmd=""delete"", args={""name"": self.name})
except (RuntimeError, AttributeError):
pass
",[],0,[],/pdarrayclass.py___del__
603,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___bool__,"def __bool__(self) -> builtins.bool:
if self.size != 1:
raise ValueError(
""The truth value of an array with more than one element is ambiguous.""
""Use a.any() or a.all()""
)
return builtins.bool(self[0])
",[],0,[],/pdarrayclass.py___bool__
604,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___len__,"def __len__(self):
return self.size
",[],0,[],/pdarrayclass.py___len__
605,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___str__,"def __str__(self):
from arkouda.client import pdarrayIterThresh
return generic_msg(cmd=""str"", args={""array"": self, ""printThresh"": pdarrayIterThresh})
",[],0,[],/pdarrayclass.py___str__
606,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___repr__,"def __repr__(self):
from arkouda.client import pdarrayIterThresh
return generic_msg(cmd=""repr"", args={""array"": self, ""printThresh"": pdarrayIterThresh})
",[],0,[],/pdarrayclass.py___repr__
607,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_max_bits,"def max_bits(self):
if self.dtype == bigint:
if not hasattr(self, ""_max_bits""):
self._max_bits = generic_msg(cmd=""get_max_bits"", args={""array"": self})
return int(self._max_bits)
return None
",[],0,[],/pdarrayclass.py_max_bits
608,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_max_bits,"def max_bits(self, max_bits):
if self.dtype == bigint:
generic_msg(cmd=""set_max_bits"", args={""array"": self, ""max_bits"": max_bits})
self._max_bits = max_bits
",[],0,[],/pdarrayclass.py_max_bits
609,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_format_other,"def format_other(self, other) -> str:
""""""
Attempt to cast scalar other to the element dtype of this pdarray,
and print the resulting value to a string (e.g. for sending to a
server command). The user should not call this function directly.
Parameters
----------
other : object
The scalar to be cast to the pdarray.dtype
Returns
-------
string representation of np.dtype corresponding to the other parameter
Raises
------
TypeError
Raised if the other parameter cannot be converted to
Numpy dtype
""""""
try:
if self.dtype != bigint:
other = np.array([other]).astype(self.dtype)[0]
else:
other = int(other)
except Exception:
raise TypeError(f""Unable to convert {other} to {self.dtype.name}"")
if self.dtype == bool:
return str(other)
fmt = NUMBER_FORMAT_STRINGS[self.dtype.name]
return fmt.format(other)
","['dtype', 'array']",2,['array([other]).astype(self.dtype)'],/pdarrayclass.py_format_other
610,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py__binop,"def _binop(self, other: pdarray, op: str) -> pdarray:
""""""
Executes binary operation specified by the op string
Parameters
----------
other : pdarray
The pdarray upon which the binop is to be executed
op : str
The binop to be executed
Returns
-------
pdarray
A pdarray encapsulating the binop result
Raises
------
ValueError
Raised if the op is not within the pdarray.BinOps set, or if the
pdarray sizes don't match
TypeError
Raised if other is not a pdarray or the pdarray.dtype is not
a supported dtype
""""""
if type(other) is not pdarray and issubclass(type(other), pdarray):
return NotImplemented
if op not in self.BinOps:
raise ValueError(f""bad operator {op}"")
if isinstance(other, pdarray):
try:
x1, x2, tmp_x1, tmp_x2 = broadcast_if_needed(self, other)
except ValueError:
raise ValueError(f""shape mismatch {self.shape} {other.shape}"")
repMsg = generic_msg(cmd=f""binopvv{x1.ndim}D"", args={""op"": op, ""a"": x1, ""b"": x2})
if tmp_x1:
del x1
if tmp_x2:
del x2
return create_pdarray(repMsg)
dt = resolve_scalar_dtype(other)
if self.dtype != bigint and np.can_cast(other, self.dtype):
dt = self.dtype.name
other = self.dtype.type(other)
if dt not in DTypes:
raise TypeError(f""Unhandled scalar type: {other} ({type(other)})"")
repMsg = generic_msg(
cmd=f""binopvs{self.ndim}D"",
args={""op"": op, ""a"": self, ""dtype"": dt, ""value"": other},
)
return create_pdarray(repMsg)
",['can_cast'],1,"['can_cast(other, self.dtype)']",/pdarrayclass.py__binop
611,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py__r_binop,"def _r_binop(self, other: pdarray, op: str) -> pdarray:
""""""
Executes reverse binary operation specified by the op string
Parameters
----------
other : pdarray
The pdarray upon which the reverse binop is to be executed
op : str
The name of the reverse binop to be executed
Returns
-------
pdarray
A pdarray encapsulating the reverse binop result
Raises
------
ValueError
Raised if the op is not within the pdarray.BinOps set
TypeError
Raised if other is not a pdarray or the pdarray.dtype is not
a supported dtype
""""""
if op not in self.BinOps:
raise ValueError(f""bad operator {op}"")
dt = resolve_scalar_dtype(other)
if self.dtype != bigint and np.can_cast(other, self.dtype):
dt = self.dtype.name
other = self.dtype.type(other)
if dt not in DTypes:
raise TypeError(f""Unhandled scalar type: {other} ({type(other)})"")
repMsg = generic_msg(
cmd=f""binopsv{self.ndim}D"",
args={""op"": op, ""dtype"": dt, ""value"": other, ""a"": self},
)
return create_pdarray(repMsg)
",['can_cast'],1,"['can_cast(other, self.dtype)']",/pdarrayclass.py__r_binop
612,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_transfer,"def transfer(self, hostname: str, port: int_scalars):
""""""
Sends a pdarray to a different Arkouda server
Parameters
----------
hostname : str
The hostname where the Arkouda server intended to
receive the pdarray is running.
port : int_scalars
The port to send the array over. This needs to be an
open port (i.e., not one that the Arkouda server is
running on). This will open up `numLocales` ports,
each of which in succession, so will use ports of the
range {port..(port+numLocales)} (e.g., running an
Arkouda server of 4 nodes, port 1234 is passed as
`port`, Arkouda will use ports 1234, 1235, 1236,
and 1237 to send the array data).
This port much match the port passed to the call to
`ak.receive_array()`.
Returns
-------
A message indicating a complete transfer
Raises
------
ValueError
Raised if the op is not within the pdarray.BinOps set
TypeError
Raised if other is not a pdarray or the pdarray.dtype is not
a supported dtype
""""""
return generic_msg(
cmd=""sendArray"",
args={""arg1"": self, ""hostname"": hostname, ""port"": port, ""objType"": ""pdarray""},
)
",[],0,[],/pdarrayclass.py_transfer
613,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___add__,"def __add__(self, other):
return self._binop(other, ""+"")
",[],0,[],/pdarrayclass.py___add__
614,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___radd__,"def __radd__(self, other):
return self._r_binop(other, ""+"")
",[],0,[],/pdarrayclass.py___radd__
615,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___sub__,"def __sub__(self, other):
return self._binop(other, ""-"")
",[],0,[],/pdarrayclass.py___sub__
616,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___rsub__,"def __rsub__(self, other):
return self._r_binop(other, ""-"")
",[],0,[],/pdarrayclass.py___rsub__
617,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___mul__,"def __mul__(self, other):
return self._binop(other, ""*"")
",[],0,[],/pdarrayclass.py___mul__
618,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___rmul__,"def __rmul__(self, other):
return self._r_binop(other, ""*"")
",[],0,[],/pdarrayclass.py___rmul__
619,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___truediv__,"def __truediv__(self, other):
return self._binop(other, ""/"")
",[],0,[],/pdarrayclass.py___truediv__
620,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___rtruediv__,"def __rtruediv__(self, other):
return self._r_binop(other, ""/"")
",[],0,[],/pdarrayclass.py___rtruediv__
621,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___floordiv__,"def __floordiv__(self, other):
return self._binop(other, ""//"")
",[],0,[],/pdarrayclass.py___floordiv__
622,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___rfloordiv__,"def __rfloordiv__(self, other):
return self._r_binop(other, ""//"")
",[],0,[],/pdarrayclass.py___rfloordiv__
623,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___mod__,"def __mod__(self, other):
return self._binop(other, ""%"")
",[],0,[],/pdarrayclass.py___mod__
624,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___rmod__,"def __rmod__(self, other):
return self._r_binop(other, ""%"")
",[],0,[],/pdarrayclass.py___rmod__
625,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___lshift__,"def __lshift__(self, other):
return self._binop(other, ""<<"")
",[],0,[],/pdarrayclass.py___lshift__
626,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___rlshift__,"def __rlshift__(self, other):
return self._r_binop(other, ""<<"")
",[],0,[],/pdarrayclass.py___rlshift__
627,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___rshift__,"def __rshift__(self, other):
return self._binop(other, "">>"")
",[],0,[],/pdarrayclass.py___rshift__
628,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___rrshift__,"def __rrshift__(self, other):
return self._r_binop(other, "">>"")
",[],0,[],/pdarrayclass.py___rrshift__
629,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___and__,"def __and__(self, other):
return self._binop(other, ""&"")
",[],0,[],/pdarrayclass.py___and__
630,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___rand__,"def __rand__(self, other):
return self._r_binop(other, ""&"")
",[],0,[],/pdarrayclass.py___rand__
631,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___or__,"def __or__(self, other):
return self._binop(other, ""|"")
",[],0,[],/pdarrayclass.py___or__
632,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___ror__,"def __ror__(self, other):
return self._r_binop(other, ""|"")
",[],0,[],/pdarrayclass.py___ror__
633,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___xor__,"def __xor__(self, other):
return self._binop(other, ""^"")
",[],0,[],/pdarrayclass.py___xor__
634,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___rxor__,"def __rxor__(self, other):
return self._r_binop(other, ""^"")
",[],0,[],/pdarrayclass.py___rxor__
635,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___pow__,"def __pow__(self, other):
return self._binop(other, ""**"")
",[],0,[],/pdarrayclass.py___pow__
636,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___rpow__,"def __rpow__(self, other):
return self._r_binop(other, ""**"")
",[],0,[],/pdarrayclass.py___rpow__
637,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___lt__,"def __lt__(self, other):
return self._binop(other, ""<"")
",[],0,[],/pdarrayclass.py___lt__
638,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___gt__,"def __gt__(self, other):
return self._binop(other, "">"")
",[],0,[],/pdarrayclass.py___gt__
639,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___le__,"def __le__(self, other):
return self._binop(other, ""<="")
",[],0,[],/pdarrayclass.py___le__
640,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___ge__,"def __ge__(self, other):
return self._binop(other, "">="")
",[],0,[],/pdarrayclass.py___ge__
641,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___eq__,"def __eq__(self, other):
if (self.dtype == bool) and (isinstance(other, pdarray) and (other.dtype == bool)):
return ~(self ^ other)
else:
return self._binop(other, ""=="")
",[],0,[],/pdarrayclass.py___eq__
642,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___ne__,"def __ne__(self, other):
if (self.dtype == bool) and (isinstance(other, pdarray) and (other.dtype == bool)):
return self ^ other
else:
return self._binop(other, ""!="")
",[],0,[],/pdarrayclass.py___ne__
643,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___neg__,"def __neg__(self):
return self._binop(-1, ""*"")
",[],0,[],/pdarrayclass.py___neg__
644,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___invert__,"def __invert__(self):
if self.dtype == akint64:
return self._binop(~0, ""^"")
if self.dtype == akuint64:
return self._binop(~np.uint(0), ""^"")
if self.dtype == bool:
return self._binop(True, ""^"")
raise TypeError(f""Unhandled dtype: {self} ({self.dtype})"")
",['uint'],1,"['uint(0), ""^"")']",/pdarrayclass.py___invert__
645,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_opeq,"def opeq(self, other, op):
if op not in self.OpEqOps:
raise ValueError(f""bad operator {op}"")
if isinstance(other, pdarray):
if self.shape != other.shape:
raise ValueError(f""shape mismatch {self.shape} {other.shape}"")
generic_msg(cmd=f""opeqvv{self.ndim}D"", args={""op"": op, ""a"": self, ""b"": other})
return self
try:
other = self.dtype.type(other)
except Exception:
raise TypeError(f""Unhandled scalar type: {other} ({type(other)})"")
generic_msg(
cmd=f""opeqvs{self.ndim}D"",
args={""op"": op, ""a"": self, ""dtype"": self.dtype.name, ""value"": self.format_other(other)},
)
return self
",[],0,[],/pdarrayclass.py_opeq
646,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___iadd__,"def __iadd__(self, other):
return self.opeq(other, ""+="")
",[],0,[],/pdarrayclass.py___iadd__
647,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___isub__,"def __isub__(self, other):
return self.opeq(other, ""-="")
",[],0,[],/pdarrayclass.py___isub__
648,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___imul__,"def __imul__(self, other):
return self.opeq(other, ""*="")
",[],0,[],/pdarrayclass.py___imul__
649,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___itruediv__,"def __itruediv__(self, other):
return self.opeq(other, ""/="")
",[],0,[],/pdarrayclass.py___itruediv__
650,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___imod__,"def __imod__(self, other):
return self.opeq(other, ""%="")
",[],0,[],/pdarrayclass.py___imod__
651,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___ifloordiv__,"def __ifloordiv__(self, other):
return self.opeq(other, ""//="")
",[],0,[],/pdarrayclass.py___ifloordiv__
652,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___ilshift__,"def __ilshift__(self, other):
return self.opeq(other, ""<<="")
",[],0,[],/pdarrayclass.py___ilshift__
653,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___irshift__,"def __irshift__(self, other):
return self.opeq(other, "">>="")
",[],0,[],/pdarrayclass.py___irshift__
654,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___iand__,"def __iand__(self, other):
return self.opeq(other, ""&="")
",[],0,[],/pdarrayclass.py___iand__
655,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___ior__,"def __ior__(self, other):
return self.opeq(other, ""|="")
",[],0,[],/pdarrayclass.py___ior__
656,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___ixor__,"def __ixor__(self, other):
return self.opeq(other, ""^="")
",[],0,[],/pdarrayclass.py___ixor__
657,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___ipow__,"def __ipow__(self, other):
return self.opeq(other, ""**="")
",[],0,[],/pdarrayclass.py___ipow__
658,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___iter__,"def __iter__(self):
raise NotImplementedError(
""pdarray does not support iteration. To force data transfer from server, use to_ndarray""
)
",[],0,[],/pdarrayclass.py___iter__
659,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___getitem__,"def __getitem__(self, key):
if self.ndim == 1 and np.isscalar(key) and (resolve_scalar_dtype(key) in [""int64"", ""uint64""]):
orig_key = key
if key < 0:
key += self.size
if key >= 0 and key < self.size:
repMsg = generic_msg(
cmd=""[int]1D"",
args={
""array"": self,
""idx"": key,
},
)
fields = repMsg.split()
return parse_single_value("" "".join(fields[1:]))
else:
raise IndexError(f""[int] {orig_key} is out of bounds with size {self.size}"")
if self.ndim == 1 and isinstance(key, slice):
(start, stop, stride) = key.indices(self.size)
repMsg = generic_msg(
cmd=""[slice]1D"",
args={
""array"": self,
""start"": start,
""stop"": stop,
""stride"": stride,
},
)
return create_pdarray(repMsg)
if isinstance(key, tuple):
allScalar = True
starts = []
stops = []
strides = []
for dim, k in enumerate(key):
if isinstance(k, slice):
allScalar = False
(start, stop, stride) = k.indices(self.shape[dim])
starts.append(start)
stops.append(stop)
strides.append(stride)
elif np.isscalar(k) and (resolve_scalar_dtype(k) in [""int64"", ""uint64""]):
if k < 0:
k += int(self.shape[dim])
if k < 0 or k >= int(self.shape[dim]):
raise IndexError(
f""index {k} is out of bounds in dimension {dim} with size {self.shape[dim]}""
)
else:
starts.append(k)
stops.append(k+1)
strides.append(1)
else:
raise IndexError(f""Unhandled key type: {k} ({type(k)})"")
if allScalar:
repMsg = generic_msg(
cmd=f""[int]{self.ndim}D"",
args={
""array"": self,
""idx"": key,
},
)
fields = repMsg.split()
return parse_single_value("" "".join(fields[1:]))
else:
repMsg = generic_msg(
cmd=f""[slice]{self.ndim}D"",
args={
""array"": self,
""starts"": tuple(starts),
""stops"": tuple(stops),
""strides"": tuple(strides),
},
)
print(repMsg)
return create_pdarray(repMsg)
if isinstance(key, pdarray) and self.ndim == 1:
kind, _ = translate_np_dtype(key.dtype)
if kind not in (""bool"", ""int"", ""uint""):
raise TypeError(f""unsupported pdarray index type {key.dtype}"")
if kind == ""bool"" and self.size != key.size:
raise ValueError(f""size mismatch {self.size} {key.size}"")
repMsg = generic_msg(
cmd=""[pdarray]"",
args={
""array"": self,
""idx"": key,
},
)
return create_pdarray(repMsg)
else:
raise TypeError(f""Unhandled key type: {key} ({type(key)})"")
","['isscalar', 'isscalar']",2,"['isscalar(key) and (resolve_scalar_dtype(key) in [""int64"", ""uint64""])', 'isscalar(k) and (resolve_scalar_dtype(k) in [""int64"", ""uint64""])']",/pdarrayclass.py___getitem__
660,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py___setitem__,"def __setitem__(self, key, value):
if np.isscalar(key) and (resolve_scalar_dtype(key) in [""int64"", ""uint64""]):
orig_key = key
if key < 0:
key += self.size
if key >= 0 and key < self.size:
generic_msg(
cmd=""[int]=val"",
args={
""array"": self,
""idx"": key,
""dtype"": self.dtype,
""value"": self.format_other(value),
},
)
else:
raise IndexError(f""index {orig_key} is out of bounds with size {self.size}"")
elif isinstance(key, pdarray):
if isinstance(value, pdarray):
generic_msg(cmd=""[pdarray]=pdarray"", args={""array"": self, ""idx"": key, ""value"": value})
else:
generic_msg(
cmd=""[pdarray]=val"",
args={
""array"": self,
""idx"": key,
""dtype"": self.dtype,
""value"": self.format_other(value),
},
)
elif isinstance(key, slice):
(start, stop, stride) = key.indices(self.size)
logger.debug(f""start: {start} stop: {stop} stride: {stride}"")
if isinstance(value, pdarray):
generic_msg(
cmd=""[slice]=pdarray"",
args={
""array"": self,
""start"": start,
""stop"": stop,
""stride"": stride,
""value"": value,
},
)
else:
generic_msg(
cmd=""[slice]=val"",
args={
""array"": self,
""start"": start,
""stop"": stop,
""stride"": stride,
""dtype"": self.dtype,
""value"": self.format_other(value),
},
)
else:
raise TypeError(f""Unhandled key type: {key} ({type(key)})"")
",['isscalar'],1,"['isscalar(key) and (resolve_scalar_dtype(key) in [""int64"", ""uint64""])']",/pdarrayclass.py___setitem__
661,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_fill,"def fill(self, value: numeric_scalars) -> None:
""""""
Fill the array (in place) with a constant value.
Parameters
----------
value : numeric_scalars
Raises
-------
TypeError
Raised if value is not an int, int64, float, or float64
""""""
cmd = f""set{self.ndim}D""
generic_msg(
cmd=cmd, args={""array"": self, ""dtype"": self.dtype.name, ""val"": self.format_other(value)}
)
",[],0,[],/pdarrayclass.py_fill
662,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_any,"def any(self) -> np.bool_:
""""""
Return True iff any element of the array evaluates to True.
""""""
return any(self)
",['bool_'],1,[],/pdarrayclass.py_any
663,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_all,"def all(self) -> np.bool_:
""""""
Return True iff all elements of the array evaluate to True.
""""""
return all(self)
",['bool_'],1,[],/pdarrayclass.py_all
664,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_is_registered,"def is_registered(self) -> np.bool_:
""""""
Return True iff the object is contained in the registry
Parameters
----------
None
Returns
-------
bool
Indicates if the object is contained in the registry
Raises
------
RuntimeError
Raised if there's a server-side error thrown
Note
-----
This will return True if the object is registered itself or as a component
of another object
""""""
from arkouda.util import is_registered
if self.registered_name is None:
return np.bool_(is_registered(self.name, as_component=True))
else:
return np.bool_(is_registered(self.registered_name))
","['bool_', 'bool_', 'bool_']",3,"['bool_(is_registered(self.name, as_component=True))', 'bool_(is_registered(self.registered_name))']",/pdarrayclass.py_is_registered
665,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py__list_component_names,"def _list_component_names(self) -> List[str]:
""""""
Internal Function that returns a list of all component names
Parameters
----------
None
Returns
-------
List[str]
List of all component names
""""""
return [self.name]
",[],0,[],/pdarrayclass.py__list_component_names
666,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_info,"def info(self) -> str:
""""""
Returns a JSON formatted string containing information about all components of self
Parameters
----------
None
Returns
-------
str
JSON string containing information about all components of self
""""""
return information(self._list_component_names())
",[],0,[],/pdarrayclass.py_info
667,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_pretty_print_info,"def pretty_print_info(self) -> None:
""""""
Prints information about all components of self in a human readable format
Parameters
----------
None
Returns
-------
None
""""""
pretty_print_information(self._list_component_names())
",[],0,[],/pdarrayclass.py_pretty_print_info
668,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_is_sorted,"def is_sorted(self) -> np.bool_:
""""""
Return True iff the array is monotonically non-decreasing.
Parameters
----------
None
Returns
-------
bool
Indicates if the array is monotonically non-decreasing
Raises
------
TypeError
Raised if pda is not a pdarray instance
RuntimeError
Raised if there's a server-side error thrown
""""""
return is_sorted(self)
",['bool_'],1,[],/pdarrayclass.py_is_sorted
669,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_sum,"def sum(self) -> numeric_and_bool_scalars:
""""""
Return the sum of all elements in the array.
""""""
return sum(self)
",[],0,[],/pdarrayclass.py_sum
670,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_prod,"def prod(self) -> np.float64:
""""""
Return the product of all elements in the array. Return value is
always a np.float64 or np.int64.
""""""
return prod(self)
","['float64', 'float64', 'int64.']",3,[],/pdarrayclass.py_prod
671,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_min,"def min(self) -> numpy_scalars:
""""""
Return the minimum value of the array.
""""""
return min(self)
",[],0,[],/pdarrayclass.py_min
672,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_max,"def max(self) -> numpy_scalars:
""""""
Return the maximum value of the array.
""""""
return max(self)
",[],0,[],/pdarrayclass.py_max
673,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_argmin,"def argmin(self) -> Union[np.int64, np.uint64]:
""""""
Return the index of the first occurrence of the array min value
""""""
return argmin(self)
","['int64', 'uint64']",2,[],/pdarrayclass.py_argmin
674,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_argmax,"def argmax(self) -> Union[np.int64, np.uint64]:
""""""
Return the index of the first occurrence of the array max value.
""""""
return argmax(self)
","['int64', 'uint64']",2,[],/pdarrayclass.py_argmax
675,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_mean,"def mean(self) -> np.float64:
""""""
Return the mean of the array.
""""""
return mean(self)
",['float64'],1,[],/pdarrayclass.py_mean
676,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_var,"def var(self, ddof: int_scalars = 0) -> np.float64:
""""""
Compute the variance. See ``arkouda.var`` for details.
Parameters
----------
ddof : int_scalars
""Delta Degrees of Freedom"" used in calculating var
Returns
-------
np.float64
The scalar variance of the array
Raises
------
TypeError
Raised if pda is not a pdarray instance
ValueError
Raised if the ddof >= pdarray size
RuntimeError
Raised if there's a server-side error thrown
""""""
return var(self, ddof=ddof)
","['float64', 'float64']",2,[],/pdarrayclass.py_var
677,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_std,"def std(self, ddof: int_scalars = 0) -> np.float64:
""""""
Compute the standard deviation. See ``arkouda.std`` for details.
Parameters
----------
ddof : int_scalars
""Delta Degrees of Freedom"" used in calculating std
Returns
-------
np.float64
The scalar standard deviation of the array
Raises
------
TypeError
Raised if pda is not a pdarray instance
RuntimeError
Raised if there's a server-side error thrown
""""""
return std(self, ddof=ddof)
","['float64', 'float64']",2,[],/pdarrayclass.py_std
678,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_cov,"def cov(self, y: pdarray) -> np.float64:
""""""
Compute the covariance between self and y.
Parameters
----------
y : pdarray
Other pdarray used to calculate covariance
Returns
-------
np.float64
The scalar covariance of the two arrays
Raises
------
TypeError
Raised if y is not a pdarray instance
RuntimeError
Raised if there's a server-side error thrown
""""""
return cov(self, y)
","['float64', 'float64']",2,[],/pdarrayclass.py_cov
679,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_corr,"def corr(self, y: pdarray) -> np.float64:
""""""
Compute the correlation between self and y using pearson correlation coefficient.
Parameters
----------
y : pdarray
Other pdarray used to calculate correlation
Returns
-------
np.float64
The scalar correlation of the two arrays
Raises
------
TypeError
Raised if y is not a pdarray instance
RuntimeError
Raised if there's a server-side error thrown
""""""
return corr(self, y)
","['float64', 'float64']",2,[],/pdarrayclass.py_corr
680,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_mink,"def mink(self, k: int_scalars) -> pdarray:
""""""
Compute the minimum ""k"" values.
Parameters
----------
k : int_scalars
The desired count of maximum values to be returned by the output.
Returns
-------
pdarray, int
The maximum `k` values from pda
Raises
------
TypeError
Raised if pda is not a pdarray
""""""
return mink(self, k)
",[],0,[],/pdarrayclass.py_mink
681,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_maxk,"def maxk(self, k: int_scalars) -> pdarray:
""""""
Compute the maximum ""k"" values.
Parameters
----------
k : int_scalars
The desired count of maximum values to be returned by the output.
Returns
-------
pdarray, int
The maximum `k` values from pda
Raises
------
TypeError
Raised if pda is not a pdarray
""""""
return maxk(self, k)
",[],0,[],/pdarrayclass.py_maxk
682,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_argmink,"def argmink(self, k: int_scalars) -> pdarray:
""""""
Compute the minimum ""k"" values.
Parameters
----------
k : int_scalars
The desired count of maximum values to be returned by the output.
Returns
-------
pdarray, int
Indices corresponding to the maximum `k` values from pda
Raises
------
TypeError
Raised if pda is not a pdarray
""""""
return argmink(self, k)
",[],0,[],/pdarrayclass.py_argmink
683,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_argmaxk,"def argmaxk(self, k: int_scalars) -> pdarray:
""""""
Finds the indices corresponding to the maximum ""k"" values.
Parameters
----------
k : int_scalars
The desired count of maximum values to be returned by the output.
Returns
-------
pdarray, int
Indices corresponding to the  maximum `k` values, sorted
Raises
------
TypeError
Raised if pda is not a pdarray
""""""
return argmaxk(self, k)
",[],0,[],/pdarrayclass.py_argmaxk
684,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_popcount,"def popcount(self) -> pdarray:
""""""
Find the population (number of bits set) in each element. See `ak.popcount`.
""""""
return popcount(self)
",[],0,[],/pdarrayclass.py_popcount
685,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_parity,"def parity(self) -> pdarray:
""""""
Find the parity (XOR of all bits) in each element. See `ak.parity`.
""""""
return parity(self)
",[],0,[],/pdarrayclass.py_parity
686,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_clz,"def clz(self) -> pdarray:
""""""
Count the number of leading zeros in each element. See `ak.clz`.
""""""
return clz(self)
",[],0,[],/pdarrayclass.py_clz
687,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_ctz,"def ctz(self) -> pdarray:
""""""
Count the number of trailing zeros in each element. See `ak.ctz`.
""""""
return ctz(self)
",[],0,[],/pdarrayclass.py_ctz
688,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_rotl,"def rotl(self, other) -> pdarray:
""""""
Rotate bits left by <other>.
""""""
return rotl(self, other)
",[],0,[],/pdarrayclass.py_rotl
689,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_rotr,"def rotr(self, other) -> pdarray:
""""""
Rotate bits right by <other>.
""""""
return rotr(self, other)
",[],0,[],/pdarrayclass.py_rotr
690,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_value_counts,"def value_counts(self):
""""""
Count the occurrences of the unique values of self.
Returns
-------
unique_values : pdarray
The unique values, sorted in ascending order
counts : pdarray, int64
The number of times the corresponding unique value occurs
Examples
--------
>>> ak.array([2, 0, 2, 4, 0, 0]).value_counts()
(array([0, 2, 4]), array([3, 2, 1]))
""""""
from arkouda.numeric import value_counts
return value_counts(self)
",[],0,[],/pdarrayclass.py_value_counts
691,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_astype,"def astype(self, dtype) -> pdarray:
""""""
Cast values of pdarray to provided dtype
Parameters
__________
dtype: np.dtype or str
Dtype to cast to
Returns
_______
ak.pdarray
An arkouda pdarray with values converted to the specified data type
Notes
_____
This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.
""""""
from arkouda.numeric import cast as akcast
return akcast(self, dtype)
",['dtype'],1,[],/pdarrayclass.py_astype
692,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_slice_bits,"def slice_bits(self, low, high) -> pdarray:
""""""
Returns a pdarray containing only bits from low to high of self.
This is zero indexed and inclusive on both ends, so slicing the bottom 64 bits is
pda.slice_bits(0, 63)
Parameters
__________
low: int
The lowest bit included in the slice (inclusive)
zero indexed, so the first bit is 0
high: int
The highest bit included in the slice (inclusive)
Returns
-------
pdarray
A new pdarray containing the bits of self from low to high
Raises
------
RuntimeError
Raised if there is a server-side error thrown
Examples
--------
>>> p = ak.array([2**65 + (2**64 - 1)])
>>> bin(p[0])
'0b101111111111111111111111111111111111111111111111111111111111111111'
>>> bin(p.slice_bits(64, 65)[0])
'0b10'
""""""
if low > high:
raise ValueError(""low must not exceed high"")
return (self >> low) % 2 ** (high - low + 1)
",[],0,[],/pdarrayclass.py_slice_bits
693,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_bigint_to_uint_arrays,"def bigint_to_uint_arrays(self) -> List[pdarray]:
""""""
Creates a list of uint pdarrays from a bigint pdarray.
The first item in return will be the highest 64 bits of the
bigint pdarray and the last item will be the lowest 64 bits.
Returns
-------
List[pdarrays]
A list of uint pdarrays where:
The first item in return will be the highest 64 bits of the
bigint pdarray and the last item will be the lowest 64 bits.
Raises
------
RuntimeError
Raised if there is a server-side error thrown
See Also
--------
pdarraycreation.bigint_from_uint_arrays
Examples
--------
>>> a = ak.arange(2**64, 2**64 + 5)
>>> a
array([""18446744073709551616"" ""18446744073709551617"" ""18446744073709551618""
""18446744073709551619"" ""18446744073709551620""])
>>> a.bigint_to_uint_arrays()
[array([1 1 1 1 1]), array([0 1 2 3 4])]
""""""
ret_list = json.loads(generic_msg(cmd=""bigint_to_uint_list"", args={""array"": self}))
return list(reversed([create_pdarray(a) for a in ret_list]))
",[],0,[],/pdarrayclass.py_bigint_to_uint_arrays
694,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_reshape,"def reshape(self, *shape, order=""row_major""):
""""""
Gives a new shape to an array without changing its data.
Parameters
----------
shape : int, tuple of ints, or pdarray
The new shape should be compatible with the original shape.
order : str {'row_major' | 'C' | 'column_major' | 'F'}
Read the elements of the pdarray in this index order
By default, read the elements in row_major or C-like order where the last index
changes the fastest
If 'column_major' or 'F', read the elements in column_major or Fortran-like order where the
first index changes the fastest
Returns
-------
ArrayView
An arrayview object with the data from the array but with the new shape
""""""
from arkouda.array_view import ArrayView
if len(shape) == 1:
shape = shape[0]
elif not isinstance(shape, pdarray):
shape = [i for i in shape]
return ArrayView(base=self, shape=shape, order=order)
",[],0,[],/pdarrayclass.py_reshape
695,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_to_ndarray,"def to_ndarray(self) -> np.ndarray:
""""""
Convert the array to a np.ndarray, transferring array data from the
Arkouda server to client-side Python. Note: if the pdarray size exceeds
client.maxTransferBytes, a RuntimeError is raised.
Returns
-------
np.ndarray
A numpy ndarray with the same attributes and data as the pdarray
Raises
------
RuntimeError
Raised if there is a server-side error thrown, if the pdarray size
exceeds the built-in client.maxTransferBytes size limit, or if the bytes
received does not match expected number of bytes
Notes
-----
The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
otherwise a ``RuntimeError`` will be raised. This is to protect the user
from overflowing the memory of the system on which the Python client
is running, under the assumption that the server is running on a
distributed system with much more memory than the client. The user
may override this limit by setting client.maxTransferBytes to a larger
value, but proceed with caution.
See Also
--------
array()
to_list()
Examples
--------
>>> a = ak.arange(0, 5, 1)
>>> a.to_ndarray()
array([0, 1, 2, 3, 4])
>>> type(a.to_ndarray())
numpy.ndarray
""""""
from arkouda.client import maxTransferBytes
dt = dtype(self.dtype)
if dt == bigint:
arrs = [n.to_ndarray().astype(""O"") for n in self.bigint_to_uint_arrays()]
return builtins.sum(n << (64 * (len(arrs) - i - 1)) for i, n in enumerate(arrs))
arraybytes = self.size * self.dtype.itemsize
if arraybytes > maxTransferBytes:
raise RuntimeError(
""Array exceeds allowed size for transfer. Increase client.maxTransferBytes to allow""
)
data = cast(
memoryview,
generic_msg(cmd=f""tondarray{self.ndim}D"", args={""array"": self}, recv_binary=True),
)
if len(data) != self.size * self.dtype.itemsize:
raise RuntimeError(
f""Expected {self.size * self.dtype.itemsize} bytes but received {len(data)}""
)
if get_server_byteorder() == ""big"":
dt = dt.newbyteorder("">"")
else:
dt = dt.newbyteorder(""<"")
if data.readonly:
x = np.frombuffer(data, dt).copy()
else:
x = np.frombuffer(data, dt)
if self.ndim == 1:
return x
else:
return x.reshape(self.shape)
","['ndarray', 'ndarray', 'ndarray', 'frombuffer', 'frombuffer']",5,"['frombuffer(data, dt).copy()', 'frombuffer(data, dt)']",/pdarrayclass.py_to_ndarray
696,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_to_list,"def to_list(self) -> List:
""""""
Convert the array to a list, transferring array data from the
Arkouda server to client-side Python. Note: if the pdarray size exceeds
client.maxTransferBytes, a RuntimeError is raised.
Returns
-------
list
A list with the same data as the pdarray
Raises
------
RuntimeError
Raised if there is a server-side error thrown, if the pdarray size
exceeds the built-in client.maxTransferBytes size limit, or if the bytes
received does not match expected number of bytes
Notes
-----
The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
otherwise a ``RuntimeError`` will be raised. This is to protect the user
from overflowing the memory of the system on which the Python client
is running, under the assumption that the server is running on a
distributed system with much more memory than the client. The user
may override this limit by setting client.maxTransferBytes to a larger
value, but proceed with caution.
See Also
--------
to_ndarray()
Examples
--------
>>> a = ak.arange(0, 5, 1)
>>> a.to_list()
[0, 1, 2, 3, 4]
>>> type(a.to_list())
list
""""""
return self.to_ndarray().tolist()
",[],0,[],/pdarrayclass.py_to_list
697,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_to_cuda,"def to_cuda(self):
""""""
Convert the array to a Numba DeviceND array, transferring array data from the
arkouda server to Python via ndarray. If the array exceeds a builtin size limit,
a RuntimeError is raised.
Returns
-------
numba.DeviceNDArray
A Numba ndarray with the same attributes and data as the pdarray
Raises
------
ImportError
Raised if CUDA is not available
ModuleNotFoundError
Raised if Numba is either not installed or not enabled
RuntimeError
Raised if there is a server-side error thrown in the course of retrieving
the pdarray.
Notes
-----
The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
otherwise a ``RuntimeError`` will be raised. This is to protect the user
from overflowing the memory of the system on which the Python client
is running, under the assumption that the server is running on a
distributed system with much more memory than the client. The user
may override this limit by setting client.maxTransferBytes to a larger
value, but proceed with caution.
See Also
--------
array
Examples
--------
>>> a = ak.arange(0, 5, 1)
>>> a.to_cuda()
array([0, 1, 2, 3, 4])
>>> type(a.to_cuda())
numpy.devicendarray
""""""
try:
from numba import cuda  # type: ignore
if not (cuda.is_available()):
raise ImportError(
""CUDA is not available. Check for the CUDA toolkit and ensure a GPU is installed.""
)
except (ModuleNotFoundError, ImportError):
raise ModuleNotFoundError(
""Numba is not enabled or installed and is required for GPU support.""
)
return cuda.to_device(self.to_ndarray())
",[],0,[],/pdarrayclass.py_to_cuda
698,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_to_parquet,"def to_parquet(
self,
prefix_path: str,
dataset: str = ""array"",
mode: str = ""truncate"",
compression: Optional[str] = None,
",[],0,[],/pdarrayclass.py_to_parquet
699,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_to_hdf,"def to_hdf(
self,
prefix_path: str,
dataset: str = ""array"",
mode: str = ""truncate"",
file_type: str = ""distribute"",
",[],0,[],/pdarrayclass.py_to_hdf
700,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_update_hdf,"def update_hdf(self, prefix_path: str, dataset: str = ""array"", repack: bool = True):
""""""
Overwrite the dataset with the name provided with this pdarray. If
the dataset does not exist it is added
Parameters
-----------
prefix_path : str
Directory and filename prefix that all output files share
dataset : str
Name of the dataset to create in files
repack: bool
Default: True
HDF5 does not release memory on delete. When True, the inaccessible
data (that was overwritten) is removed. When False, the data remains, but is
inaccessible. Setting to false will yield better performance, but will cause
file sizes to expand.
Returns
--------
str - success message if successful
Raises
-------
RuntimeError
Raised if a server-side error is thrown saving the pdarray
Notes
------
- If file does not contain File_Format attribute to indicate how it was saved,
the file name is checked for _LOCALE#### to determine if it is distributed.
- If the dataset provided does not exist, it will be added
""""""
from arkouda.io import (
_file_type_to_int,
_get_hdf_filetype,
_mode_str_to_int,
_repack_hdf,
)
file_type = _get_hdf_filetype(prefix_path + ""*"")
generic_msg(
cmd=""tohdf"",
args={
""values"": self,
""dset"": dataset,
""write_mode"": _mode_str_to_int(""append""),
""filename"": prefix_path,
""dtype"": self.dtype,
""objType"": ""pdarray"",
""file_format"": _file_type_to_int(file_type),
""overwrite"": True,
},
)
if repack:
_repack_hdf(prefix_path)
",[],0,[],/pdarrayclass.py_update_hdf
701,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_to_csv,"def to_csv(
self,
prefix_path: str,
dataset: str = ""array"",
col_delim: str = "","",
overwrite: bool = False,
",[],0,[],/pdarrayclass.py_to_csv
702,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_save,"def save(
self,
prefix_path: str,
dataset: str = ""array"",
mode: str = ""truncate"",
compression: Optional[str] = None,
file_format: str = ""HDF5"",
file_type: str = ""distribute"",
",[],0,[],/pdarrayclass.py_save
703,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_register,"def register(self, user_defined_name: str) -> pdarray:
""""""
Register this pdarray with a user defined name in the arkouda server
so it can be attached to later using pdarray.attach()
This is an in-place operation, registering a pdarray more than once will
update the name in the registry and remove the previously registered name.
A name can only be registered to one pdarray at a time.
Parameters
----------
user_defined_name : str
user defined name array is to be registered under
Returns
-------
pdarray
The same pdarray which is now registered with the arkouda server and has an updated name.
This is an in-place modification, the original is returned to support a
fluid programming style.
Please note you cannot register two different pdarrays with the same name.
Raises
------
TypeError
Raised if user_defined_name is not a str
RegistrationError
If the server was unable to register the pdarray with the user_defined_name
If the user is attempting to register more than one pdarray with the same name,
the former should be unregistered first to free up the registration name.
See also
--------
attach, unregister, is_registered, list_registry, unregister_pdarray_by_name
Notes
-----
Registered names/pdarrays in the server are immune to deletion
until they are unregistered.
Examples
--------
>>> a = zeros(100)
>>> a.register(""my_zeros"")
>>> # potentially disconnect from server and reconnect to server
>>> b = ak.pdarray.attach(""my_zeros"")
>>> # ...other work...
>>> b.unregister()
""""""
if self.registered_name is not None and self.is_registered():
raise RegistrationError(f""This object is already registered as {self.registered_name}"")
generic_msg(
cmd=""register"",
args={
""name"": user_defined_name,
""objType"": self.objType,
""array"": self.name,
},
)
self.registered_name = user_defined_name
return self
",[],0,[],/pdarrayclass.py_register
704,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_unregister,"def unregister(self) -> None:
""""""
Unregister a pdarray in the arkouda server which was previously
registered using register() and/or attahced to using attach()
Parameters
----------
Returns
-------
None
Raises
------
RuntimeError
Raised if the server could not find the internal name/symbol to remove
See also
--------
register, unregister, is_registered, unregister_pdarray_by_name, list_registry
Notes
-----
Registered names/pdarrays in the server are immune to deletion until
they are unregistered.
Examples
--------
>>> a = zeros(100)
>>> a.register(""my_zeros"")
>>> # potentially disconnect from server and reconnect to server
>>> b = ak.pdarray.attach(""my_zeros"")
>>> # ...other work...
>>> b.unregister()
""""""
from arkouda.util import unregister
if self.registered_name is None:
raise RegistrationError(""This object is not registered"")
unregister(self.registered_name)
self.registered_name = None
",[],0,[],/pdarrayclass.py_unregister
705,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_attach,"def attach(user_defined_name: str) -> pdarray:
""""""
class method to return a pdarray attached to the registered name in the arkouda
server which was registered using register()
Parameters
----------
user_defined_name : str
user defined name which array was registered under
Returns
-------
pdarray
pdarray which is bound to the corresponding server side component which was registered
with user_defined_name
Raises
------
TypeError
Raised if user_defined_name is not a str
See also
--------
register, unregister, is_registered, unregister_pdarray_by_name, list_registry
Notes
-----
Registered names/pdarrays in the server are immune to deletion
until they are unregistered.
Examples
--------
>>> a = zeros(100)
>>> a.register(""my_zeros"")
>>> # potentially disconnect from server and reconnect to server
>>> b = ak.pdarray.attach(""my_zeros"")
>>> # ...other work...
>>> b.unregister()
""""""
import warnings
from arkouda.util import attach
warnings.warn(
""ak.pdarray.attach() is deprecated. Please use ak.attach() instead."",
DeprecationWarning,
)
return attach(user_defined_name)
",[],0,[],/pdarrayclass.py_attach
706,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py__float_to_uint,"def _float_to_uint(self):
return generic_msg(cmd=""transmuteFloat"", args={""name"": self})
",[],0,[],/pdarrayclass.py__float_to_uint
707,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py__get_grouping_keys,"def _get_grouping_keys(self) -> List[pdarray]:
""""""
Private method for generating grouping keys used by GroupBy.
API: this method must be defined by all groupable arrays, and it
must return a list of arrays that can be (co)argsorted.
""""""
if self.dtype == akbool:
from arkouda.numeric import cast as akcast
return [akcast(self, akint64)]
elif self.dtype in (akint64, akuint64):
return [self]
elif self.dtype == akfloat64:
return [create_pdarray(self._float_to_uint())]
elif self.dtype == bigint:
return self.bigint_to_uint_arrays()
else:
raise TypeError(""Grouping is only supported on numeric data (integral types) and bools."")
",[],0,[],/pdarrayclass.py__get_grouping_keys
708,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_create_pdarray,"def create_pdarray(repMsg: str, max_bits=None) -> pdarray:
""""""
Return a pdarray instance pointing to an array created by the arkouda server.
The user should not call this function directly.
Parameters
----------
repMsg : str
space-delimited string containing the pdarray name, datatype, size
dimension, shape,and itemsize
Returns
-------
pdarray
A pdarray with the same attributes and data as the pdarray
Raises
-----
ValueError
If there's an error in parsing the repMsg parameter into the six
values needed to create the pdarray instance
RuntimeError
Raised if a server-side error is thrown in the process of creating
the pdarray instance
""""""
try:
fields = repMsg.split()
name = fields[1]
mydtype = fields[2]
size = int(fields[3])
ndim = int(fields[4])
if fields[5] == ""[]"":
shape = []
else:
trailing_comma_offset = -2 if fields[5][len(fields[5]) - 2] == "","" else -1
shape = [int(el) for el in fields[5][1:trailing_comma_offset].split("","")]
itemsize = int(fields[6])
except Exception as e:
raise ValueError(e)
logger.debug(
f""created Chapel array with name: {name} dtype: {mydtype} size: {size} ndim: {ndim} ""
+ f""shape: {shape} itemsize: {itemsize}""
)
return pdarray(name, dtype(mydtype), size, ndim, shape, itemsize, max_bits)
",[],0,[],/pdarrayclass.py_create_pdarray
709,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_clear,"def clear() -> None:
""""""
Send a clear message to clear all unregistered data from the server symbol table
Returns
-------
None
Raises
------
RuntimeError
Raised if there is a server-side error in executing clear request
""""""
generic_msg(cmd=""clear"")
",[],0,[],/pdarrayclass.py_clear
710,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_any,"def any(pda: pdarray) -> np.bool_:
""""""
Return True iff any element of the array evaluates to True.
Parameters
----------
pda : pdarray
The pdarray instance to be evaluated
Returns
-------
bool
Indicates if 1..n pdarray elements evaluate to True
Raises
------
TypeError
Raised if pda is not a pdarray instance
RuntimeError
Raised if there's a server-side error thrown
""""""
repMsg = generic_msg(cmd=f""reduction{pda.ndim}D"", args={""op"": ""any"", ""array"": pda})
return parse_single_value(cast(str, repMsg))
",['bool_'],1,[],/pdarrayclass.py_any
711,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_all,"def all(pda: pdarray) -> np.bool_:
""""""
Return True iff all elements of the array evaluate to True.
Parameters
----------
pda : pdarray
The pdarray instance to be evaluated
Returns
-------
bool
Indicates if all pdarray elements evaluate to True
Raises
------
TypeError
Raised if pda is not a pdarray instance
RuntimeError
Raised if there's a server-side error thrown
""""""
repMsg = generic_msg(cmd=f""reduction{pda.ndim}D"", args={""op"": ""all"", ""array"": pda})
return parse_single_value(cast(str, repMsg))
",['bool_'],1,[],/pdarrayclass.py_all
712,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_is_sorted,"def is_sorted(pda: pdarray) -> np.bool_:
""""""
Return True iff the array is monotonically non-decreasing.
Parameters
----------
pda : pdarray
The pdarray instance to be evaluated
Returns
-------
bool
Indicates if the array is monotonically non-decreasing
Raises
------
TypeError
Raised if pda is not a pdarray instance
RuntimeError
Raised if there's a server-side error thrown
""""""
repMsg = generic_msg(cmd=f""reduction{pda.ndim}D"", args={""op"": ""is_sorted"", ""array"": pda})
return parse_single_value(cast(str, repMsg))
",['bool_'],1,[],/pdarrayclass.py_is_sorted
713,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_sum,"def sum(pda: pdarray) -> np.float64:
""""""
Return the sum of all elements in the array.
Parameters
----------
pda : pdarray
Values for which to calculate the sum
Returns
-------
np.float64
The sum of all elements in the array
Raises
------
TypeError
Raised if pda is not a pdarray instance
RuntimeError
Raised if there's a server-side error thrown
""""""
repMsg = generic_msg(cmd=f""reduction{pda.ndim}D"", args={""op"": ""sum"", ""array"": pda})
return parse_single_value(cast(str, repMsg))
","['float64', 'float64']",2,[],/pdarrayclass.py_sum
714,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_prod,"def prod(pda: pdarray) -> np.float64:
""""""
Return the product of all elements in the array. Return value is
always a np.float64 or np.int64
Parameters
----------
pda : pdarray
Values for which to calculate the product
Returns
-------
numpy_scalars
The product calculated from the pda
Raises
------
TypeError
Raised if pda is not a pdarray instance
RuntimeError
Raised if there's a server-side error thrown
""""""
repMsg = generic_msg(cmd=f""reduction{pda.ndim}D"", args={""op"": ""prod"", ""array"": pda})
return parse_single_value(cast(str, repMsg))
","['float64', 'float64', 'int64']",3,[],/pdarrayclass.py_prod
715,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_min,"def min(pda: pdarray) -> numpy_scalars:
""""""
Return the minimum value of the array.
Parameters
----------
pda : pdarray
Values for which to calculate the min
Returns
-------
numpy_scalars
The min calculated from the pda
Raises
------
TypeError
Raised if pda is not a pdarray instance
RuntimeError
Raised if there's a server-side error thrown
""""""
repMsg = generic_msg(cmd=f""reduction{pda.ndim}D"", args={""op"": ""min"", ""array"": pda})
return parse_single_value(cast(str, repMsg))
",[],0,[],/pdarrayclass.py_min
716,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_max,"def max(pda: pdarray) -> numpy_scalars:
""""""
Return the maximum value of the array.
Parameters
----------
pda : pdarray
Values for which to calculate the max
Returns
-------
numpy_scalars:
The max calculated from the pda
Raises
------
TypeError
Raised if pda is not a pdarray instance
RuntimeError
Raised if there's a server-side error thrown
""""""
repMsg = generic_msg(cmd=f""reduction{pda.ndim}D"", args={""op"": ""max"", ""array"": pda})
return parse_single_value(cast(str, repMsg))
",[],0,[],/pdarrayclass.py_max
717,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_argmin,"def argmin(pda: pdarray) -> Union[np.int64, np.uint64]:
""""""
Return the index of the first occurrence of the array min value.
Parameters
----------
pda : pdarray
Values for which to calculate the argmin
Returns
-------
Union[np.int64, np.uint64]
The index of the argmin calculated from the pda
Raises
------
TypeError
Raised if pda is not a pdarray instance
RuntimeError
Raised if there's a server-side error thrown
""""""
repMsg = generic_msg(cmd=f""reduction{pda.ndim}D"", args={""op"": ""argmin"", ""array"": pda})
return parse_single_value(cast(str, repMsg))
","['int64', 'uint64', 'int64', 'uint64']",4,[],/pdarrayclass.py_argmin
718,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_argmax,"def argmax(pda: pdarray) -> Union[np.int64, np.uint64]:
""""""
Return the index of the first occurrence of the array max value.
Parameters
----------
pda : pdarray
Values for which to calculate the argmax
Returns
-------
Union[np.int64, np.uint64]
The index of the argmax calculated from the pda
Raises
------
TypeError
Raised if pda is not a pdarray instance
RuntimeError
Raised if there's a server-side error thrown
""""""
repMsg = generic_msg(cmd=f""reduction{pda.ndim}D"", args={""op"": ""argmax"", ""array"": pda})
return parse_single_value(cast(str, repMsg))
","['int64', 'uint64', 'int64', 'uint64']",4,[],/pdarrayclass.py_argmax
719,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_mean,"def mean(pda: pdarray) -> np.float64:
""""""
Return the mean of the array.
Parameters
----------
pda : pdarray
Values for which to calculate the mean
Returns
-------
np.float64
The mean calculated from the pda sum and size
Raises
------
TypeError
Raised if pda is not a pdarray instance
RuntimeError
Raised if there's a server-side error thrown
""""""
return parse_single_value(generic_msg(cmd=""mean"", args={""x"": pda}))
","['float64', 'float64']",2,[],/pdarrayclass.py_mean
720,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_var,"def var(pda: pdarray, ddof: int_scalars = 0) -> np.float64:
""""""
Return the variance of values in the array.
Parameters
----------
pda : pdarray
Values for which to calculate the variance
ddof : int_scalars
""Delta Degrees of Freedom"" used in calculating var
Returns
-------
np.float64
The scalar variance of the array
Raises
------
TypeError
Raised if pda is not a pdarray instance
ValueError
Raised if the ddof >= pdarray size
RuntimeError
Raised if there's a server-side error thrown
See Also
--------
mean, std
Notes
-----
The variance is the average of the squared deviations from the mean,
i.e.,  ``var = mean((x - x.mean())**2)``.
The mean is normally calculated as ``x.sum() / N``, where ``N = len(x)``.
If, however, `ddof` is specified, the divisor ``N - ddof`` is used
instead.  In standard statistical practice, ``ddof=1`` provides an
unbiased estimator of the variance of a hypothetical infinite population.
``ddof=0`` provides a maximum likelihood estimate of the variance for
normally distributed variables.
""""""
if ddof >= pda.size:
raise ValueError(""var: ddof must be less than number of values"")
return parse_single_value(generic_msg(cmd=""var"", args={""x"": pda, ""ddof"": ddof}))
","['float64', 'float64']",2,[],/pdarrayclass.py_var
721,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_std,"def std(pda: pdarray, ddof: int_scalars = 0) -> np.float64:
""""""
Return the standard deviation of values in the array. The standard
deviation is implemented as the square root of the variance.
Parameters
----------
pda : pdarray
values for which to calculate the standard deviation
ddof : int_scalars
""Delta Degrees of Freedom"" used in calculating std
Returns
-------
np.float64
The scalar standard deviation of the array
Raises
------
TypeError
Raised if pda is not a pdarray instance or ddof is not an integer
ValueError
Raised if ddof is an integer < 0
RuntimeError
Raised if there's a server-side error thrown
See Also
--------
mean, var
Notes
-----
The standard deviation is the square root of the average of the squared
deviations from the mean, i.e., ``std = sqrt(mean((x - x.mean())**2))``.
The average squared deviation is normally calculated as
``x.sum() / N``, where ``N = len(x)``.  If, however, `ddof` is specified,
the divisor ``N - ddof`` is used instead. In standard statistical
practice, ``ddof=1`` provides an unbiased estimator of the variance
of the infinite population. ``ddof=0`` provides a maximum likelihood
estimate of the variance for normally distributed variables. The
standard deviation computed in this function is the square root of
the estimated variance, so even with ``ddof=1``, it will not be an
unbiased estimate of the standard deviation per se.
""""""
if ddof < 0:
raise ValueError(""ddof must be an integer 0 or greater"")
return parse_single_value(generic_msg(cmd=""std"", args={""x"": pda, ""ddof"": ddof}))
","['float64', 'float64']",2,[],/pdarrayclass.py_std
722,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_cov,"def cov(x: pdarray, y: pdarray) -> np.float64:
""""""
Return the covariance of x and y
Parameters
----------
x : pdarray
One of the pdarrays used to calculate covariance
y : pdarray
One of the pdarrays used to calculate covariance
Returns
-------
np.float64
The scalar covariance of the two pdarrays
Raises
------
TypeError
Raised if x or y is not a pdarray instance
RuntimeError
Raised if there's a server-side error thrown
See Also
--------
mean, var
Notes
-----
The covariance is calculated by
``cov = ((x - x.mean()) * (y - y.mean())).sum() / (x.size - 1)``.
""""""
return parse_single_value(generic_msg(cmd=""cov"", args={""x"": x, ""y"": y}))
","['float64', 'float64']",2,[],/pdarrayclass.py_cov
723,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_corr,"def corr(x: pdarray, y: pdarray) -> np.float64:
""""""
Return the correlation between x and y
Parameters
----------
x : pdarray
One of the pdarrays used to calculate correlation
y : pdarray
One of the pdarrays used to calculate correlation
Returns
-------
np.float64
The scalar correlation of the two pdarrays
Raises
------
TypeError
Raised if x or y is not a pdarray instance
RuntimeError
Raised if there's a server-side error thrown
See Also
--------
std, cov
Notes
-----
The correlation is calculated by
cov(x, y) / (x.std(ddof=1) * y.std(ddof=1))
""""""
return parse_single_value(generic_msg(cmd=""corr"", args={""x"": x, ""y"": y}))
","['float64', 'float64']",2,[],/pdarrayclass.py_corr
724,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_divmod,"def divmod(
x: Union[numeric_scalars, pdarray],
y: Union[numeric_scalars, pdarray],
where: Union[bool, pdarray] = True,
",[],0,[],/pdarrayclass.py_divmod
725,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_mink,"def mink(pda: pdarray, k: int_scalars) -> pdarray:
""""""
Find the `k` minimum values of an array.
Returns the smallest `k` values of an array, sorted
Parameters
----------
pda : pdarray
Input array.
k : int_scalars
The desired count of minimum values to be returned by the output.
Returns
-------
pdarray
The minimum `k` values from pda, sorted
Raises
------
TypeError
Raised if pda is not a pdarray
ValueError
Raised if the pda is empty or k < 1
Notes
-----
This call is equivalent in value to:
a[ak.argsort(a)[:k]]
and generally outperforms this operation.
This reduction will see a significant drop in performance as `k` grows
beyond a certain value. This value is system dependent, but generally
about a `k` of 5 million is where performance degredation has been observed.
Examples
--------
>>> A = ak.array([10,5,1,3,7,2,9,0])
>>> ak.mink(A, 3)
array([0, 1, 2])
>>> ak.mink(A, 4)
array([0, 1, 2, 3])
""""""
if k < 1:
raise ValueError(""k must be 1 or greater"")
if pda.size == 0:
raise ValueError(""must be a non-empty pdarray of type int or float"")
repMsg = generic_msg(cmd=""mink"", args={""array"": pda, ""k"": k, ""rtnInd"": False})
return create_pdarray(cast(str, repMsg))
",[],0,[],/pdarrayclass.py_mink
726,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_maxk,"def maxk(pda: pdarray, k: int_scalars) -> pdarray:
""""""
Find the `k` maximum values of an array.
Returns the largest `k` values of an array, sorted
Parameters
----------
pda : pdarray
Input array.
k : int_scalars
The desired count of maximum values to be returned by the output.
Returns
-------
pdarray, int
The maximum `k` values from pda, sorted
Raises
------
TypeError
Raised if pda is not a pdarray or k is not an integer
ValueError
Raised if the pda is empty or k < 1
Notes
-----
This call is equivalent in value to:
a[ak.argsort(a)[k:]]
and generally outperforms this operation.
This reduction will see a significant drop in performance as `k` grows
beyond a certain value. This value is system dependent, but generally
about a `k` of 5 million is where performance degredation has been observed.
Examples
--------
>>> A = ak.array([10,5,1,3,7,2,9,0])
>>> ak.maxk(A, 3)
array([7, 9, 10])
>>> ak.maxk(A, 4)
array([5, 7, 9, 10])
""""""
if k < 1:
raise ValueError(""k must be 1 or greater"")
if pda.size == 0:
raise ValueError(""must be a non-empty pdarray of type int or float"")
repMsg = generic_msg(cmd=""maxk"", args={""array"": pda, ""k"": k, ""rtnInd"": False})
return create_pdarray(repMsg)
",[],0,[],/pdarrayclass.py_maxk
727,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_argmink,"def argmink(pda: pdarray, k: int_scalars) -> pdarray:
""""""
Finds the indices corresponding to the `k` minimum values of an array.
Parameters
----------
pda : pdarray
Input array.
k : int_scalars
The desired count of indices corresponding to minimum array values
Returns
-------
pdarray, int
The indices of the minimum `k` values from the pda, sorted
Raises
------
TypeError
Raised if pda is not a pdarray or k is not an integer
ValueError
Raised if the pda is empty or k < 1
Notes
-----
This call is equivalent in value to:
ak.argsort(a)[:k]
and generally outperforms this operation.
This reduction will see a significant drop in performance as `k` grows
beyond a certain value. This value is system dependent, but generally
about a `k` of 5 million is where performance degradation has been observed.
Examples
--------
>>> A = ak.array([10,5,1,3,7,2,9,0])
>>> ak.argmink(A, 3)
array([7, 2, 5])
>>> ak.argmink(A, 4)
array([7, 2, 5, 3])
""""""
if k < 1:
raise ValueError(""k must be 1 or greater"")
if pda.size == 0:
raise ValueError(""must be a non-empty pdarray of type int or float"")
repMsg = generic_msg(cmd=""mink"", args={""array"": pda, ""k"": k, ""rtnInd"": True})
return create_pdarray(repMsg)
",[],0,[],/pdarrayclass.py_argmink
728,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_argmaxk,"def argmaxk(pda: pdarray, k: int_scalars) -> pdarray:
""""""
Find the indices corresponding to the `k` maximum values of an array.
Returns the largest `k` values of an array, sorted
Parameters
----------
pda : pdarray
Input array.
k : int_scalars
The desired count of indices corresponding to maxmum array values
Returns
-------
pdarray, int
The indices of the maximum `k` values from the pda, sorted
Raises
------
TypeError
Raised if pda is not a pdarray or k is not an integer
ValueError
Raised if the pda is empty or k < 1
Notes
-----
This call is equivalent in value to:
ak.argsort(a)[k:]
and generally outperforms this operation.
This reduction will see a significant drop in performance as `k` grows
beyond a certain value. This value is system dependent, but generally
about a `k` of 5 million is where performance degradation has been observed.
Examples
--------
>>> A = ak.array([10,5,1,3,7,2,9,0])
>>> ak.argmaxk(A, 3)
array([4, 6, 0])
>>> ak.argmaxk(A, 4)
array([1, 4, 6, 0])
""""""
if k < 1:
raise ValueError(""k must be 1 or greater"")
if pda.size == 0:
raise ValueError(""must be a non-empty pdarray of type int or float"")
repMsg = generic_msg(cmd=""maxk"", args={""array"": pda, ""k"": k, ""rtnInd"": True})
return create_pdarray(repMsg)
",[],0,[],/pdarrayclass.py_argmaxk
729,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_popcount,"def popcount(pda: pdarray) -> pdarray:
""""""
Find the population (number of bits set) for each integer in an array.
Parameters
----------
pda : pdarray, int64, uint64, bigint
Input array (must be integral).
Returns
-------
population : pdarray
The number of bits set (1) in each element
Raises
------
TypeError
If input array is not int64, uint64, or bigint
Examples
--------
>>> A = ak.arange(10)
>>> ak.popcount(A)
array([0, 1, 1, 2, 1, 2, 2, 3, 1, 2])
""""""
if pda.dtype not in [akint64, akuint64, bigint]:
raise TypeError(""BitOps only supported on int64, uint64, and bigint arrays"")
if pda.dtype == bigint:
from builtins import sum
return sum(popcount(a) for a in pda.bigint_to_uint_arrays())
else:
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""popcount"",
""array"": pda,
},
)
return create_pdarray(repMsg)
",[],0,[],/pdarrayclass.py_popcount
730,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_clz,"def clz(pda: pdarray) -> pdarray:
""""""
Count leading zeros for each integer in an array.
Parameters
----------
pda : pdarray, int64, uint64, bigint
Input array (must be integral).
Returns
-------
lz : pdarray
The number of leading zeros of each element.
Raises
------
TypeError
If input array is not int64, uint64, or bigint
Examples
--------
>>> A = ak.arange(10)
>>> ak.clz(A)
array([64, 63, 62, 62, 61, 61, 61, 61, 60, 60])
""""""
if pda.dtype not in [akint64, akuint64, bigint]:
raise TypeError(""BitOps only supported on int64, uint64, and bigint arrays"")
if pda.dtype == bigint:
if pda.max_bits == -1:
raise ValueError(""max_bits must be set to count leading zeros"")
from arkouda.numeric import where
from arkouda.pdarraycreation import zeros
uint_arrs = pda.bigint_to_uint_arrays()
mod_max_bits, div_max_bits = pda.max_bits % 64, ceil(pda.max_bits / 64)
sub_off = 0 if mod_max_bits == 0 else 64 - mod_max_bits
add_on = 64 * (div_max_bits - len(uint_arrs))
lz = zeros(pda.size, dtype=akuint64)
previously_non_zero = zeros(pda.size, dtype=bool)
for a in uint_arrs:
lz += where(previously_non_zero, 0, clz(a))
previously_non_zero |= a != 0
if all(previously_non_zero):
break
lz += add_on - sub_off
return lz
else:
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""clz"",
""array"": pda,
},
)
return create_pdarray(repMsg)
",[],0,[],/pdarrayclass.py_clz
731,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_ctz,"def ctz(pda: pdarray) -> pdarray:
""""""
Count trailing zeros for each integer in an array.
Parameters
----------
pda : pdarray, int64, uint64, bigint
Input array (must be integral).
Returns
-------
lz : pdarray
The number of trailing zeros of each element.
Notes
-----
ctz(0) is defined to be zero.
Raises
------
TypeError
If input array is not int64, uint64, or bigint
Examples
--------
>>> A = ak.arange(10)
>>> ak.ctz(A)
array([0, 0, 1, 0, 2, 0, 1, 0, 3, 0])
""""""
if pda.dtype not in [akint64, akuint64, bigint]:
raise TypeError(""BitOps only supported on int64, uint64, and bigint arrays"")
if pda.dtype == bigint:
from arkouda.numeric import where
from arkouda.pdarraycreation import zeros
reversed_uint_arrs = pda.bigint_to_uint_arrays()[::-1]
tz = zeros(pda.size, dtype=akuint64)
previously_non_zero = zeros(pda.size, dtype=bool)
for a in reversed_uint_arrs:
a_is_zero = a == 0
num_zeros = where(a_is_zero, 64, ctz(a))
tz += where(previously_non_zero, 0, num_zeros)
previously_non_zero |= ~a_is_zero
if all(previously_non_zero):
break
if not all(previously_non_zero):
tz[~previously_non_zero] = 0
return tz
else:
repMsg = generic_msg(
cmd=f""efunc{pda.ndim}D"",
args={
""func"": ""ctz"",
""array"": pda,
},
)
return create_pdarray(repMsg)
",[],0,[],/pdarrayclass.py_ctz
732,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_rotl,"def rotl(x, rot) -> pdarray:
""""""
Rotate bits of <x> to the left by <rot>.
Parameters
----------
x : pdarray(int64/uint64) or integer
Value(s) to rotate left.
rot : pdarray(int64/uint64) or integer
Amount(s) to rotate by.
Returns
-------
rotated : pdarray(int64/uint64)
The rotated elements of x.
Raises
------
TypeError
If input array is not int64 or uint64
Examples
--------
>>> A = ak.arange(10)
>>> ak.rotl(A, A)
array([0, 2, 8, 24, 64, 160, 384, 896, 2048, 4608])
""""""
if isinstance(x, pdarray) and x.dtype in [akint64, akuint64, bigint]:
if (isinstance(rot, pdarray) and rot.dtype in [akint64, akuint64]) or isSupportedInt(rot):
return x._binop(rot, ""<<<"")
else:
raise TypeError(""Rotations only supported on integers"")
elif isSupportedInt(x) and isinstance(rot, pdarray) and rot.dtype in [akint64, akuint64]:
return rot._r_binop(x, ""<<<"")
else:
raise TypeError(""Rotations only supported on integers"")
",[],0,[],/pdarrayclass.py_rotl
733,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_rotr,"def rotr(x, rot) -> pdarray:
""""""
Rotate bits of <x> to the left by <rot>.
Parameters
----------
x : pdarray(int64/uint64) or integer
Value(s) to rotate left.
rot : pdarray(int64/uint64) or integer
Amount(s) to rotate by.
Returns
-------
rotated : pdarray(int64/uint64)
The rotated elements of x.
Raises
------
TypeError
If input array is not int64 or uint64
Examples
--------
>>> A = ak.arange(10)
>>> ak.rotr(1024 * A, A)
array([0, 512, 512, 384, 256, 160, 96, 56, 32, 18])
""""""
if isinstance(x, pdarray) and x.dtype in [akint64, akuint64, bigint]:
if (isinstance(rot, pdarray) and rot.dtype in [akint64, akuint64]) or isSupportedInt(rot):
return x._binop(rot, "">>>"")
else:
raise TypeError(""Rotations only supported on integers"")
elif isSupportedInt(x) and isinstance(rot, pdarray) and rot.dtype in [akint64, akuint64]:
return rot._r_binop(x, "">>>"")
else:
raise TypeError(""Rotations only supported on integers"")
",[],0,[],/pdarrayclass.py_rotr
734,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_power,"def power(pda: pdarray, pwr: Union[int, float, pdarray], where: Union[bool, pdarray] = True) -> pdarray:
""""""
Raises an array to a power. If where is given, the operation will only take place in the positions
where the where condition is True.
Note:
Our implementation of the where argument deviates from numpy. The difference in behavior occurs
at positions where the where argument contains a False. In numpy, these position will have
uninitialized memory (which can contain anything and will vary between runs). We have chosen to
instead return the value of the original array in these positions.
Parameters
----------
pda : pdarray
A pdarray of values that will be raised to a power (pwr)
pwr : integer, float, or pdarray
The power(s) that pda is raised to
where : Boolean or pdarray
This condition is broadcast over the input. At locations where the condition is True, the
corresponding value will be raised to the respective power. Elsewhere, it will retain its
original value. Default set to True.
Returns
-------
pdarray
Returns a pdarray of values raised to a power, under the boolean where condition.
Examples
--------
>>> a = ak.arange(5)
>>> ak.power(a, 3)
array([0, 1, 8, 27, 64])
>>> ak.power(a), 3, a % 2 == 0)
array([0, 1, 8, 3, 64])
""""""
from arkouda.numeric import cast as akcast
from arkouda.numeric import where as akwhere
if where is True:
return pda**pwr
elif where is False:
return pda
else:
exp = pda**pwr
return akwhere(where, exp, akcast(pda, exp.dtype))
",[],0,[],/pdarrayclass.py_power
735,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_sqrt,"def sqrt(pda: pdarray, where: Union[bool, pdarray] = True) -> pdarray:
""""""
Takes the square root of array. If where is given, the operation will only take place in
the positions where the where condition is True.
Parameters
----------
pda : pdarray
A pdarray of values that will be square rooted
where : Boolean or pdarray
This condition is broadcast over the input. At locations where the condition is True, the
corresponding value will be square rooted. Elsewhere, it will retain its original value.
Default set to True.
Returns
-------
pdarray
Returns a pdarray of square rooted values, under the boolean where condition.
Examples:
>>> a = ak.arange(5)
>>> ak.sqrt(a)
array([0 1 1.4142135623730951 1.7320508075688772 2])
>>> ak.sqrt(a, ak.sqrt([True, True, False, False, True]))
array([0, 1, 2, 3, 2])
""""""
return power(pda, 0.5, where)
",[],0,[],/pdarrayclass.py_sqrt
736,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_skew,"def skew(pda: pdarray, bias: bool = True) -> np.float64:
""""""
Computes the sample skewness of an array.
Skewness > 0 means there's greater weight in the right tail of the distribution.
Skewness < 0 means there's greater weight in the left tail of the distribution.
Skewness == 0 means the data is normally distributed.
Based on the `scipy.stats.skew` function.
Parameters
----------
pda : pdarray
A pdarray of values that will be calculated to find the skew
bias : bool, optional
If False, then the calculations are corrected for statistical bias.
Returns
-------
np.float64
The skew of all elements in the array
Examples:
>>> a = ak.array([1, 1, 1, 5, 10])
>>> ak.skew(a)
0.9442193396379163
""""""
deviations = pda - pda.mean()
cubed_deviations = deviations**3
std_dev = pda.std()
if std_dev != 0:
skewness = cubed_deviations.mean() / (std_dev**3)
if not bias:
n = len(pda)
correction = np.sqrt((n - 1) * n) / (n - 2)
skewness = correction * skewness
else:
skewness = 0
return skewness
","['float64', 'float64', 'sqrt']",3,['sqrt((n - 1) * n) / (n - 2)'],/pdarrayclass.py_skew
737,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_mod,"def mod(dividend, divisor) -> pdarray:
""""""
Returns the element-wise remainder of division.
Computes the remainder complementary to the floor_divide function.
It is equivalent to np.mod, the remainder has the same sign as the divisor.
Parameters
----------
dividend
The array being acted on by the bases for the modular division.
divisor
The array that will be the bases for the modular division.
Returns
-------
pdarray
Returns an array that contains the element-wise remainder of division.
""""""
return dividend % divisor
",['mod'],1,[],/pdarrayclass.py_mod
738,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_fmod,"def fmod(dividend: Union[pdarray, numeric_scalars], divisor: Union[pdarray, numeric_scalars]) -> pdarray:
""""""
Returns the element-wise remainder of division.
It is equivalent to np.fmod, the remainder has the same sign as the dividend.
Parameters
----------
dividend : numeric scalars or pdarray
The array being acted on by the bases for the modular division.
divisor : numeric scalars or pdarray
The array that will be the bases for the modular division.
Returns
-------
pdarray
Returns an array that contains the element-wise remainder of division.
""""""
if not builtins.all(
isSupportedNumber(arg) or isinstance(arg, pdarray) for arg in [dividend, divisor]
):
raise TypeError(
f""Unsupported types {type(dividend)} and/or {type(divisor)}. Supported ""
""types are numeric scalars and pdarrays. At least one argument must be a pdarray.""
)
if isSupportedNumber(dividend) and isSupportedNumber(divisor):
raise TypeError(
f""Unsupported types {type(dividend)} and/or {type(divisor)}. Supported ""
""types are numeric scalars and pdarrays. At least one argument must be a pdarray.""
)
return create_pdarray(
cast(
str,
generic_msg(
cmd=""efunc2"",
args={
""func"": ""fmod"",
""A"": dividend,
""B"": divisor,
},
),
)
)
",['fmod'],1,[],/pdarrayclass.py_fmod
739,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_broadcast_if_needed,"def broadcast_if_needed(x1: pdarray, x2: pdarray) -> Tuple[pdarray, pdarray, bool, bool]:
from arkouda.util import broadcast_dims
if x1.shape == x2.shape:
return (x1, x2, False, False)
else:
tmp_x1 = False
tmp_x2 = False
try:
bc_shape = broadcast_dims(x1.shape, x2.shape)
except ValueError:
raise ValueError(
f""Incompatible array shapes for broadcasted operation: {x1.shape} and {x2.shape}""
)
if bc_shape != x1.shape:
x1b = broadcast_to_shape(x1, bc_shape)
tmp_x1 = True
else:
x1b = x1
if bc_shape != x2.shape:
x2b = broadcast_to_shape(x2, bc_shape)
tmp_x2 = True
else:
x2b = x2
return (x1b, x2b, tmp_x1, tmp_x2)
",[],0,[],/pdarrayclass.py_broadcast_if_needed
740,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_broadcast_to_shape,"def broadcast_to_shape(pda: pdarray, shape: Tuple[int, ...]) -> pdarray:
""""""
expand an array's rank to the specified shape using broadcasting
""""""
return create_pdarray(
cast(
str,
generic_msg(
cmd=f""broadcastTo{pda.ndim}Dx{len(shape)}D"",
args={
""name"": pda,
""shape"": shape,
},
),
)
)
",[],0,[],/pdarrayclass.py_broadcast_to_shape
741,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_attach_pdarray,"def attach_pdarray(user_defined_name: str) -> pdarray:
""""""
class method to return a pdarray attached to the registered name in the arkouda
server which was registered using register()
Parameters
----------
user_defined_name : str
user defined name which array was registered under
Returns
-------
pdarray
pdarray which is bound to the corresponding server side component which was registered
with user_defined_name
Raises
------
TypeError
Raised if user_defined_name is not a str
See also
--------
attach, register, unregister, is_registered, unregister_pdarray_by_name, list_registry
Notes
-----
Registered names/pdarrays in the server are immune to deletion
until they are unregistered.
Examples
--------
>>> a = zeros(100)
>>> a.register(""my_zeros"")
>>> # potentially disconnect from server and reconnect to server
>>> b = ak.attach_pdarray(""my_zeros"")
>>> # ...other work...
>>> b.unregister()
""""""
import warnings
from arkouda.util import attach
warnings.warn(
""ak.attach_pdarray() is deprecated. Please use ak.attach() instead."",
DeprecationWarning,
)
return attach(user_defined_name)
",[],0,[],/pdarrayclass.py_attach_pdarray
742,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_attach,"def attach(user_defined_name: str) -> pdarray:
""""""
class method to return a pdarray attached to the registered name in the arkouda
server which was registered using register()
Parameters
----------
user_defined_name : str
user defined name which array was registered under
Returns
-------
pdarray
pdarray which is bound to the corresponding server side component which was registered
with user_defined_name
Raises
------
TypeError
Raised if user_defined_name is not a str
See also
--------
register, unregister, is_registered, unregister_pdarray_by_name, list_registry
Notes
-----
Registered names/pdarrays in the server are immune to deletion
until they are unregistered.
Examples
--------
>>> a = zeros(100)
>>> a.register(""my_zeros"")
>>> # potentially disconnect from server and reconnect to server
>>> b = ak.pdarrayclass.attach(""my_zeros"")
>>> # ...other work...
>>> b.unregister()
""""""
import warnings
from arkouda.util import attach
warnings.warn(
""ak.pdarrayclass.attach() is deprecated. Please use ak.attach() instead."",
DeprecationWarning,
)
return attach(user_defined_name)
",[],0,[],/pdarrayclass.py_attach
743,/home/amandapotts/git/arkouda/arkouda/pdarrayclass.py_unregister_pdarray_by_name,"def unregister_pdarray_by_name(user_defined_name: str) -> None:
""""""
Unregister a named pdarray in the arkouda server which was previously
registered using register() and/or attahced to using attach_pdarray()
Parameters
----------
user_defined_name : str
user defined name which array was registered under
Returns
-------
None
Raises
------
RuntimeError
Raised if the server could not find the internal name/symbol to remove
See also
--------
register, unregister, is_registered, list_registry, attach
Notes
-----
Registered names/pdarrays in the server are immune to deletion until
they are unregistered.
Examples
--------
>>> a = zeros(100)
>>> a.register(""my_zeros"")
>>> # potentially disconnect from server and reconnect to server
>>> b = ak.attach_pdarray(""my_zeros"")
>>> # ...other work...
>>> ak.unregister_pdarray_by_name(b)
""""""
import warnings
from arkouda.util import unregister
warnings.warn(
""ak.unregister_pdarray_by_name() is deprecated. Please use ak.unregister() instead."",
DeprecationWarning,
)
return unregister(user_defined_name)
",[],0,[],/pdarrayclass.py_unregister_pdarray_by_name
744,/home/amandapotts/git/arkouda/arkouda/timeclass.py__get_factor,"def _get_factor(unit: str) -> int:
unit = unit.lower()
if unit in _unit2factor:
return _unit2factor[unit]
else:
for key, normunit in _unit2normunit.items():
if key.startswith(unit):
return _unit2factor[normunit]
raise ValueError(
f""Argument must be one of {set(_unit2factor.keys()) | set(_unit2normunit.keys())}""
)
",[],0,[],/timeclass.py__get_factor
745,/home/amandapotts/git/arkouda/arkouda/timeclass.py__identity,"def _identity(x, **kwargs):
return x
",[],0,[],/timeclass.py__identity
746,/home/amandapotts/git/arkouda/arkouda/timeclass.py___init__,"def __init__(self, scalar):
if isinstance(scalar, np.datetime64) or isinstance(scalar, datetime.datetime):
scalar = to_datetime(scalar).to_numpy()
elif isinstance(scalar, np.timedelta64) or isinstance(scalar, datetime.timedelta):
scalar = to_timedelta(scalar).to_numpy()
self.unit = np.datetime_data(scalar.dtype)[0]
self._factor = _get_factor(self.unit)
self.value = self._factor * scalar.astype(""int64"")
","['datetime64', 'timedelta64', 'datetime_data']",3,['datetime_data(scalar.dtype)'],/timeclass.py___init__
747,/home/amandapotts/git/arkouda/arkouda/timeclass.py___init__,"def __init__(self, pda, unit: str = _BASE_UNIT):  # type: ignore
if isinstance(pda, Datetime) or isinstance(pda, Timedelta):
self.unit: str = pda.unit
self._factor: int = pda._factor
self.values: pdarray = cast(pda.values, int64)
elif isinstance(pda, pdarray):
if pda.dtype not in intTypes:
raise TypeError(f""{self.__class__.__name__} array must have int64 dtype"")
self.unit = unit
self._factor = _get_factor(self.unit)
self.values = cast(self._factor * pda, int64)  # Mimics a datetime64[ns] array
elif hasattr(pda, ""dtype""):
if pda.dtype.kind not in (""M"", ""m""):
raise TypeError(f""Invalid dtype: {pda.dtype.name}"")
if isinstance(pda, Series):
self.unit = np.datetime_data(pda.values.dtype)[0]
self._factor = _get_factor(self.unit)
self.values = from_series(pda)
if self._factor != 1:
self.values *= self._factor
elif isinstance(pda, np.ndarray):
self.__init__(to_datetime(pda).to_series())  # type: ignore
elif hasattr(pda, ""to_series""):
self.__init__(pda.to_series())  # type: ignore
else:
raise TypeError(f""Unsupported type: {type(pda)}"")
super().__init__(
self.values.name,
self.values.dtype,
self.values.size,
self.values.ndim,
self.values.shape,
self.values.itemsize,
)
self._data = self.values
self._is_populated = False
","['datetime_data', 'ndarray']",2,['datetime_data(pda.values.dtype)'],/timeclass.py___init__
748,/home/amandapotts/git/arkouda/arkouda/timeclass.py__get_callback,"def _get_callback(cls, other, op):
return _identity
",[],0,[],/timeclass.py__get_callback
749,/home/amandapotts/git/arkouda/arkouda/timeclass.py_floor,"def floor(self, freq):
""""""Round times down to the nearest integer of a given frequency.
Parameters
----------
freq : str {'d', 'm', 'h', 's', 'ms', 'us', 'ns'}
Frequency to round to
Returns
-------
self.__class__
Values rounded down to nearest frequency
""""""
f = _get_factor(freq)
return self.__class__(self.values // f, unit=freq)
",[],0,[],/timeclass.py_floor
750,/home/amandapotts/git/arkouda/arkouda/timeclass.py_ceil,"def ceil(self, freq):
""""""Round times up to the nearest integer of a given frequency.
Parameters
----------
freq : str {'d', 'm', 'h', 's', 'ms', 'us', 'ns'}
Frequency to round to
Returns
-------
self.__class__
Values rounded up to nearest frequency
""""""
f = _get_factor(freq)
return self.__class__((self.values + (f - 1)) // f, unit=freq)
",[],0,[],/timeclass.py_ceil
751,/home/amandapotts/git/arkouda/arkouda/timeclass.py_round,"def round(self, freq):
""""""Round times to the nearest integer of a given frequency. Midpoint
values will be rounded to nearest even integer.
Parameters
----------
freq : str {'d', 'm', 'h', 's', 'ms', 'us', 'ns'}
Frequency to round to
Returns
-------
self.__class__
Values rounded to nearest frequency
""""""
f = _get_factor(freq)
offset = self.values + ((f + 1) // 2)
rounded = offset // f
decrement = ((offset % f) == 0) & ((rounded % 2) == 1)
rounded[decrement] = rounded[decrement] - 1
return self.__class__(rounded, unit=freq)
",[],0,[],/timeclass.py_round
752,/home/amandapotts/git/arkouda/arkouda/timeclass.py_to_ndarray,"def to_ndarray(self):
__doc__ = super().to_ndarray.__doc__  # noqa
return np.array(
self.values.to_ndarray(),
dtype=""{}64[ns]"".format(self.__class__.__name__.lower()),
)
",['array'],1,[],/timeclass.py_to_ndarray
753,/home/amandapotts/git/arkouda/arkouda/timeclass.py_to_list,"def to_list(self):
__doc__ = super().to_list().__doc__  # noqa
return self.to_ndarray().tolist()
",[],0,[],/timeclass.py_to_list
754,/home/amandapotts/git/arkouda/arkouda/timeclass.py_to_hdf,"def to_hdf(
self,
prefix_path: str,
dataset: str = ""array"",
mode: str = ""truncate"",
file_type: str = ""distribute"",
",[],0,[],/timeclass.py_to_hdf
755,/home/amandapotts/git/arkouda/arkouda/timeclass.py_update_hdf,"def update_hdf(self, prefix_path: str, dataset: str = ""array"", repack: bool = True):
""""""
Override the pdarray implementation so that the special object type will be used.
""""""
from arkouda.io import (
_file_type_to_int,
_get_hdf_filetype,
_mode_str_to_int,
_repack_hdf,
)
file_type = _get_hdf_filetype(prefix_path + ""*"")
generic_msg(
cmd=""tohdf"",
args={
""values"": self,
""dset"": dataset,
""write_mode"": _mode_str_to_int(""append""),
""filename"": prefix_path,
""dtype"": self.dtype,
""objType"": self.special_objType,
""file_format"": _file_type_to_int(file_type),
""overwrite"": True,
},
)
if repack:
_repack_hdf(prefix_path)
",[],0,[],/timeclass.py_update_hdf
756,/home/amandapotts/git/arkouda/arkouda/timeclass.py___str__,"def __str__(self):
from arkouda.client import pdarrayIterThresh
if self.size <= pdarrayIterThresh:
vals = [f""'{self[i]}'"" for i in range(self.size)]
else:
vals = [f""'{self[i]}'"" for i in range(3)]
vals.append(""... "")
vals.extend([f""'{self[i]}'"" for i in range(self.size - 3, self.size)])
spaces = "" "" * (len(self.__class__.__name__) + 1)
return ""{}([{}],\n{}dtype='{}64[ns]')"".format(
self.__class__.__name__,
"",\n{} "".format(spaces).join(vals),
spaces,
self.__class__.__name__.lower(),
)
",[],0,[],/timeclass.py___str__
757,/home/amandapotts/git/arkouda/arkouda/timeclass.py___repr__,"def __repr__(self) -> str:
return self.__str__()
",[],0,[],/timeclass.py___repr__
758,/home/amandapotts/git/arkouda/arkouda/timeclass.py__binop,"def _binop(self, other, op):
if isinstance(other, Datetime) or self._is_datetime_scalar(other):
if op not in self.supported_with_datetime:
raise TypeError(f""{op} not supported between {self.__class__.__name__} and Datetime"")
otherclass = ""Datetime""
if self._is_datetime_scalar(other):
otherdata = _Timescalar(other).value
else:
otherdata = other.values
elif isinstance(other, Timedelta) or self._is_timedelta_scalar(other):
if op not in self.supported_with_timedelta:
raise TypeError(f""{op} not supported between {self.__class__.__name__} and Timedelta"")
otherclass = ""Timedelta""
if self._is_timedelta_scalar(other):
otherdata = _Timescalar(other).value
else:
otherdata = other.values
elif (isinstance(other, pdarray) and other.dtype in intTypes) or isSupportedInt(other):
if op not in self.supported_with_pdarray:
raise TypeError(f""{op} not supported between {self.__class__.__name__} and integer"")
otherclass = ""pdarray""
otherdata = other
else:
return NotImplemented
callback = self._get_callback(otherclass, op)
return callback(self.values._binop(otherdata, op))
",[],0,[],/timeclass.py__binop
759,/home/amandapotts/git/arkouda/arkouda/timeclass.py__r_binop,"def _r_binop(self, other, op):
if isinstance(other, pdarray) and other.dtype in intTypes:
if op not in self.supported_with_r_pdarray:
raise TypeError(f""{op} not supported between int64 and {self.__class__.__name__}"")
callback = self._get_callback(""pdarray"", op)
return callback(other._binop(self.values, op))
elif self._is_datetime_scalar(other):
if op not in self.supported_with_r_datetime:
raise TypeError(
f""{op} not supported between scalar datetime and {self.__class__.__name__}""
)
otherclass = ""Datetime""
otherdata = _Timescalar(other).value
elif self._is_timedelta_scalar(other):
if op not in self.supported_with_r_timedelta:
raise TypeError(
f""{op} not supported between scalar timedelta and {self.__class__.__name__}""
)
otherclass = ""Timedelta""
otherdata = _Timescalar(other).value
elif isSupportedInt(other):
if op not in self.supported_with_r_pdarray:
raise TypeError(f""{op} not supported between int64 and {self.__class__.__name__}"")
otherclass = ""pdarray""
otherdata = other
else:
return NotImplemented
callback = self._get_callback(otherclass, op)
return callback(self.values._r_binop(otherdata, op))
",[],0,[],/timeclass.py__r_binop
760,/home/amandapotts/git/arkouda/arkouda/timeclass.py_opeq,"def opeq(self, other, op):
if isinstance(other, Timedelta) or self._is_timedelta_scalar(other):
if op not in self.supported_opeq:
raise TypeError(f""{self.__class__.__name__} {op} Timedelta not supported"")
if self._is_timedelta_scalar(other):
otherdata = _Timescalar(other).value
else:
otherdata = other.values
self.values.opeq(otherdata, op)
elif isinstance(other, Datetime) or self._is_datetime_scalar(other):
raise TypeError(f""{self.__class__.__name__} {op} datetime not supported"")
else:
return NotImplemented
",[],0,[],/timeclass.py_opeq
761,/home/amandapotts/git/arkouda/arkouda/timeclass.py__is_datetime_scalar,"def _is_datetime_scalar(scalar):
return (
isinstance(scalar, Timestamp)
or (isinstance(scalar, np.datetime64) and np.isscalar(scalar))
or isinstance(scalar, datetime.datetime)
)
","['datetime64', 'isscalar']",2,['isscalar(scalar))'],/timeclass.py__is_datetime_scalar
762,/home/amandapotts/git/arkouda/arkouda/timeclass.py__is_timedelta_scalar,"def _is_timedelta_scalar(scalar):
return (
isinstance(scalar, pdTimedelta)
or (isinstance(scalar, np.timedelta64) and np.isscalar(scalar))
or isinstance(scalar, datetime.timedelta)
)
","['timedelta64', 'isscalar']",2,['isscalar(scalar))'],/timeclass.py__is_timedelta_scalar
763,/home/amandapotts/git/arkouda/arkouda/timeclass.py__scalar_callback,"def _scalar_callback(self, key):
return key
",[],0,[],/timeclass.py__scalar_callback
764,/home/amandapotts/git/arkouda/arkouda/timeclass.py___getitem__,"def __getitem__(self, key):
if isSupportedInt(key):
return self._scalar_callback(self.values[key])
else:
return self.__class__(self.values[key])
",[],0,[],/timeclass.py___getitem__
765,/home/amandapotts/git/arkouda/arkouda/timeclass.py___setitem__,"def __setitem__(self, key, value):
if isinstance(value, self.__class__):
self.values[key] = value.values
elif self._is_supported_scalar(value):
normval = _Timescalar(value)
self.values[key] = normval.value
else:
return NotImplemented
",[],0,[],/timeclass.py___setitem__
766,/home/amandapotts/git/arkouda/arkouda/timeclass.py_min,"def min(self):
__doc__ = super().min.__doc__  # noqa
return self._scalar_callback(self.values.min())
",[],0,[],/timeclass.py_min
767,/home/amandapotts/git/arkouda/arkouda/timeclass.py_max,"def max(self):
__doc__ = super().max.__doc__  # noqa
return self._scalar_callback(self.values.max())
",[],0,[],/timeclass.py_max
768,/home/amandapotts/git/arkouda/arkouda/timeclass.py_mink,"def mink(self, k):
__doc__ = super().mink.__doc__  # noqa
return self.__class__(self.values.mink(k))
",[],0,[],/timeclass.py_mink
769,/home/amandapotts/git/arkouda/arkouda/timeclass.py_maxk,"def maxk(self, k):
__doc__ = super().maxk.__doc__  # noqa
return self.__class__(self.values.maxk(k))
",[],0,[],/timeclass.py_maxk
770,/home/amandapotts/git/arkouda/arkouda/timeclass.py__ensure_components,"def _ensure_components(self):
if self._is_populated:
return
attribute_dict = json.loads(generic_msg(cmd=""dateTimeAttributes"", args={""values"": self.values}))
self._ns = create_pdarray(attribute_dict[""nanosecond""])
self._us = create_pdarray(attribute_dict[""microsecond""])
self._ms = create_pdarray(attribute_dict[""millisecond""])
self._s = create_pdarray(attribute_dict[""second""])
self._min = create_pdarray(attribute_dict[""minute""])
self._hour = create_pdarray(attribute_dict[""hour""])
self._day = create_pdarray(attribute_dict[""day""])
self._month = create_pdarray(attribute_dict[""month""])
self._year = create_pdarray(attribute_dict[""year""])
self._iso_year = create_pdarray(attribute_dict[""isoYear""])
self._day_of_week = create_pdarray(attribute_dict[""dayOfWeek""])
self._week_of_year = create_pdarray(attribute_dict[""weekOfYear""])
self._day_of_year = create_pdarray(attribute_dict[""dayOfYear""])
self._is_leap_year = create_pdarray(attribute_dict[""isLeapYear""])
self._date = self.floor(""d"")
self._is_populated = True
",[],0,[],/timeclass.py__ensure_components
771,/home/amandapotts/git/arkouda/arkouda/timeclass.py_nanosecond,"def nanosecond(self):
self._ensure_components()
return self._ns
",[],0,[],/timeclass.py_nanosecond
772,/home/amandapotts/git/arkouda/arkouda/timeclass.py_microsecond,"def microsecond(self):
self._ensure_components()
return self._us
",[],0,[],/timeclass.py_microsecond
773,/home/amandapotts/git/arkouda/arkouda/timeclass.py_millisecond,"def millisecond(self):
self._ensure_components()
return self._ms
",[],0,[],/timeclass.py_millisecond
774,/home/amandapotts/git/arkouda/arkouda/timeclass.py_second,"def second(self):
self._ensure_components()
return self._s
",[],0,[],/timeclass.py_second
775,/home/amandapotts/git/arkouda/arkouda/timeclass.py_minute,"def minute(self):
self._ensure_components()
return self._min
",[],0,[],/timeclass.py_minute
776,/home/amandapotts/git/arkouda/arkouda/timeclass.py_hour,"def hour(self):
self._ensure_components()
return self._hour
",[],0,[],/timeclass.py_hour
777,/home/amandapotts/git/arkouda/arkouda/timeclass.py_day,"def day(self):
self._ensure_components()
return self._day
",[],0,[],/timeclass.py_day
778,/home/amandapotts/git/arkouda/arkouda/timeclass.py_month,"def month(self):
self._ensure_components()
return self._month
",[],0,[],/timeclass.py_month
779,/home/amandapotts/git/arkouda/arkouda/timeclass.py_year,"def year(self):
self._ensure_components()
return self._year
",[],0,[],/timeclass.py_year
780,/home/amandapotts/git/arkouda/arkouda/timeclass.py_day_of_year,"def day_of_year(self):
self._ensure_components()
return self._day_of_year
",[],0,[],/timeclass.py_day_of_year
781,/home/amandapotts/git/arkouda/arkouda/timeclass.py_dayofyear,"def dayofyear(self):
return self.day_of_year
",[],0,[],/timeclass.py_dayofyear
782,/home/amandapotts/git/arkouda/arkouda/timeclass.py_day_of_week,"def day_of_week(self):
self._ensure_components()
return self._day_of_week
",[],0,[],/timeclass.py_day_of_week
783,/home/amandapotts/git/arkouda/arkouda/timeclass.py_dayofweek,"def dayofweek(self):
return self.day_of_week
",[],0,[],/timeclass.py_dayofweek
784,/home/amandapotts/git/arkouda/arkouda/timeclass.py_weekday,"def weekday(self):
return self.day_of_week
",[],0,[],/timeclass.py_weekday
785,/home/amandapotts/git/arkouda/arkouda/timeclass.py_week,"def week(self):
self._ensure_components()
return self._week_of_year
",[],0,[],/timeclass.py_week
786,/home/amandapotts/git/arkouda/arkouda/timeclass.py_weekofyear,"def weekofyear(self):
return self.week
",[],0,[],/timeclass.py_weekofyear
787,/home/amandapotts/git/arkouda/arkouda/timeclass.py_date,"def date(self):
if not hasattr(self, ""_date""):
self._date = self.floor(""d"")
return self._date
",[],0,[],/timeclass.py_date
788,/home/amandapotts/git/arkouda/arkouda/timeclass.py_is_leap_year,"def is_leap_year(self):
self._ensure_components()
return self._is_leap_year
",[],0,[],/timeclass.py_is_leap_year
789,/home/amandapotts/git/arkouda/arkouda/timeclass.py_isocalendar,"def isocalendar(self):
from arkouda import DataFrame
self._ensure_components()
return DataFrame(
{
""year"": self._iso_year,
""week"": self._week_of_year,
""day"": self._day_of_week + 1,
}
)
",[],0,[],/timeclass.py_isocalendar
790,/home/amandapotts/git/arkouda/arkouda/timeclass.py__get_callback,"def _get_callback(cls, otherclass, op):
callbacks = {
(""Datetime"", ""-""): Timedelta,  # Datetime - Datetime -> Timedelta
(""Timedelta"", ""+""): cls,  # Datetime + Timedelta -> Datetime
(""Timedelta"", ""-""): cls,  # Datetime - Timedelta -> Datetime
(""Timedelta"", ""%""): Timedelta,
}  # Datetime % Timedelta -> Timedelta
return callbacks.get((otherclass, op), _identity)
",[],0,[],/timeclass.py__get_callback
791,/home/amandapotts/git/arkouda/arkouda/timeclass.py__scalar_callback,"def _scalar_callback(self, scalar):
return Timestamp(int(scalar), unit=_BASE_UNIT)
",[],0,[],/timeclass.py__scalar_callback
792,/home/amandapotts/git/arkouda/arkouda/timeclass.py__is_supported_scalar,"def _is_supported_scalar(self, scalar):
return self.is_datetime_scalar(scalar)
",[],0,[],/timeclass.py__is_supported_scalar
793,/home/amandapotts/git/arkouda/arkouda/timeclass.py_to_pandas,"def to_pandas(self):
""""""Convert array to a pandas DatetimeIndex. Note: if the array size
exceeds client.maxTransferBytes, a RuntimeError is raised.
See Also
--------
to_ndarray
""""""
return to_datetime(self.to_ndarray())
",[],0,[],/timeclass.py_to_pandas
794,/home/amandapotts/git/arkouda/arkouda/timeclass.py_sum,"def sum(self):
raise TypeError(""Cannot sum datetime64 values"")
",[],0,[],/timeclass.py_sum
795,/home/amandapotts/git/arkouda/arkouda/timeclass.py_register,"def register(self, user_defined_name):
""""""
Register this Datetime object and underlying components with the Arkouda server
Parameters
----------
user_defined_name : str
user defined name the Datetime is to be registered under,
this will be the root name for underlying components
Returns
-------
Datetime
The same Datetime which is now registered with the arkouda server and has an updated name.
This is an in-place modification, the original is returned to support
a fluid programming style.
Please note you cannot register two different Datetimes with the same name.
Raises
------
TypeError
Raised if user_defined_name is not a str
RegistrationError
If the server was unable to register the Datetimes with the user_defined_name
See also
--------
unregister, attach, is_registered
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.client import generic_msg
if self.registered_name is not None and self.is_registered():
raise RegistrationError(f""This object is already registered as {self.registered_name}"")
generic_msg(
cmd=""register"",
args={
""name"": user_defined_name,
""objType"": self.special_objType,
""array"": self.values,
},
)
self.registered_name = user_defined_name
return self
",[],0,[],/timeclass.py_register
796,/home/amandapotts/git/arkouda/arkouda/timeclass.py_unregister,"def unregister(self):
""""""
Unregister this Datetime object in the arkouda server which was previously
registered using register() and/or attached to using attach()
Raises
------
RegistrationError
If the object is already unregistered or if there is a server error
when attempting to unregister
See also
--------
register, attach, is_registered
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.util import unregister
if not self.registered_name:
raise RegistrationError(""This object is not registered"")
unregister(self.registered_name)
self.registered_name = None
",[],0,[],/timeclass.py_unregister
797,/home/amandapotts/git/arkouda/arkouda/timeclass.py_is_registered,"def is_registered(self) -> np.bool_:
""""""
Return True iff the object is contained in the registry or is a component of a
registered object.
Returns
-------
numpy.bool
Indicates if the object is contained in the registry
Raises
------
RegistrationError
Raised if there's a server-side error or a mis-match of registered components
See Also
--------
register, attach, unregister
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.util import is_registered
if self.registered_name is None:
return np.bool_(is_registered(self.values.name, as_component=True))
else:
return np.bool_(is_registered(self.registered_name))
","['bool_', 'bool_', 'bool_']",3,"['bool_(is_registered(self.values.name, as_component=True))', 'bool_(is_registered(self.registered_name))']",/timeclass.py_is_registered
798,/home/amandapotts/git/arkouda/arkouda/timeclass.py__ensure_components,"def _ensure_components(self):
if self._is_populated:
return
attribute_dict = json.loads(generic_msg(cmd=""timeDeltaAttributes"", args={""values"": self.values}))
self._ns = create_pdarray(attribute_dict[""nanosecond""])
self._us = create_pdarray(attribute_dict[""microsecond""])
self._ms = create_pdarray(attribute_dict[""millisecond""])
self._s = create_pdarray(attribute_dict[""second""])
self._m = create_pdarray(attribute_dict[""minute""])
self._h = create_pdarray(attribute_dict[""hour""])
self._d = create_pdarray(attribute_dict[""day""])
self._nanoseconds = self._ns
self._microseconds = self._ms * 1000 + self._us
self._seconds = self._h * 3600 + self._m * 60 + self._s
self._days = self._d
self._total_seconds = self._days * (24 * 3600) + self._seconds + (self._microseconds / 10**6)
self._is_populated = True
",[],0,[],/timeclass.py__ensure_components
799,/home/amandapotts/git/arkouda/arkouda/timeclass.py_nanoseconds,"def nanoseconds(self):
self._ensure_components()
return self._nanoseconds
",[],0,[],/timeclass.py_nanoseconds
800,/home/amandapotts/git/arkouda/arkouda/timeclass.py_microseconds,"def microseconds(self):
self._ensure_components()
return self._microseconds
",[],0,[],/timeclass.py_microseconds
801,/home/amandapotts/git/arkouda/arkouda/timeclass.py_seconds,"def seconds(self):
self._ensure_components()
return self._seconds
",[],0,[],/timeclass.py_seconds
802,/home/amandapotts/git/arkouda/arkouda/timeclass.py_days,"def days(self):
self._ensure_components()
return self._days
",[],0,[],/timeclass.py_days
803,/home/amandapotts/git/arkouda/arkouda/timeclass.py_total_seconds,"def total_seconds(self):
self._ensure_components()
return self._total_seconds
",[],0,[],/timeclass.py_total_seconds
804,/home/amandapotts/git/arkouda/arkouda/timeclass.py_components,"def components(self):
from arkouda import DataFrame
self._ensure_components()
return DataFrame(
{
""days"": self._d,
""hours"": self._h,
""minutes"": self._m,
""seconds"": self._s,
""milliseconds"": self._ms,
""microseconds"": self._us,
""nanoseconds"": self._ns,
}
)
",[],0,[],/timeclass.py_components
805,/home/amandapotts/git/arkouda/arkouda/timeclass.py__get_callback,"def _get_callback(cls, otherclass, op):
callbacks = {
(""Timedelta"", ""-""): cls,  # Timedelta - Timedelta -> Timedelta
(""Timedelta"", ""+""): cls,  # Timedelta + Timedelta -> Timedelta
(""Datetime"", ""+""): Datetime,  # Timedelta + Datetime -> Datetime
(""Datetime"", ""-""): Datetime,  # Datetime - Timedelta -> Datetime
(""Timedelta"", ""%""): cls,  # Timedelta % Timedelta -> Timedelta
(""pdarray"", ""//""): cls,  # Timedelta // pdarray -> Timedelta
(""pdarray"", ""*""): cls,
}  # Timedelta * pdarray -> Timedelta
return callbacks.get((otherclass, op), _identity)
",[],0,[],/timeclass.py__get_callback
806,/home/amandapotts/git/arkouda/arkouda/timeclass.py__scalar_callback,"def _scalar_callback(self, scalar):
return pdTimedelta(int(scalar), unit=_BASE_UNIT)
",[],0,[],/timeclass.py__scalar_callback
807,/home/amandapotts/git/arkouda/arkouda/timeclass.py__is_supported_scalar,"def _is_supported_scalar(self, scalar):
return self.is_timedelta_scalar(scalar)
",[],0,[],/timeclass.py__is_supported_scalar
808,/home/amandapotts/git/arkouda/arkouda/timeclass.py_to_pandas,"def to_pandas(self):
""""""Convert array to a pandas TimedeltaIndex. Note: if the array size
exceeds client.maxTransferBytes, a RuntimeError is raised.
See Also
--------
to_ndarray
""""""
return to_timedelta(self.to_ndarray())
",[],0,[],/timeclass.py_to_pandas
809,/home/amandapotts/git/arkouda/arkouda/timeclass.py_std,"def std(self, ddof: int_scalars = 0):
""""""
Returns the standard deviation as a pd.Timedelta object
""""""
return self._scalar_callback(self.values.std(ddof=ddof))
",[],0,[],/timeclass.py_std
810,/home/amandapotts/git/arkouda/arkouda/timeclass.py_sum,"def sum(self):
return self._scalar_callback(self.values.sum())
",[],0,[],/timeclass.py_sum
811,/home/amandapotts/git/arkouda/arkouda/timeclass.py_abs,"def abs(self):
""""""Absolute value of time interval.""""""
return self.__class__(cast(akabs(self.values), ""int64""))
",[],0,[],/timeclass.py_abs
812,/home/amandapotts/git/arkouda/arkouda/timeclass.py_register,"def register(self, user_defined_name):
""""""
Register this Timedelta object and underlying components with the Arkouda server
Parameters
----------
user_defined_name : str
user defined name the timedelta is to be registered under,
this will be the root name for underlying components
Returns
-------
Timedelta
The same Timedelta which is now registered with the arkouda server and has an updated name.
This is an in-place modification, the original is returned to support
a fluid programming style.
Please note you cannot register two different Timedeltas with the same name.
Raises
------
TypeError
Raised if user_defined_name is not a str
RegistrationError
If the server was unable to register the timedelta with the user_defined_name
See also
--------
unregister, attach, is_registered
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.client import generic_msg
if self.registered_name is not None and self.is_registered():
raise RegistrationError(f""This object is already registered as {self.registered_name}"")
generic_msg(
cmd=""register"",
args={
""name"": user_defined_name,
""objType"": self.special_objType,
""array"": self.values,
},
)
self.registered_name = user_defined_name
return self
",[],0,[],/timeclass.py_register
813,/home/amandapotts/git/arkouda/arkouda/timeclass.py_unregister,"def unregister(self):
""""""
Unregister this timedelta object in the arkouda server which was previously
registered using register() and/or attached to using attach()
Raises
------
RegistrationError
If the object is already unregistered or if there is a server error
when attempting to unregister
See also
--------
register, attach, is_registered
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.util import unregister
if not self.registered_name:
raise RegistrationError(""This object is not registered"")
unregister(self.registered_name)
self.registered_name = None
",[],0,[],/timeclass.py_unregister
814,/home/amandapotts/git/arkouda/arkouda/timeclass.py_is_registered,"def is_registered(self) -> np.bool_:
""""""
Return True iff the object is contained in the registry or is a component of a
registered object.
Returns
-------
numpy.bool
Indicates if the object is contained in the registry
Raises
------
RegistrationError
Raised if there's a server-side error or a mis-match of registered components
See Also
--------
register, attach, unregister
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
""""""
from arkouda.util import is_registered
if self.registered_name is None:
return np.bool_(is_registered(self.values.name, as_component=True))
else:
return np.bool_(is_registered(self.registered_name))
","['bool_', 'bool_', 'bool_']",3,"['bool_(is_registered(self.values.name, as_component=True))', 'bool_(is_registered(self.registered_name))']",/timeclass.py_is_registered
815,/home/amandapotts/git/arkouda/arkouda/timeclass.py_date_range,"def date_range(
start=None,
end=None,
periods=None,
freq=None,
tz=None,
normalize=False,
name=None,
closed=None,
inclusive=""both"",
",[],0,[],/timeclass.py_date_range
816,/home/amandapotts/git/arkouda/arkouda/timeclass.py_timedelta_range,"def timedelta_range(start=None, end=None, periods=None, freq=None, name=None, closed=None, **kwargs):
""""""Return a fixed frequency TimedeltaIndex, with day as the default
frequency. Alias for ``ak.Timedelta(pd.timedelta_range(args))``.
Subject to size limit imposed by client.maxTransferBytes.
Parameters
----------
start : str or timedelta-like, default None
Left bound for generating timedeltas.
end : str or timedelta-like, default None
Right bound for generating timedeltas.
periods : int, default None
Number of periods to generate.
freq : str or DateOffset, default 'D'
Frequency strings can have multiples, e.g. '5H'.
name : str, default None
Name of the resulting TimedeltaIndex.
closed : str, default None
Make the interval closed with respect to the given frequency to
the 'left', 'right', or both sides (None).
Returns
-------
rng : TimedeltaIndex
Notes
-----
Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,
exactly three must be specified. If ``freq`` is omitted, the resulting
``TimedeltaIndex`` will have ``periods`` linearly spaced elements between
``start`` and ``end`` (closed on both sides).
To learn more about the frequency strings, please see `this link
<https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.
""""""
return Timedelta(pd_timedelta_range(start, end, periods, freq, name, closed, **kwargs))
",[],0,[],/timeclass.py_timedelta_range
817,/home/amandapotts/git/arkouda/arkouda/plotting.py_plot_dist,"def plot_dist(b, h, log=True, xlabel=None, newfig=True):
""""""
Plot the distribution and cumulative distribution of histogram Data
Parameters
----------
b : np.ndarray
Bin edges
h : np.ndarray
Histogram data
log : bool
use log to scale y
xlabel: str
Label for the x axis of the graph
newfig: bool
Generate a new figure or not
Notes
-----
This function does not return or display the plot. A user must have matplotlib imported in
addition to arkouda to display plots. This could be updated to return the object or have a
flag to show the resulting plots.
See Examples Below.
Examples
--------
>>> import arkouda as ak
>>> from matplotlib import pyplot as plt
>>> b, h = ak.histogram(ak.arange(10), 3)
>>> ak.plot_dist(b, h.to_ndarray())
>>> # to show the plot
>>> plt.show()
""""""
if newfig:
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(b, h, marker=""."", linestyle=""solid"")
if log:
plt.yscale(""log"")
if xlabel is not None:
plt.gca().set_xlabel(xlabel, fontsize=14)
plt.gca().set_title(""distribution"")
plt.subplot(1, 2, 2)
plt.plot(b, np.cumsum(h) / np.sum(h), marker=None, linestyle=""solid"")
plt.gca().set_ylim((0, 1))
plt.gca().set_title(""cumulative distribution"")
if xlabel is not None:
plt.gca().set_xlabel(xlabel, fontsize=14)
","['ndarray', 'ndarray', 'cumsum', 'sum']",4,"['cumsum(h) / np.sum(h), marker=None, linestyle=""solid"")']",/plotting.py_plot_dist
818,/home/amandapotts/git/arkouda/arkouda/plotting.py_hist_all,"def hist_all(ak_df: DataFrame, cols: list = []):
""""""
Create a grid plot histogramming all numeric columns in ak dataframe
Parameters
----------
ak_df : ak.DataFrame
Full Arkouda DataFrame containing data to be visualized
cols : list
(Optional) A specified list of columns to be plotted
Notes
-----
This function displays the plot.
Examples
--------
>>> import arkouda as ak
>>> from arkouda.plotting import hist_all
>>> ak_df = ak.DataFrame({""a"": ak.array(np.random.randn(100)),
""b"": ak.array(np.random.randn(100)),
""c"": ak.array(np.random.randn(100)),
""d"": ak.array(np.random.randn(100))
})
>>> hist_all(ak_df)
""""""
if len(cols) == 0:
cols = ak_df.columns
num_rows = int(math.ceil(len(cols) ** 0.5))
num_cols = (len(cols) + num_rows - 1) // num_rows
fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 10))
fig.tight_layout(pad=2.0)
if num_rows > 1:
axes = axes.flatten()
else:
axes = [axes]
for col in cols:
try:
ax = axes[cols.index(col)]
x = ak_df[col]
if x.dtype == ""float64"":
x = x[~isnan(x)]
n = len(x)
g1 = skew(x)
except ValueError:
GB_df = GroupBy(ak_df[col])
new_labels = arange(GB_df.unique_keys.size)
newcol = GB_df.broadcast(new_labels)
x = newcol[: ak_df.size]
if x.dtype == ""float64"":
x = x[~isnan(x)]
n = len(x)
g1 = skew(x)
sigma_g1 = math.sqrt(6 * (n - 2) / ((n + 1) * (n + 3)))
num_bins = int(1 + math.log2(n) + math.log2(1 + abs(g1) / sigma_g1))
h = histogram(x, num_bins)
if isinstance(x, Datetime):
bins = date_range(x.min(), x.max(), periods=num_bins).to_ndarray().astype(""int"")
elif isinstance(x, Timedelta):
bins = timedelta_range(x.min(), x.max(), periods=num_bins).to_ndarray().astype(""int"")
else:
bins = np.linspace(x.min(), x.max(), num_bins + 1)[:-1]
ax.bar(bins, h[1].to_ndarray(), width=bins[1] - bins[0])
ax.set_title(col, size=8)
if x.max() > 100 * x.min():
ax.set_yscale(""log"")
","['random.randn', 'random.randn', 'random.randn', 'random.randn', 'linspace']",5,"['random.randn(100))', 'random.randn(100))', 'random.randn(100))', 'random.randn(100))', 'linspace(x.min(), x.max(), num_bins + 1)']",/plotting.py_hist_all
819,/home/amandapotts/git/arkouda/arkouda/sorting.py_argsort,"def argsort(
pda: Union[pdarray, Strings, ""Categorical""],  # type: ignore # noqa
algorithm: SortingAlgorithm = SortingAlgorithm.RadixSortLSD,
axis: int_scalars = 0,
",[],0,[],/sorting.py_argsort
820,/home/amandapotts/git/arkouda/arkouda/sorting.py_coargsort,"def coargsort(
arrays: Sequence[Union[Strings, pdarray, ""Categorical""]],  # type: ignore # noqa
algorithm: SortingAlgorithm = SortingAlgorithm.RadixSortLSD,
",[],0,[],/sorting.py_coargsort
821,/home/amandapotts/git/arkouda/arkouda/sorting.py_sort,"def sort(pda: pdarray, algorithm: SortingAlgorithm = SortingAlgorithm.RadixSortLSD) -> pdarray:
""""""
Return a sorted copy of the array. Only sorts numeric arrays
for Strings, use argsort.
Parameters
----------
pda : pdarray or Categorical
The array to sort (int64, uint64, or float64)
Returns
-------
pdarray, int64, uint64, or float64
The sorted copy of pda
Raises
------
TypeError
Raised if the parameter is not a pdarray
ValueError
Raised if sort attempted on a pdarray with an unsupported dtype
such as bool
See Also
--------
argsort
Notes
-----
Uses a least-significant-digit radix sort, which is stable and resilient
to non-uniformity in data but communication intensive.
Examples
--------
>>> a = ak.randint(0, 10, 10)
>>> sorted = ak.sort(a)
>>> a
array([0, 1, 1, 3, 4, 5, 7, 8, 8, 9])
""""""
if pda.dtype == bigint:
return pda[coargsort(pda.bigint_to_uint_arrays(), algorithm)]
if pda.dtype not in numeric_dtypes:
raise ValueError(f""ak.sort supports int64, uint64, or float64, not {pda.dtype}"")
if pda.size == 0:
return zeros(0, dtype=pda.dtype)
repMsg = generic_msg(cmd=""sort"", args={""alg"": algorithm.name, ""array"": pda})
return create_pdarray(cast(str, repMsg))
",[],0,[],/sorting.py_sort
822,/home/amandapotts/git/arkouda/arkouda/dtypes.py_dtype,"def dtype(x):
if (isinstance(x, str) and x == ""bigint"") or isinstance(x, BigInt):
return bigint
else:
return np.dtype(x)
",['dtype'],1,['dtype(x)'],/dtypes.py_dtype
823,/home/amandapotts/git/arkouda/arkouda/dtypes.py___init__,"def __init__(self):
self.name = ""bigint""
",[],0,[],/dtypes.py___init__
824,/home/amandapotts/git/arkouda/arkouda/dtypes.py___str__,"def __str__(self):
return self.name
",[],0,[],/dtypes.py___str__
825,/home/amandapotts/git/arkouda/arkouda/dtypes.py___repr__,"def __repr__(self):
return f""dtype({self.name})""
",[],0,[],/dtypes.py___repr__
826,/home/amandapotts/git/arkouda/arkouda/dtypes.py_type,"def type(self, x):
return int(x)
",[],0,[],/dtypes.py_type
827,/home/amandapotts/git/arkouda/arkouda/dtypes.py___str__,"def __str__(self) -> str:  # type: ignore
""""""
Overridden method returns value, which is useful in outputting
a DType as a request parameter
""""""
return self.value
",[],0,[],/dtypes.py___str__
828,/home/amandapotts/git/arkouda/arkouda/dtypes.py___repr__,"def __repr__(self) -> str:  # type: ignore
""""""
Overridden method returns value, which is useful in outputting
a DType as a request parameter
""""""
return self.value
",[],0,[],/dtypes.py___repr__
829,/home/amandapotts/git/arkouda/arkouda/dtypes.py_isSupportedInt,"def isSupportedInt(num):
return isinstance(num, ARKOUDA_SUPPORTED_INTS)
",[],0,[],/dtypes.py_isSupportedInt
830,/home/amandapotts/git/arkouda/arkouda/dtypes.py_isSupportedFloat,"def isSupportedFloat(num):
return isinstance(num, ARKOUDA_SUPPORTED_FLOATS)
",[],0,[],/dtypes.py_isSupportedFloat
831,/home/amandapotts/git/arkouda/arkouda/dtypes.py_isSupportedNumber,"def isSupportedNumber(num):
return isinstance(num, ARKOUDA_SUPPORTED_NUMBERS)
",[],0,[],/dtypes.py_isSupportedNumber
832,/home/amandapotts/git/arkouda/arkouda/dtypes.py__as_dtype,"def _as_dtype(dt) -> np.dtype:
if not isinstance(dt, np.dtype):
return dtype(dt)
return dt
","['dtype', 'dtype']",2,[],/dtypes.py__as_dtype
833,/home/amandapotts/git/arkouda/arkouda/dtypes.py_check_np_dtype,"def check_np_dtype(dt: np.dtype) -> None:
""""""
Assert that numpy dtype dt is one of the dtypes supported
by arkouda, otherwise raise TypeError.
Raises
------
TypeError
Raised if the dtype is not in supported dtypes or if
dt is not a np.dtype
""""""
if _as_dtype(dt).name not in DTypes:
raise TypeError(f""Unsupported type: {dt}"")
","['dtype', 'dtype']",2,[],/dtypes.py_check_np_dtype
834,/home/amandapotts/git/arkouda/arkouda/dtypes.py_translate_np_dtype,"def translate_np_dtype(dt: np.dtype) -> Tuple[builtins.str, int]:
""""""
Split numpy dtype dt into its kind and byte size, raising
TypeError for unsupported dtypes.
Raises
------
TypeError
Raised if the dtype is not in supported dtypes or if
dt is not a np.dtype
""""""
dt = _as_dtype(dt)
check_np_dtype(dt)
trans = {""i"": ""int"", ""f"": ""float"", ""b"": ""bool"", ""u"": ""uint"", ""U"": ""str"", ""c"": ""complex""}
kind = trans[dt.kind]
return kind, dt.itemsize
","['dtype', 'dtype']",2,[],/dtypes.py_translate_np_dtype
835,/home/amandapotts/git/arkouda/arkouda/dtypes.py_resolve_scalar_dtype,"def resolve_scalar_dtype(val: object) -> str:  # type: ignore
""""""
Try to infer what dtype arkouda_server should treat val as.
""""""
if isinstance(val, builtins.bool) or (
hasattr(val, ""dtype"") and cast(np.bool_, val).dtype.kind == ""b""
):
return ""bool""
elif isinstance(val, int) or (hasattr(val, ""dtype"") and cast(np.uint, val).dtype.kind in ""ui""):
if isSupportedInt(val) and val >= 2**64:  # type: ignore
return ""bigint""
elif isinstance(val, np.uint64) or val >= 2**63:  # type: ignore
return ""uint64""
else:
return ""int64""
elif isinstance(val, float) or (hasattr(val, ""dtype"") and cast(np.float_, val).dtype.kind == ""f""):
return ""float64""
elif isinstance(val, complex) or (hasattr(val, ""dtype"") and cast(np.float_, val).dtype.kind == ""c""):
return ""float64""  # TODO: actually support complex values in the backend
elif isinstance(val, builtins.str) or isinstance(val, np.str_):
return ""str""
elif hasattr(val, ""dtype""):
return cast(np.dtype, val).name
else:
return builtins.str(type(val))
","['bool_', 'uint', 'uint64', 'float_', 'float_', 'str_', 'dtype']",7,[],/dtypes.py_resolve_scalar_dtype
836,/home/amandapotts/git/arkouda/arkouda/dtypes.py_get_byteorder,"def get_byteorder(dt: np.dtype) -> str:
""""""
Get a concrete byteorder (turns '=' into '<' or '>')
""""""
if dt.byteorder == ""="":
if sys.byteorder == ""little"":
return ""<""
elif sys.byteorder == ""big"":
return "">""
else:
raise ValueError(""Client byteorder must be 'little' or 'big'"")
else:
return dt.byteorder
",['dtype'],1,[],/dtypes.py_get_byteorder
837,/home/amandapotts/git/arkouda/arkouda/dtypes.py_get_server_byteorder,"def get_server_byteorder() -> str:
""""""
Get the server's byteorder
""""""
from arkouda.client import get_config
order = get_config()[""byteorder""]
if order not in (""little"", ""big""):
raise ValueError(""Server byteorder must be 'little' or 'big'"")
return cast(""str"", order)
",[],0,[],/dtypes.py_get_server_byteorder
838,/home/amandapotts/git/arkouda/arkouda/dataframe.py_groupby_operators,"def groupby_operators(cls):
for name in GROUPBY_REDUCTION_TYPES:
setattr(cls, name, cls._make_aggop(name))
return cls
",[],0,[],/dataframe.py_groupby_operators
839,/home/amandapotts/git/arkouda/arkouda/dataframe.py___init__,"def __init__(self, gb, df, gb_key_names=None, as_index=True):
self.gb = gb
self.df = df
self.gb_key_names = gb_key_names
self.as_index = as_index
for attr in [""nkeys"", ""permutation"", ""unique_keys"", ""segments""]:
setattr(self, attr, getattr(gb, attr))
",[],0,[],/dataframe.py___init__
840,/home/amandapotts/git/arkouda/arkouda/dataframe.py__make_aggop,"def _make_aggop(cls, opname):
numerical_dtypes = [akfloat64, akint64, akuint64]
",[],0,[],/dataframe.py__make_aggop
841,/home/amandapotts/git/arkouda/arkouda/dataframe.py_aggop,"def aggop(self, colnames=None):
""""""
Aggregate the operation, with the grouped column(s) values as keys.
Parameters
----------
colnames : (list of) str, default=None
Column name or list of column names to compute the aggregation over.
Returns
-------
arkouda.dataframe.DataFrame
""""""
if colnames is None:
colnames = list(self.df.data.keys())
elif isinstance(colnames, str):
colnames = [colnames]
colnames = [
c
for c in colnames
if (
(self.df.data[c].dtype.type in numerical_dtypes)
or isinstance(self.df.data[c].dtype, BigInt)
)
and (
(isinstance(self.gb_key_names, str) and (c != self.gb_key_names))
or (isinstance(self.gb_key_names, list) and c not in self.gb_key_names)
)
]
if isinstance(colnames, List):
if isinstance(self.gb_key_names, str):
return DataFrame(
{c: self.gb.aggregate(self.df.data[c], opname)[1] for c in colnames},
index=Index(self.gb.unique_keys, name=self.gb_key_names),
)
elif isinstance(self.gb_key_names, list) and len(self.gb_key_names) == 1:
return DataFrame(
{c: self.gb.aggregate(self.df.data[c], opname)[1] for c in colnames},
index=Index(self.gb.unique_keys, name=self.gb_key_names[0]),
)
elif isinstance(self.gb_key_names, list):
column_dict = dict(zip(self.gb_key_names, self.unique_keys))
for c in colnames:
column_dict[c] = self.gb.aggregate(self.df.data[c], opname)[1]
return DataFrame(column_dict)
else:
return None
",[],0,[],/dataframe.py_aggop
842,/home/amandapotts/git/arkouda/arkouda/dataframe.py_count,"def count(self, as_series=None):
""""""
Compute the count of each value as the total number of rows, including NaN values.
This is an alias for size(), and may change in the future.
Parameters
----------
as_series : bool, default=None
Indicates whether to return arkouda.dataframe.DataFrame (if as_series = False) or
arkouda.series.Series (if as_series = True)
Returns
-------
arkouda.dataframe.DataFrame or arkouda.series.Series
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({""A"":[1,2,2,3],""B"":[3,4,5,6]})
>>> display(df)
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   1 |   3 |
+----+-----+-----+
|  1 |   2 |   4 |
+----+-----+-----+
|  2 |   2 |   5 |
+----+-----+-----+
|  3 |   3 |   6 |
+----+-----+-----+
>>> df.groupby(""A"").count(as_series = False)
+----+---------+
|    |   count |
+====+=========+
|  0 |       1 |
+----+---------+
|  1 |       2 |
+----+---------+
|  2 |       1 |
+----+---------+
""""""
if as_series is True or (as_series is None and self.as_index is True):
return self._return_agg_series(self.gb.count())
else:
return self._return_agg_dataframe(self.gb.count(), ""count"")
",[],0,[],/dataframe.py_count
843,/home/amandapotts/git/arkouda/arkouda/dataframe.py_size,"def size(self, as_series=None, sort_index=True):
""""""
Compute the size of each value as the total number of rows, including NaN values.
Parameters
----------
as_series : bool, default=None
Indicates whether to return arkouda.dataframe.DataFrame (if as_series = False) or
arkouda.series.Series (if as_series = True)
sort_index : bool, default=True
If True, results will be returned with index values sorted in ascending order.
Returns
-------
arkouda.dataframe.DataFrame or arkouda.series.Series
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({""A"":[1,2,2,3],""B"":[3,4,5,6]})
>>> display(df)
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   1 |   3 |
+----+-----+-----+
|  1 |   2 |   4 |
+----+-----+-----+
|  2 |   2 |   5 |
+----+-----+-----+
|  3 |   3 |   6 |
+----+-----+-----+
>>> df.groupby(""A"").size(as_series = False)
+----+---------+
|    |   size  |
+====+=========+
|  0 |       1 |
+----+---------+
|  1 |       2 |
+----+---------+
|  2 |       1 |
+----+---------+
""""""
if as_series is True or (as_series is None and self.as_index is True):
return self._return_agg_series(self.gb.size(), sort_index=sort_index)
else:
return self._return_agg_dataframe(self.gb.size(), ""size"", sort_index=sort_index)
",[],0,[],/dataframe.py_size
844,/home/amandapotts/git/arkouda/arkouda/dataframe.py__return_agg_series,"def _return_agg_series(self, values, sort_index=True):
if self.as_index is True:
if isinstance(self.gb_key_names, str):
series = Series(values, index=Index(self.gb.unique_keys, name=self.gb_key_names))
elif isinstance(self.gb_key_names, list) and len(self.gb_key_names) == 1:
series = Series(values, index=Index(self.gb.unique_keys, name=self.gb_key_names[0]))
elif isinstance(self.gb_key_names, list) and len(self.gb_key_names) > 1:
from arkouda.index import MultiIndex
series = Series(
values,
index=MultiIndex(self.gb.unique_keys, names=self.gb_key_names),
)
else:
series = Series(values)
if sort_index is True:
series = series.sort_index()
return series
",[],0,[],/dataframe.py__return_agg_series
845,/home/amandapotts/git/arkouda/arkouda/dataframe.py__return_agg_dataframe,"def _return_agg_dataframe(self, values, name, sort_index=True):
if isinstance(self.gb_key_names, str):
if self.as_index is True:
df = DataFrame(
{name: values[1]},
index=Index(self.gb.unique_keys, name=self.gb_key_names),
)
else:
df = DataFrame({self.gb_key_names: self.gb.unique_keys, name: values[1]})
if sort_index is True:
df = df.sort_index()
return df
elif len(self.gb_key_names) == 1:
if self.as_index is True:
df = DataFrame(
{name: values[1]},
index=Index(self.gb.unique_keys, name=self.gb_key_names[0]),
)
else:
df = DataFrame(
{self.gb_key_names[0]: self.gb.unique_keys, name: values[1]},
)
if sort_index is True:
df = df.sort_index()
return df
else:
return Series(values).to_dataframe(index_labels=self.gb_key_names, value_label=name)
",[],0,[],/dataframe.py__return_agg_dataframe
846,/home/amandapotts/git/arkouda/arkouda/dataframe.py_diff,"def diff(self, colname):
""""""
Create a difference aggregate for the given column.
For each group, the difference between successive values is calculated.
Aggregate operations (mean,min,max,std,var) can be done on the results.
Parameters
----------
colname:  str
Name of the column to compute the difference on.
Returns
-------
DiffAggregate
Object containing the differences, which can be aggregated.
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({""A"":[1,2,2,2,3,3],""B"":[3,9,11,27,86,100]})
>>> display(df)
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   1 |   3 |
+----+-----+-----+
|  1 |   2 |   9 |
+----+-----+-----+
|  2 |   2 |  11 |
+----+-----+-----+
|  3 |   2 |  27 |
+----+-----+-----+
|  4 |   3 |  86 |
+----+-----+-----+
|  5 |   3 | 100 |
+----+-----+-----+
>>> gb = df.groupby(""A"")
>>> gb.diff(""B"").values
array([nan nan 2.00000000000000000 16.00000000000000000 nan 14.00000000000000000])
""""""
return DiffAggregate(self.gb, self.df.data[colname])
",[],0,[],/dataframe.py_diff
847,/home/amandapotts/git/arkouda/arkouda/dataframe.py_broadcast,"def broadcast(self, x, permute=True):
""""""
Fill each group’s segment with a constant value.
Parameters
----------
x :  Series or pdarray
The values to put in each group’s segment.
permute : bool, default=True
If True (default), permute broadcast values back to the
ordering of the original array on which GroupBy was called.
If False, the broadcast values are grouped by value.
Returns
-------
arkouda.series.Series
A Series with the Index of the original frame and the values of the broadcast.
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> from arkouda.dataframe import GroupBy
>>> df = ak.DataFrame({""A"":[1,2,2,3],""B"":[3,4,5,6]})
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   1 |   3 |
+----+-----+-----+
|  1 |   2 |   4 |
+----+-----+-----+
|  2 |   2 |   5 |
+----+-----+-----+
|  3 |   3 |   6 |
+----+-----+-----+
>>> gb = df.groupby(""A"")
>>> x = ak.array([10,11,12])
>>> s = GroupBy.broadcast(gb, x)
>>> df[""C""] = s.values
>>> display(df)
+----+-----+-----+-----+
|    |   A |   B |   C |
+====+=====+=====+=====+
|  0 |   1 |   3 |  10 |
+----+-----+-----+-----+
|  1 |   2 |   4 |  11 |
+----+-----+-----+-----+
|  2 |   2 |   5 |  11 |
+----+-----+-----+-----+
|  3 |   3 |   6 |  12 |
+----+-----+-----+-----+
""""""
if isinstance(x, Series):
data = self.gb.broadcast(x.values, permute=permute)
else:
data = self.gb.broadcast(x, permute=permute)
return Series(data=data, index=self.df.index)
",[],0,[],/dataframe.py_broadcast
848,/home/amandapotts/git/arkouda/arkouda/dataframe.py___init__,"def __init__(self, gb, series):
self.gb = gb
values = zeros(len(series), ""float64"")
series_permuted = series[gb.permutation]
values[1:] = akcast(series_permuted[1:] - series_permuted[:-1], ""float64"")
values[gb.segments] = np.nan
self.values = values
",['nan'],1,[],/dataframe.py___init__
849,/home/amandapotts/git/arkouda/arkouda/dataframe.py__make_aggop,"def _make_aggop(cls, opname):
",[],0,[],/dataframe.py__make_aggop
850,/home/amandapotts/git/arkouda/arkouda/dataframe.py_aggop,"def aggop(self):
return Series(self.gb.aggregate(self.values, opname))
",[],0,[],/dataframe.py_aggop
851,/home/amandapotts/git/arkouda/arkouda/dataframe.py___init__,"def __init__(self, initialdata=None, index=None, columns=None):
super().__init__()
self.registered_name = None
if isinstance(initialdata, DataFrame):
self._nrows = initialdata._nrows
self._bytes = initialdata._bytes
self._empty = initialdata._empty
self._columns = initialdata._columns
if index is None:
self._set_index(initialdata.index)
else:
self._set_index(index)
self.data = initialdata.data
self.update_nrows()
return
elif isinstance(initialdata, pd.DataFrame):
self._nrows = initialdata.shape[0]
self._bytes = 0
self._empty = initialdata.empty
self._columns = initialdata.columns.tolist()
if index is None:
self._set_index(initialdata.index.values.tolist())
else:
self._set_index(index)
self.data = {}
for key in initialdata.columns:
self.data[key] = (
SegArray.from_multi_array([array(r) for r in initialdata[key]])
if isinstance(initialdata[key][0], (list, np.ndarray))
else array(initialdata[key])
)
self.data.update()
return
self._nrows = 0
self._bytes = 0
self._empty = True
self._columns = []
self._set_index(index)
if initialdata is not None:
sizes = set()
if isinstance(initialdata, dict):
for key, val in initialdata.items():
if isinstance(val, (list, tuple)):
val = array(val)
if not isinstance(val, self._COLUMN_CLASSES):
raise ValueError(f""Values must be one of {self._COLUMN_CLASSES}."")
if key.lower() == ""index"":
self._set_index(val)
continue
sizes.add(val.size)
if len(sizes) > 1:
raise ValueError(""Input arrays must have equal size."")
self._empty = False
UserDict.__setitem__(self, key, val)
self._columns.append(key)
elif isinstance(initialdata, list):
keys = []
if columns is not None:
if any(not isinstance(label, str) for label in columns):
raise TypeError(""Column labels must be strings."")
if len(columns) != len(initialdata):
raise ValueError(""Must have as many labels as columns"")
keys = columns
else:
keys = [str(x) for x in range(len(initialdata))]
for key, col in zip(keys, initialdata):
if isinstance(col, (list, tuple)):
col = array(col)
if not isinstance(col, self._COLUMN_CLASSES):
raise ValueError(f""Values must be one of {self._COLUMN_CLASSES}."")
sizes.add(col.size)
if len(sizes) > 1:
raise ValueError(""Input arrays must have equal size."")
self._empty = False
UserDict.__setitem__(self, key, col)
self._columns.append(key)
else:
raise ValueError(f""Initialize with dict or list of {self._COLUMN_CLASSES}."")
if len(sizes) > 0:
self._nrows = sizes.pop()
if self.index is None:
self._set_index(arange(self._nrows))
else:
self._set_index(index)
self.update_nrows()
",['ndarray'],1,[],/dataframe.py___init__
852,/home/amandapotts/git/arkouda/arkouda/dataframe.py___getattr__,"def __getattr__(self, key):
if key not in self.columns:
raise AttributeError(f""Attribute {key} not found"")
return Series(data=self[key], index=self.index.index)
",[],0,[],/dataframe.py___getattr__
853,/home/amandapotts/git/arkouda/arkouda/dataframe.py___dir__,"def __dir__(self):
return dir(DataFrame) + self.columns
",[],0,[],/dataframe.py___dir__
854,/home/amandapotts/git/arkouda/arkouda/dataframe.py___delitem__,"def __delitem__(self, key):
UserDict.__delitem__(self, key)
self._columns.remove(key)
if len(self._columns) == 0:
self._set_index(None)
self._empty = True
self.update_nrows()
",[],0,[],/dataframe.py___delitem__
855,/home/amandapotts/git/arkouda/arkouda/dataframe.py___getitem__,"def __getitem__(self, key):
if isinstance(key, Series):
key = key.values
if isinstance(key, pdarray):
if key.dtype == akbool:
key = arange(key.size)[key]
result = {}
for k in self._columns:
result[k] = UserDict.__getitem__(self, k)[key]
return DataFrame(initialdata=result, index=self.index.index[key])
if isinstance(key, (list, tuple)):
result = DataFrame()
if len(key) <= 0:
return result
if len({type(x) for x in key}) > 1:
raise TypeError(""Invalid selector: too many types in list."")
if isinstance(key[0], str):
for k in key:
result.data[k] = UserDict.__getitem__(self, k)
result._columns.append(k)
result._empty = False
result._set_index(self.index)  # column lens remain the same. Copy the indexing
return result
else:
raise TypeError(
""DataFrames only support lists for column indexing. ""
""All list entries must be of type str.""
)
if isinstance(key, int):
result = {}
row = array([key])
for k in self._columns:
result[k] = (UserDict.__getitem__(self, k)[row])[0]
return Row(result)
elif isinstance(key, str):
if key not in self.keys():
raise KeyError(f""Invalid column name '{key}'."")
return UserDict.__getitem__(self, key)
elif isinstance(key, slice):
rtn_data = {}
s = key
for k in self._columns:
rtn_data[k] = UserDict.__getitem__(self, k)[s]
return DataFrame(initialdata=rtn_data, index=self.index.index[arange(self._nrows)[s]])
else:
raise IndexError(""Invalid selector: unknown error."")
",[],0,[],/dataframe.py___getitem__
856,/home/amandapotts/git/arkouda/arkouda/dataframe.py___setitem__,"def __setitem__(self, key, value):
self.update_nrows()
add_index = False
if self._empty:
add_index = True
if isinstance(key, int):
for k in self._columns:
if isinstance(self.data[k], Strings):
raise ValueError(
""This DataFrame has a column of type ak.Strings
"" so this DataFrame is immutable. This feature could change""
"" if arkouda supports mutable Strings in the future.""
)
if self._empty:
raise ValueError(""Initial data must be dict of arkouda arrays."")
elif not isinstance(value, (dict, UserDict)):
raise ValueError(""Expected dict or Row type."")
elif key >= self._nrows:
raise KeyError(""The row index is out of range."")
else:
for k, v in value.items():
if k == ""index"":
continue
self[k][key] = v
elif isinstance(key, str):
if not isinstance(value, self._COLUMN_CLASSES):
raise ValueError(f""Column must be one of {self._COLUMN_CLASSES}."")
elif self._nrows is not None and self._nrows != value.size:
raise ValueError(f""Expected size {self._nrows} but received size {value.size}."")
else:
self._empty = False
UserDict.__setitem__(self, key, value)
if key not in self._columns:
self._columns.append(key)
else:
raise ValueError(""No valid data received."")
if add_index:
self.update_nrows()
self._set_index(arange(self._nrows))
",[],0,[],/dataframe.py___setitem__
857,/home/amandapotts/git/arkouda/arkouda/dataframe.py___len__,"def __len__(self):
""""""
Return the number of rows.
""""""
return self._nrows
",[],0,[],/dataframe.py___len__
858,/home/amandapotts/git/arkouda/arkouda/dataframe.py__ncols,"def _ncols(self):
""""""
Number of columns.
If index appears, we now want to utilize this
because the actual index has been moved to a property
""""""
return len(self._columns)
",[],0,[],/dataframe.py__ncols
859,/home/amandapotts/git/arkouda/arkouda/dataframe.py___str__,"def __str__(self):
""""""
Returns a summary string of this dataframe.
""""""
self.update_nrows()
if self._empty:
return ""DataFrame([ -- ][ 0 rows : 0 B])""
keys = [str(key) for key in list(self._columns)]
keys = [(""'"" + key + ""'"") for key in keys]
keystr = "", "".join(keys)
mem = self.memory_usage()
if self._bytes < 1024:
mem = self.memory_usage(unit=""B"")
elif self._bytes < 1024**2:
mem = self.memory_usage(unit=""KB"")
elif self._bytes < 1024**3:
mem = self.memory_usage(unit=""MB"")
else:
mem = self.memory_usage(unit=""GB"")
rows = "" rows""
if self._nrows == 1:
rows = "" row""
return ""DataFrame(["" + keystr + ""], {:,}"".format(self._nrows) + rows + "", "" + str(mem) + "")""
",[],0,[],/dataframe.py___str__
860,/home/amandapotts/git/arkouda/arkouda/dataframe.py__get_head_tail,"def _get_head_tail(self):
if self._empty:
return pd.DataFrame()
self.update_nrows()
maxrows = pd.get_option(""display.max_rows"")
if self._nrows <= maxrows:
newdf = DataFrame()
for col in self._columns:
if isinstance(self[col], Categorical):
newdf[col] = self[col].categories[self[col].codes]
else:
newdf[col] = self[col]
newdf._set_index(self.index)
return newdf.to_pandas(retain_index=True)
idx = array(
list(range(maxrows // 2 + 1)) + list(range(self._nrows - (maxrows // 2), self._nrows))
)
newdf = DataFrame()
for col in self._columns:
if isinstance(self[col], Categorical):
newdf[col] = self[col].categories[self[col].codes[idx]]
else:
newdf[col] = self[col][idx]
newdf._set_index(self.index.index[idx])
return newdf.to_pandas(retain_index=True)
",[],0,[],/dataframe.py__get_head_tail
861,/home/amandapotts/git/arkouda/arkouda/dataframe.py__get_head_tail_server,"def _get_head_tail_server(self):
if self._empty:
return pd.DataFrame()
self.update_nrows()
maxrows = pd.get_option(""display.max_rows"")
if self._nrows <= maxrows:
newdf = DataFrame()
for col in self._columns:
if isinstance(self[col], Categorical):
newdf[col] = self[col].categories[self[col].codes]
else:
newdf[col] = self[col]
newdf._set_index(self.index)
return newdf.to_pandas(retain_index=True)
idx = array(
list(range(maxrows // 2 + 1)) + list(range(self._nrows - (maxrows // 2), self._nrows))
)
msg_list = []
for col in self._columns:
if isinstance(self[col], Categorical):
msg_list.append(f""Categorical+{col}+{self[col].codes.name}+{self[col].categories.name}"")
elif isinstance(self[col], SegArray):
msg_list.append(f""SegArray+{col}+{self[col].segments.name}+{self[col].values.name}"")
elif isinstance(self[col], Strings):
msg_list.append(f""Strings+{col}+{self[col].name}"")
elif isinstance(self[col], Fields):
msg_list.append(f""Fields+{col}+{self[col].name}"")
elif isinstance(self[col], IPv4):
msg_list.append(f""IPv4+{col}+{self[col].name}"")
elif isinstance(self[col], Datetime):
msg_list.append(f""Datetime+{col}+{self[col].name}"")
elif isinstance(self[col], BitVector):
msg_list.append(f""BitVector+{col}+{self[col].name}"")
else:
msg_list.append(f""pdarray+{col}+{self[col].name}"")
repMsg = cast(
str,
generic_msg(
cmd=""dataframe_idx"",
args={
""size"": len(msg_list),
""idx_name"": idx.name,
""columns"": msg_list,
},
),
)
msgList = json.loads(repMsg)
df_dict = {}
for m in msgList:
msg = m.split(""+"", 2)
t = msg[0]
if t == ""Strings"":
df_dict[msg[1]] = Strings.from_return_msg(msg[2])
elif t == ""SegArray"":
eles = msg[2].split(""+"")
df_dict[msg[1]] = SegArray(create_pdarray(eles[0]), create_pdarray(eles[1]))
elif t == ""Fields"":
df_dict[msg[1]] = Fields(
create_pdarray(msg[2]),
self[msg[1]].names,
MSB_left=self[msg[1]].MSB_left,
pad=self[msg[1]].padchar,
separator=self[msg[1]].separator,
show_int=self[msg[1]].show_int,
)
elif t == ""IPv4"":
df_dict[msg[1]] = IPv4(create_pdarray(msg[2]))
elif t == ""Datetime"":
df_dict[msg[1]] = Datetime(create_pdarray(msg[2]))
elif t == ""BitVector"":
df_dict[msg[1]] = BitVector(
create_pdarray(msg[2]),
width=self[msg[1]].width,
reverse=self[msg[1]].reverse,
)
else:
df_dict[msg[1]] = create_pdarray(msg[2])
new_df = DataFrame(df_dict)
new_df._set_index(self.index.index[idx])
return new_df.to_pandas(retain_index=True)[self._columns]
",[],0,[],/dataframe.py__get_head_tail_server
862,/home/amandapotts/git/arkouda/arkouda/dataframe.py_transfer,"def transfer(self, hostname, port):
""""""
Sends a DataFrame to a different Arkouda server.
Parameters
----------
hostname : str
The hostname where the Arkouda server intended to
receive the DataFrame is running.
port : int_scalars
The port to send the array over. This needs to be an
open port (i.e., not one that the Arkouda server is
running on). This will open up `numLocales` ports,
each of which in succession, so will use ports of the
range {port..(port+numLocales)} (e.g., running an
Arkouda server of 4 nodes, port 1234 is passed as
`port`, Arkouda will use ports 1234, 1235, 1236,
and 1237 to send the array data).
This port much match the port passed to the call to
`ak.receive_array()`.
Returns
-------
str
A message indicating a complete transfer.
Raises
------
ValueError
Raised if the op is not within the pdarray.BinOps set
TypeError
Raised if other is not a pdarray or the pdarray.dtype is not
a supported dtype
""""""
self.update_nrows()
idx = self._index
msg_list = []
for col in self._columns:
if isinstance(self[col], Categorical):
msg_list.append(
f""Categorical+{col}+{self[col].codes.name} \
+{self[col].categories.name}+{self[col]._akNAcode.name}""
)
elif isinstance(self[col], SegArray):
msg_list.append(f""SegArray+{col}+{self[col].segments.name}+{self[col].values.name}"")
elif isinstance(self[col], Strings):
msg_list.append(f""Strings+{col}+{self[col].name}"")
elif isinstance(self[col], Fields):
msg_list.append(f""Fields+{col}+{self[col].name}"")
elif isinstance(self[col], IPv4):
msg_list.append(f""IPv4+{col}+{self[col].name}"")
elif isinstance(self[col], Datetime):
msg_list.append(f""Datetime+{col}+{self[col].name}"")
elif isinstance(self[col], BitVector):
msg_list.append(f""BitVector+{col}+{self[col].name}"")
else:
msg_list.append(f""pdarray+{col}+{self[col].name}"")
repMsg = cast(
str,
generic_msg(
cmd=""sendDataframe"",
args={
""size"": len(msg_list),
""idx_name"": idx.name,
""columns"": msg_list,
""hostname"": hostname,
""port"": port,
},
),
)
return repMsg
",[],0,[],/dataframe.py_transfer
863,/home/amandapotts/git/arkouda/arkouda/dataframe.py__shape_str,"def _shape_str(self):
return f""{self._nrows} rows x {self._ncols()} columns""
",[],0,[],/dataframe.py__shape_str
864,/home/amandapotts/git/arkouda/arkouda/dataframe.py___repr__,"def __repr__(self):
""""""
Return ascii-formatted version of the dataframe.
""""""
prt = self._get_head_tail_server()
with pd.option_context(""display.show_dimensions"", False):
retval = prt.__repr__()
retval += "" ("" + self._shape_str() + "")""
return retval
",[],0,[],/dataframe.py___repr__
865,/home/amandapotts/git/arkouda/arkouda/dataframe.py__repr_html_,"def _repr_html_(self):
""""""
Return html-formatted version of the dataframe.
""""""
prt = self._get_head_tail_server()
with pd.option_context(""display.show_dimensions"", False):
retval = prt._repr_html_()
retval += ""<p>"" + self._shape_str() + ""</p>""
return retval
",[],0,[],/dataframe.py__repr_html_
866,/home/amandapotts/git/arkouda/arkouda/dataframe.py__ipython_key_completions_,"def _ipython_key_completions_(self):
return self._columns
",[],0,[],/dataframe.py__ipython_key_completions_
867,/home/amandapotts/git/arkouda/arkouda/dataframe.py_from_pandas,"def from_pandas(cls, pd_df):
""""""
Copy the data from a pandas DataFrame into a new arkouda.dataframe.DataFrame.
Parameters
----------
pd_df : pandas.DataFrame
A pandas DataFrame to convert.
Returns
-------
arkouda.dataframe.DataFrame
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> import pandas as pd
>>> pd_df = pd.DataFrame({""A"":[1,2],""B"":[3,4]})
>>> type(pd_df)
pandas.core.frame.DataFrame
>>> display(pd_df)
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   1 |   3 |
+----+-----+-----+
|  1 |   2 |   4 |
+----+-----+-----+
>>> ak_df = DataFrame.from_pandas(pd_df)
>>> type(ak_df)
arkouda.dataframe.DataFrame
>>> display(ak_df)
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   1 |   3 |
+----+-----+-----+
|  1 |   2 |   4 |
+----+-----+-----+
""""""
return DataFrame(initialdata=pd_df)
",[],0,[],/dataframe.py_from_pandas
868,/home/amandapotts/git/arkouda/arkouda/dataframe.py__drop_column,"def _drop_column(self, keys):
""""""
Drop a column or columns from the dataframe, in-place.
keys : list
The labels to be dropped on the given axis
""""""
for key in keys:
del self[key]
",[],0,[],/dataframe.py__drop_column
869,/home/amandapotts/git/arkouda/arkouda/dataframe.py__drop_row,"def _drop_row(self, keys):
""""""
Drop a row or rows from the dataframe, in-place.
keys : list
The indexes to be dropped on the given axis
""""""
idx_list = []
last_idx = -1
keys.sort()
for k in keys:
if not isinstance(k, int):
raise TypeError(""Index keys must be integers."")
idx_list.append(self.index.index[(last_idx + 1) : k])
last_idx = k
idx_list.append(self.index.index[(last_idx + 1) :])
idx_to_keep = concatenate(idx_list)
for key in self.keys():
UserDict.__setitem__(self, key, self[key][idx_to_keep])
self._set_index(idx_to_keep)
",[],0,[],/dataframe.py__drop_row
870,/home/amandapotts/git/arkouda/arkouda/dataframe.py_drop,"def drop(
self,
keys: Union[str, int, List[Union[str, int]]],
axis: Union[str, int] = 0,
inplace: bool = False,
",[],0,[],/dataframe.py_drop
871,/home/amandapotts/git/arkouda/arkouda/dataframe.py_drop_duplicates,"def drop_duplicates(self, subset=None, keep=""first""):
""""""
Drops duplcated rows and returns resulting DataFrame.
If a subset of the columns are provided then only one instance of each
duplicated row will be returned (keep determines which row).
Parameters
----------
subset : Iterable
Iterable of column names to use to dedupe.
keep : {'first', 'last'}, default='first'
Determines which duplicates (if any) to keep.
Returns
-------
arkouda.dataframe.DataFrame
DataFrame with duplicates removed.
Example
-------
>>> df = ak.DataFrame({'col1': [1, 2, 2, 3], 'col2': [4, 5, 5, 6]})
>>> display(df)
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |      4 |
+----+--------+--------+
|  1 |      2 |      5 |
+----+--------+--------+
|  2 |      2 |      5 |
+----+--------+--------+
|  3 |      3 |      6 |
+----+--------+--------+
>>> df.drop_duplicates()
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |      4 |
+----+--------+--------+
|  1 |      2 |      5 |
+----+--------+--------+
|  2 |      3 |      6 |
+----+--------+--------+
""""""
if self._empty:
return self
if not subset:
subset = self._columns
if len(subset) == 1:
if not subset[0] in self.data:
raise KeyError(f""{subset[0]} is not a column in the DataFrame."")
gp = akGroupBy(self.data[subset[0]])
else:
for col in subset:
if col not in self.data:
raise KeyError(f""{subset[0]} is not a column in the DataFrame."")
gp = akGroupBy([self.data[col] for col in subset])
if keep == ""last"":
_segment_ends = concatenate([gp.segments[1:] - 1, array([gp.permutation.size - 1])])
return self[gp.permutation[_segment_ends]]
else:
return self[gp.permutation[gp.segments]]
",[],0,[],/dataframe.py_drop_duplicates
872,/home/amandapotts/git/arkouda/arkouda/dataframe.py_size,"def size(self):
""""""
Returns the number of bytes on the arkouda server.
Returns
-------
int
The number of bytes on the arkouda server.
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]})
>>> df
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |      4 |
+----+--------+--------+
|  1 |      2 |      5 |
+----+--------+--------+
|  2 |      3 |      6 |
+----+--------+--------+
>>> df.size
6
""""""
self.update_nrows()
if self._nrows is None:
return 0
return self.shape[0] * self.shape[1]
",[],0,[],/dataframe.py_size
873,/home/amandapotts/git/arkouda/arkouda/dataframe.py_dtypes,"def dtypes(self):
""""""
The dtypes of the dataframe.
Returns
-------
dtypes :  arkouda.row.Row
The dtypes of the dataframe.
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({'col1': [1, 2], 'col2': [""a"", ""b""]})
>>> df
+----+--------+--------+
|    |   col1 | col2   |
+====+========+========+
|  0 |      1 | a      |
+----+--------+--------+
|  1 |      2 | b      |
+----+--------+--------+
>>> df.dtypes
+----+--------+
|keys| values |
+====+========+
|col1|  int64 |
+----+--------+
|col2|    str |
+----+--------+
""""""
dtypes = []
keys = []
for key, val in self.items():
keys.append(key)
if isinstance(val, pdarray):
dtypes.append(str(val.dtype))
elif isinstance(val, Strings):
dtypes.append(""str"")
elif isinstance(val, Categorical):
dtypes.append(""Categorical"")
elif isinstance(val, SegArray):
dtypes.append(""SegArray"")
else:
raise TypeError(f""Unsupported type encountered for ak.DataFrame, {type(val)}"")
res = Row({key: dtype for key, dtype in zip(keys, dtypes)})
return res
",[],0,[],/dataframe.py_dtypes
874,/home/amandapotts/git/arkouda/arkouda/dataframe.py_empty,"def empty(self):
""""""
Whether the dataframe is empty.
Returns
-------
bool
True if the dataframe is empty, otherwise False.
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({})
>>> df
0 rows x 0 columns
>>> df.empty
True
""""""
return self._empty
",[],0,[],/dataframe.py_empty
875,/home/amandapotts/git/arkouda/arkouda/dataframe.py_ndim,"def ndim(self):
return 2
",[],0,[],/dataframe.py_ndim
876,/home/amandapotts/git/arkouda/arkouda/dataframe.py_shape,"def shape(self):
""""""
The shape of the dataframe.
Returns
-------
tuple of int
Tuple of array dimensions.
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]})
>>> df
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |      4 |
+----+--------+--------+
|  1 |      2 |      5 |
+----+--------+--------+
|  2 |      3 |      6 |
+----+--------+--------+
>>> df.shape
(3, 2)
""""""
self.update_nrows()
num_cols = len(self._columns)
nrows = self._nrows
return (nrows, num_cols)
",[],0,[],/dataframe.py_shape
877,/home/amandapotts/git/arkouda/arkouda/dataframe.py_columns,"def columns(self):
""""""
A list of column names of the dataframe.
Returns
-------
list of str
A list of column names of the dataframe.
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({'col1': [1, 2], 'col2': [3, 4]})
>>> df
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |      3 |
+----+--------+--------+
|  1 |      2 |      4 |
+----+--------+--------+
>>> df.columns
['col1', 'col2']
""""""
return self._columns
",[],0,[],/dataframe.py_columns
878,/home/amandapotts/git/arkouda/arkouda/dataframe.py_index,"def index(self):
""""""
The index of the dataframe.
Returns
-------
arkouda.index.Index or arkouda.index.MultiIndex
The index of the dataframe.
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({'col1': [1, 2], 'col2': [3, 4]})
>>> df
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |      3 |
+----+--------+--------+
|  1 |      2 |      4 |
+----+--------+--------+
>>> df.index
Index(array([0 1]), dtype='int64')
""""""
return self._index
",[],0,[],/dataframe.py_index
879,/home/amandapotts/git/arkouda/arkouda/dataframe.py__set_index,"def _set_index(self, value):
if isinstance(value, Index) or value is None:
self._index = value
elif isinstance(value, (pdarray, Strings)):
self._index = Index(value)
elif isinstance(value, list):
self._index = Index(array(value))
else:
raise TypeError(
f""DataFrame Index can only be constructed from type ak.Index, pdarray or list.""
f"" {type(value)} provided.""
)
",[],0,[],/dataframe.py__set_index
880,/home/amandapotts/git/arkouda/arkouda/dataframe.py_reset_index,"def reset_index(self, size: bool = False, inplace: bool = False) -> Union[None, DataFrame]:
""""""
Set the index to an integer range.
Useful if this dataframe is the result of a slice operation from
another dataframe, or if you have permuted the rows and no longer need
to keep that ordering on the rows.
Parameters
----------
size : int
If size is passed, do not attempt to determine size based on
existing column sizes. Assume caller handles consistency correctly.
inplace: bool, default=False
When True, perform the operation on the calling object.
When False, return a new object.
Returns
-------
arkouda.dataframe.DataFrame or None
DateFrame when `inplace=False`
None when `inplace=True`.
NOTE
----------
Pandas adds a column 'index' to indicate the original index. Arkouda does not currently
support this behavior.
Example
-------
>>> df = ak.DataFrame({""A"": ak.array([1, 2, 3]), ""B"": ak.array([4, 5, 6])})
>>> display(df)
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   1 |   4 |
+----+-----+-----+
|  1 |   2 |   5 |
+----+-----+-----+
|  2 |   3 |   6 |
+----+-----+-----+
>>> perm_df = df[ak.array([0,2,1])]
>>> display(perm_df)
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   1 |   4 |
+----+-----+-----+
|  1 |   3 |   6 |
+----+-----+-----+
|  2 |   2 |   5 |
+----+-----+-----+
>>> perm_df.reset_index()
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   1 |   4 |
+----+-----+-----+
|  1 |   3 |   6 |
+----+-----+-----+
|  2 |   2 |   5 |
+----+-----+-----+
""""""
obj = self if inplace else self.copy()
if not size:
obj.update_nrows()
obj._set_index(arange(obj._nrows))
else:
obj._set_index(arange(size))
if not inplace:
return obj
return None
",[],0,[],/dataframe.py_reset_index
881,/home/amandapotts/git/arkouda/arkouda/dataframe.py_info,"def info(self):
""""""
Returns a summary string of this dataframe.
Returns
-------
str
A summary string of this dataframe.
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({'col1': [1, 2], 'col2': [""a"", ""b""]})
>>> df
+----+--------+--------+
|    |   col1 | col2   |
+====+========+========+
|  0 |      1 | a      |
+----+--------+--------+
|  1 |      2 | b      |
+----+--------+--------+
>>> df.info
""DataFrame(['col1', 'col2'], 2 rows, 20 B)""
""""""
self.update_nrows()
if self._nrows is None:
return ""DataFrame([ -- ][ 0 rows : 0 B])""
keys = [str(key) for key in list(self._columns)]
keys = [(""'"" + key + ""'"") for key in keys]
keystr = "", "".join(keys)
mem = self.memory_usage()
if self._bytes < 1024:
mem = self.memory_usage(unit=""B"")
elif self._bytes < 1024**2:
mem = self.memory_usage(unit=""KB"")
elif self._bytes < 1024**3:
mem = self.memory_usage(unit=""MB"")
else:
mem = self.memory_usage(unit=""GB"")
rows = "" rows""
if self._nrows == 1:
rows = "" row""
return ""DataFrame(["" + keystr + ""], {:,}"".format(self._nrows) + rows + "", "" + str(mem) + "")""
",[],0,[],/dataframe.py_info
882,/home/amandapotts/git/arkouda/arkouda/dataframe.py_update_nrows,"def update_nrows(self):
""""""
Computes the number of rows on the arkouda server and updates the size parameter.
""""""
sizes = set()
for key, val in self.items():
if val is not None:
sizes.add(val.size)
if len(sizes) > 1:
raise ValueError(""Size mismatch in DataFrame columns."")
if len(sizes) == 0:
self._nrows = None
else:
self._nrows = sizes.pop()
",[],0,[],/dataframe.py_update_nrows
883,/home/amandapotts/git/arkouda/arkouda/dataframe.py__rename_column,"def _rename_column(
self, mapper: Union[Callable, Dict], inplace: bool = False
",[],0,[],/dataframe.py__rename_column
884,/home/amandapotts/git/arkouda/arkouda/dataframe.py__rename_index,"def _rename_index(self, mapper: Union[Callable, Dict], inplace: bool = False) -> Optional[DataFrame]:
""""""
Rename indexes within the dataframe
Parameters
----------
mapper : callable or dict-like
Function or dictionary mapping existing indexes to new indexes.
Nonexistent names will not raise an error.
inplace: bool, default=False
When True, perform the operation on the calling object.
When False, return a new object.
Returns
-------
arkouda.dataframe.DataFrame or None
DateFrame when `inplace=False`
None when `inplace=True`
See Also
-------
ak.DataFrame._rename_column
ak.DataFrame.rename
Notes
-----
This does not function exactly like pandas. The replacement value here must be
the same type as the existing value.
""""""
obj = self if inplace else self.copy()
if callable(mapper):
for i in range(obj.index.size):
oldval = obj.index[i]
newval = mapper(oldval)
if type(oldval) is not type(newval):
raise TypeError(""Replacement value must have the same type as the original value"")
obj.index.values[obj.index.values == oldval] = newval
elif isinstance(mapper, dict):
for key, val in mapper.items():
if type(key) is not type(val):
raise TypeError(""Replacement value must have the same type as the original value"")
obj.index.values[obj.index.values == key] = val
else:
raise TypeError(""Argument must be callable or dict-like"")
if not inplace:
return obj
return None
",[],0,[],/dataframe.py__rename_index
885,/home/amandapotts/git/arkouda/arkouda/dataframe.py_rename,"def rename(
self,
mapper: Optional[Union[Callable, Dict]] = None,
index: Optional[Union[Callable, Dict]] = None,
column: Optional[Union[Callable, Dict]] = None,
axis: Union[str, int] = 0,
inplace: bool = False,
",[],0,[],/dataframe.py_rename
886,/home/amandapotts/git/arkouda/arkouda/dataframe.py_append,"def append(self, other, ordered=True):
""""""
Concatenate data from 'other' onto the end of this DataFrame, in place.
Explicitly, use the arkouda concatenate function to append the data
from each column in other to the end of self. This operation is done
in place, in the sense that the underlying pdarrays are updated from
the result of the arkouda concatenate function, rather than returning
a new DataFrame object containing the result.
Parameters
----------
other : DataFrame
The DataFrame object whose data will be appended to this DataFrame.
ordered: bool, default=True
If False, allow rows to be interleaved for better performance (but
data within a row remains together). By default, append all rows
to the end, in input order.
Returns
-------
self
Appending occurs in-place, but result is returned for compatibility.
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df1 = ak.DataFrame({'col1': [1, 2], 'col2': [3, 4]})
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |      3 |
+----+--------+--------+
|  1 |      2 |      4 |
+----+--------+--------+
>>> df2 = ak.DataFrame({'col1': [3], 'col2': [5]})
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      3 |      5 |
+----+--------+--------+
>>> df1.append(df2)
>>> df1
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |      3 |
+----+--------+--------+
|  1 |      2 |      4 |
+----+--------+--------+
|  2 |      3 |      5 |
+----+--------+--------+
""""""
from arkouda.util import generic_concat as util_concatenate
if other.empty:
return self
self.update_nrows()
keyset = set(self._columns)
keylist = list(self._columns)
if self.empty:
self = other.copy()
elif keyset != set(other._columns):
raise KeyError(""Key mismatch
else:
tmp_data = {}
for key in keylist:
try:
tmp_data[key] = util_concatenate([self[key], other[key]], ordered=ordered)
except TypeError as e:
raise TypeError(
f""Incompatible types for column {key}: {type(self[key])} vs {type(other[key])}""
) from e
self.data = tmp_data
self.update_nrows()
self.reset_index(inplace=True)
self._empty = False
return self
",[],0,[],/dataframe.py_append
887,/home/amandapotts/git/arkouda/arkouda/dataframe.py__get_sample_object,"def _get_sample_object(
self,
objs: list[Series | DataFrame],
ndims: set[int],
keys,
names,
levels,
",[],0,[],/dataframe.py__get_sample_object
888,/home/amandapotts/git/arkouda/arkouda/dataframe.py_concat,"def concat(cls, items, ordered=True):
""""""
Essentially an append, but different formatting.
""""""
from arkouda.util import generic_concat as util_concatenate
if len(items) == 0:
return cls()
first = True
columnset = set()
columnlist = []
for df in items:
if df.empty:
continue
if first:
columnset = set(df._columns)
columnlist = df._columns
first = False
else:
if set(df._columns) != columnset:
raise KeyError(""Cannot concatenate DataFrames with mismatched columns"")
ret = cls()
for col in columnlist:
try:
ret[col] = util_concatenate([df[col] for df in items], ordered=ordered)
except TypeError:
raise TypeError(f""Incompatible types for column {col}"")
return ret
",[],0,[],/dataframe.py_concat
889,/home/amandapotts/git/arkouda/arkouda/dataframe.py_head,"def head(self, n=5):
""""""
Return the first `n` rows.
This function returns the first `n` rows of the the dataframe. It is
useful for quickly verifying data, for example, after sorting or
appending rows.
Parameters
----------
n : int, default = 5
Number of rows to select.
Returns
-------
arkouda.dataframe.DataFrame
The first `n` rows of the DataFrame.
See Also
--------
tail
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({'col1': ak.arange(10), 'col2': -1 * ak.arange(10)})
>>> display(df)
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      0 |      0 |
+----+--------+--------+
|  1 |      1 |     -1 |
+----+--------+--------+
|  2 |      2 |     -2 |
+----+--------+--------+
|  3 |      3 |     -3 |
+----+--------+--------+
|  4 |      4 |     -4 |
+----+--------+--------+
|  5 |      5 |     -5 |
+----+--------+--------+
|  6 |      6 |     -6 |
+----+--------+--------+
|  7 |      7 |     -7 |
+----+--------+--------+
|  8 |      8 |     -8 |
+----+--------+--------+
|  9 |      9 |     -9 |
+----+--------+--------+
>>> df.head()
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      0 |      0 |
+----+--------+--------+
|  1 |      1 |     -1 |
+----+--------+--------+
|  2 |      2 |     -2 |
+----+--------+--------+
|  3 |      3 |     -3 |
+----+--------+--------+
|  4 |      4 |     -4 |
+----+--------+--------+
>>> df.head(n=2)
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      0 |      0 |
+----+--------+--------+
|  1 |      1 |     -1 |
+----+--------+--------+
""""""
return self[:n]
",[],0,[],/dataframe.py_head
890,/home/amandapotts/git/arkouda/arkouda/dataframe.py_tail,"def tail(self, n=5):
""""""
Return the last `n` rows.
This function returns the last `n` rows for the dataframe. It is
useful for quickly testing if your object has the right type of data in
it.
Parameters
----------
n : int, default=5
Number of rows to select.
Returns
-------
arkouda.dataframe.DataFrame
The last `n` rows of the DataFrame.
See Also
--------
arkouda.dataframe.head
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({'col1': ak.arange(10), 'col2': -1 * ak.arange(10)})
>>> display(df)
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      0 |      0 |
+----+--------+--------+
|  1 |      1 |     -1 |
+----+--------+--------+
|  2 |      2 |     -2 |
+----+--------+--------+
|  3 |      3 |     -3 |
+----+--------+--------+
|  4 |      4 |     -4 |
+----+--------+--------+
|  5 |      5 |     -5 |
+----+--------+--------+
|  6 |      6 |     -6 |
+----+--------+--------+
|  7 |      7 |     -7 |
+----+--------+--------+
|  8 |      8 |     -8 |
+----+--------+--------+
|  9 |      9 |     -9 |
+----+--------+--------+
>>> df.tail()
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      5 |     -5 |
+----+--------+--------+
|  1 |      6 |     -6 |
+----+--------+--------+
|  2 |      7 |     -7 |
+----+--------+--------+
|  3 |      8 |     -8 |
+----+--------+--------+
|  4 |      9 |     -9 |
+----+--------+--------+
>>> df.tail(n=2)
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      8 |     -8 |
+----+--------+--------+
|  1 |      9 |     -9 |
+----+--------+--------+
""""""
self.update_nrows()
if self._nrows <= n:
return self
return self[self._nrows - n :]
",[],0,[],/dataframe.py_tail
891,/home/amandapotts/git/arkouda/arkouda/dataframe.py_sample,"def sample(self, n=5):
""""""
Return a random sample of `n` rows.
Parameters
----------
n : int, default=5
Number of rows to return.
Returns
-------
arkouda.dataframe.DataFrame
The sampled `n` rows of the DataFrame.
Example
-------
>>> df = ak.DataFrame({""A"": ak.arange(5), ""B"": -1 * ak.arange(5)})
>>> display(df)
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   0 |   0 |
+----+-----+-----+
|  1 |   1 |  -1 |
+----+-----+-----+
|  2 |   2 |  -2 |
+----+-----+-----+
|  3 |   3 |  -3 |
+----+-----+-----+
|  4 |   4 |  -4 |
+----+-----+-----+
Random output of size 3:
>>> df.sample(n=3)
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   0 |   0 |
+----+-----+-----+
|  1 |   1 |  -1 |
+----+-----+-----+
|  2 |   4 |  -4 |
+----+-----+-----+
""""""
self.update_nrows()
if self._nrows <= n:
return self
return self[array(random.sample(range(self._nrows), n))]
",[],0,[],/dataframe.py_sample
892,/home/amandapotts/git/arkouda/arkouda/dataframe.py_GroupBy,"def GroupBy(self, keys, use_series=False, as_index=True, dropna=True):
""""""
Group the dataframe by a column or a list of columns.
Parameters
----------
keys : str or list of str
An (ordered) list of column names or a single string to group by.
use_series : bool, default=False
If True, returns an arkouda.dataframe.GroupBy object.
Otherwise an arkouda.groupbyclass.GroupBy object.
as_index: bool, default=True
If True, groupby columns will be set as index
otherwise, the groupby columns will be treated as DataFrame columns.
dropna : bool, default=True
If True, and the groupby keys contain NaN values,
the NaN values together with the corresponding row will be dropped.
Otherwise, the rows corresponding to NaN values will be kept.
Returns
-------
arkouda.dataframe.GroupBy or arkouda.groupbyclass.GroupBy
If use_series = True, returns an arkouda.dataframe.GroupBy object.
Otherwise returns an arkouda.groupbyclass.GroupBy object.
See Also
--------
arkouda.GroupBy
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({'col1': [1.0, 1.0, 2.0, np.nan], 'col2': [4, 5, 6, 7]})
>>> df
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |      4 |
+----+--------+--------+
|  1 |      1 |      5 |
+----+--------+--------+
|  2 |      2 |      6 |
+----+--------+--------+
|  3 |    nan |      7 |
+----+--------+--------+
>>> df.GroupBy(""col1"")
<arkouda.groupbyclass.GroupBy at 0x7f2cf23e10c0>
>>> df.GroupBy(""col1"").size()
(array([1.00000000000000000 2.00000000000000000]), array([2 1]))
>>> df.GroupBy(""col1"",use_series=True)
col1
1.0    2
2.0    1
dtype: int64
>>> df.GroupBy(""col1"",use_series=True, as_index = False).size()
+----+--------+--------+
|    |   col1 |   size |
+====+========+========+
|  0 |      1 |      2 |
+----+--------+--------+
|  1 |      2 |      1 |
+----+--------+--------+
""""""
self.update_nrows()
if isinstance(keys, str):
cols = self.data[keys]
elif not isinstance(keys, (list, tuple)):
raise TypeError(""keys must be a column name or a list/tuple of column names"")
elif len(keys) == 1:
cols = self.data[keys[0]]
else:
cols = [self.data[col] for col in keys]
gb = akGroupBy(cols, dropna=dropna)
if use_series:
gb = GroupBy(gb, self, gb_key_names=keys, as_index=as_index)
return gb
",['nan'],1,[],/dataframe.py_GroupBy
893,/home/amandapotts/git/arkouda/arkouda/dataframe.py_memory_usage,"def memory_usage(self, unit=""GB""):
""""""
Print the size of this DataFrame.
Parameters
----------
unit : str, default = ""GB""
Unit to return. One of {'KB', 'MB', 'GB'}.
Returns
-------
int
The number of bytes used by this DataFrame in [unit]s.
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({'col1': ak.arange(1000), 'col2': ak.arange(1000)})
>>> df.memory_usage()
'0.00 GB'
>>> df.memory_usage(unit=""KB"")
'15 KB'
""""""
KB = 1024
MB = KB * KB
GB = MB * KB
self._bytes = 0
for key, val in self.items():
if isinstance(val, pdarray):
self._bytes += (val.dtype).itemsize * val.size
elif isinstance(val, Strings):
self._bytes += val.nbytes
if unit == ""B"":
return ""{:} B"".format(int(self._bytes))
elif unit == ""MB"":
return ""{:} MB"".format(int(self._bytes / MB))
elif unit == ""KB"":
return ""{:} KB"".format(int(self._bytes / KB))
return ""{:.2f} GB"".format(self._bytes / GB)
",[],0,[],/dataframe.py_memory_usage
894,/home/amandapotts/git/arkouda/arkouda/dataframe.py_to_pandas,"def to_pandas(self, datalimit=maxTransferBytes, retain_index=False):
""""""
Send this DataFrame to a pandas DataFrame.
Parameters
----------
datalimit : int, default=arkouda.client.maxTransferBytes
The maximum number size, in megabytes to transfer. The requested
DataFrame will be converted to a pandas DataFrame only if the
estimated size of the DataFrame does not exceed this value.
retain_index : bool, default=False
Normally, to_pandas() creates a new range index object. If you want
to keep the index column, set this to True.
Returns
-------
pandas.DataFrame
The result of converting this DataFrame to a pandas DataFrame.
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> ak_df = ak.DataFrame({""A"": ak.arange(2), ""B"": -1 * ak.arange(2)})
>>> type(ak_df)
arkouda.dataframe.DataFrame
>>> display(ak_df)
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   0 |   0 |
+----+-----+-----+
|  1 |   1 |  -1 |
+----+-----+-----+
>>> import pandas as pd
>>> pd_df = ak_df.to_pandas()
>>> type(pd_df)
pandas.core.frame.DataFrame
>>> display(pd_df)
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   0 |   0 |
+----+-----+-----+
|  1 |   1 |  -1 |
+----+-----+-----+
""""""
self.update_nrows()
nbytes = 0
for key, val in self.items():
if isinstance(val, pdarray):
nbytes += (val.dtype).itemsize * self._nrows
elif isinstance(val, Strings):
nbytes += val.nbytes
KB = 1024
MB = KB * KB
GB = MB * KB
msg = """"
if nbytes < KB:
msg = ""{:,} B"".format(nbytes)
elif nbytes < MB:
msg = ""{:,} KB"".format(int(nbytes / KB))
elif nbytes < GB:
msg = ""{:,} MB"".format(int(nbytes / MB))
print(f""This transfer will use {msg} ."")
else:
msg = ""{:,} GB"".format(int(nbytes / GB))
print(f""This will transfer {msg} from arkouda to pandas."")
if nbytes > (datalimit * len(self._columns) * MB):
msg = f""This operation would transfer more than {datalimit} bytes.""
warn(msg, UserWarning)
return None
pandas_data = {}
for key in self._columns:
val = self[key]
try:
pandas_data[key] = val.to_ndarray() if not isinstance(val, SegArray) else val.to_list()
except TypeError:
raise IndexError(""Bad index type or format."")
if retain_index and self.index is not None:
index = self.index.to_pandas()
return pd.DataFrame(data=pandas_data, index=index)
else:
return pd.DataFrame(data=pandas_data)
",[],0,[],/dataframe.py_to_pandas
895,/home/amandapotts/git/arkouda/arkouda/dataframe.py__prep_data,"def _prep_data(self, index=False, columns=None):
if columns is None:
data = self.data
else:
data = {c: self.data[c] for c in columns}
if index:
data[""Index""] = self.index.values
return data
",[],0,[],/dataframe.py__prep_data
896,/home/amandapotts/git/arkouda/arkouda/dataframe.py_to_hdf,"def to_hdf(self, path, index=False, columns=None, file_type=""distribute""):
""""""
Save DataFrame to disk as hdf5, preserving column names.
Parameters
----------
path : str
File path to save data.
index : bool, default=False
If True, save the index column. By default, do not save the index.
columns: List, default = None
List of columns to include in the file. If None, writes out all columns.
file_type: str (single | distribute), default=distribute
Whether to save to a single file or distribute across Locales.
Returns
-------
None
Raises
------
RuntimeError
Raised if a server-side error is thrown saving the pdarray.
Notes
-----
This method saves one file per locale of the arkouda server. All
files are prefixed by the path argument and suffixed by their
locale number.
See Also
---------
to_parquet
load
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> import os.path
>>> from pathlib import Path
>>> my_path = os.path.join(os.getcwd(), 'hdf_output')
>>> Path(my_path).mkdir(parents=True, exist_ok=True)
>>> df = ak.DataFrame({""A"":[1,2],""B"":[3,4]})
>>> df.to_hdf(my_path + ""/my_data"")
>>> df.load(my_path + ""/my_data"")
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   1 |   3 |
+----+-----+-----+
|  1 |   2 |   4 |
+----+-----+-----+
""""""
from arkouda.io import to_hdf
data = self._prep_data(index=index, columns=columns)
to_hdf(data, prefix_path=path, file_type=file_type)
",[],0,[],/dataframe.py_to_hdf
897,/home/amandapotts/git/arkouda/arkouda/dataframe.py__to_hdf_snapshot,"def _to_hdf_snapshot(self, path, dataset=""DataFrame"", mode=""truncate"", file_type=""distribute""):
""""""
Save a dataframe as a group with columns within the group. This allows saving other
datasets in the HDF5 file without impacting the integrity of the dataframe
This is only used for the snapshot workflow
Parameters
----------
path : str
File path to save data
dataset: str
Name to save the dataframe under within the file
Only used when as_dataset=True
mode: str (truncate | append), default=truncate
Indicates whether the dataset should truncate the file and write or append
to the file
Only used when as_dataset=True
file_type: str (single | distribute), default=distribute
Whether to save to a single file or distribute across Locales
Only used when as_dataset=True
Returns
-------
None
Raises
------
RuntimeError
Raised if a server-side error is thrown saving the pdarray
""""""
from arkouda.categorical import Categorical as Categorical_
from arkouda.io import _file_type_to_int, _mode_str_to_int
column_data = [
obj.name
if not isinstance(obj, (Categorical_, SegArray))
else json.dumps(
{
""codes"": obj.codes.name,
""categories"": obj.categories.name,
""NA_codes"": obj._akNAcode.name,
}
)
if isinstance(obj, Categorical_)
else json.dumps({""segments"": obj.segments.name, ""values"": obj.values.name})
for k, obj in self.items()
]
dtypes = [
str(obj.categories.dtype) if isinstance(obj, Categorical_) else str(obj.dtype)
for obj in self.values()
]
col_objTypes = [
obj.special_objType if hasattr(obj, ""special_objType"") else obj.objType
for obj in self.values()
]
return cast(
str,
generic_msg(
cmd=""tohdf"",
args={
""filename"": path,
""dset"": dataset,
""file_format"": _file_type_to_int(file_type),
""write_mode"": _mode_str_to_int(mode),
""objType"": self.objType,
""num_cols"": len(self.columns),
""column_names"": self.columns,
""column_objTypes"": col_objTypes,
""column_dtypes"": dtypes,
""columns"": column_data,
""index"": self.index.values.name,
},
),
)
",[],0,[],/dataframe.py__to_hdf_snapshot
898,/home/amandapotts/git/arkouda/arkouda/dataframe.py_update_hdf,"def update_hdf(self, prefix_path: str, index=False, columns=None, repack: bool = True):
""""""
Overwrite the dataset with the name provided with this dataframe. If
the dataset does not exist it is added.
Parameters
----------
prefix_path : str
Directory and filename prefix that all output files share.
index : bool, default=False
If True, save the index column. By default, do not save the index.
columns: List, default=None
List of columns to include in the file. If None, writes out all columns.
repack: bool, default=True
HDF5 does not release memory on delete. When True, the inaccessible
data (that was overwritten) is removed. When False, the data remains, but is
inaccessible. Setting to false will yield better performance, but will cause
file sizes to expand.
Returns
-------
str
Success message if successful.
Raises
------
RuntimeError
Raised if a server-side error is thrown saving the pdarray.
Notes
-----
If file does not contain File_Format attribute to indicate how it was saved,
the file name is checked for _LOCALE#### to determine if it is distributed.
If the dataset provided does not exist, it will be added.
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> import os.path
>>> from pathlib import Path
>>> my_path = os.path.join(os.getcwd(), 'hdf_output')
>>> Path(my_path).mkdir(parents=True, exist_ok=True)
>>> df = ak.DataFrame({""A"":[1,2],""B"":[3,4]})
>>> df.to_hdf(my_path + ""/my_data"")
>>> df.load(my_path + ""/my_data"")
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   1 |   3 |
+----+-----+-----+
|  1 |   2 |   4 |
+----+-----+-----+
>>> df2 = ak.DataFrame({""A"":[5,6],""B"":[7,8]})
>>> df2.update_hdf(my_path + ""/my_data"")
>>> df.load(my_path + ""/my_data"")
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   5 |   7 |
+----+-----+-----+
|  1 |   6 |   8 |
+----+-----+-----+
""""""
from arkouda.io import update_hdf
data = self._prep_data(index=index, columns=columns)
update_hdf(data, prefix_path=prefix_path, repack=repack)
",[],0,[],/dataframe.py_update_hdf
899,/home/amandapotts/git/arkouda/arkouda/dataframe.py_to_parquet,"def to_parquet(
self,
path,
index=False,
columns=None,
compression: Optional[str] = None,
convert_categoricals: bool = False,
",[],0,[],/dataframe.py_to_parquet
900,/home/amandapotts/git/arkouda/arkouda/dataframe.py_to_csv,"def to_csv(
self,
path: str,
index: bool = False,
columns: Optional[List[str]] = None,
col_delim: str = "","",
overwrite: bool = False,
",[],0,[],/dataframe.py_to_csv
901,/home/amandapotts/git/arkouda/arkouda/dataframe.py_read_csv,"def read_csv(cls, filename: str, col_delim: str = "",""):
r""""""
Read the columns of a CSV file into an Arkouda DataFrame.
If the file contains the appropriately formatted header, typed data will be returned.
Otherwise, all data will be returned as a Strings objects.
Parameters
----------
filename: str
Filename to read data from.
col_delim: str, default="",""
The delimiter for columns within the data.
Returns
-------
arkouda.dataframe.DataFrame
Arkouda DataFrame containing the columns from the CSV file.
Raises
------
ValueError
Raised if all datasets are not present in all parquet files or if one or
more of the specified files do not exist.
RuntimeError
Raised if one or more of the specified files cannot be opened.
If `allow_errors` is true this may be raised if no values are returned
from the server.
TypeError
Raised if we receive an unknown arkouda_type returned from the server.
See Also
--------
to_csv
Notes
------
- CSV format is not currently supported by load/load_all operations.
- The column delimiter is expected to be the same for column names and data.
- Be sure that column delimiters are not found within your data.
- All CSV files must delimit rows using newline (""\\n"") at this time.
- Unlike other file formats, CSV files store Strings as their UTF-8 format instead of storing
bytes as uint(8).
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> import os.path
>>> from pathlib import Path
>>> my_path = os.path.join(os.getcwd(), 'csv_output','my_data')
>>> Path(my_path).mkdir(parents=True, exist_ok=True)
>>> df = ak.DataFrame({""A"":[1,2],""B"":[3,4]})
>>> df.to_csv(my_path)
>>> df2 = DataFrame.read_csv(my_path + ""_LOCALE0000"")
>>> display(df2)
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   1 |   3 |
+----+-----+-----+
|  1 |   2 |   4 |
+----+-----+-----+
""""""
from arkouda.io import read_csv
data = read_csv(filename, column_delim=col_delim)
return cls(data)
",[],0,[],/dataframe.py_read_csv
902,/home/amandapotts/git/arkouda/arkouda/dataframe.py_save,"def save(
self,
path,
index=False,
columns=None,
file_format=""HDF5"",
file_type=""distribute"",
compression: Optional[str] = None,
",[],0,[],/dataframe.py_save
903,/home/amandapotts/git/arkouda/arkouda/dataframe.py_load,"def load(cls, prefix_path, file_format=""INFER""):
""""""
Load dataframe from file.
file_format needed for consistency with other load functions.
Parameters
----------
prefix_path : str
The prefix path for the data.
file_format : string, default = ""INFER""
Returns
-------
arkouda.dataframe.DataFrame
A dataframe loaded from the prefix_path.
Examples
--------
To store data in <my_dir>/my_data_LOCALE0000,
use ""<my_dir>/my_data"" as the prefix.
>>> import arkouda as ak
>>> ak.connect()
>>> import os.path
>>> from pathlib import Path
>>> my_path = os.path.join(os.getcwd(), 'hdf5_output','my_data')
>>> Path(my_path).mkdir(parents=True, exist_ok=True)
>>> df = ak.DataFrame({""A"": ak.arange(5), ""B"": -1 * ak.arange(5)})
>>> df.save(my_path, file_type=""distribute"")
>>> df.load(my_path)
+----+-----+-----+
|    |   A |   B |
+====+=====+=====+
|  0 |   0 |   0 |
+----+-----+-----+
|  1 |   1 |  -1 |
+----+-----+-----+
|  2 |   2 |  -2 |
+----+-----+-----+
|  3 |   3 |  -3 |
+----+-----+-----+
|  4 |   4 |  -4 |
+----+-----+-----+
""""""
from arkouda.io import (
_dict_recombine_segarrays_categoricals,
get_filetype,
load_all,
)
prefix, extension = os.path.splitext(prefix_path)
first_file = f""{prefix}_LOCALE0000{extension}""
filetype = get_filetype(first_file) if file_format.lower() == ""infer"" else file_format
df = cls(_dict_recombine_segarrays_categoricals(load_all(prefix_path, file_format=filetype)))
return df if filetype == ""HDF5"" else df[df.columns[::-1]]
",[],0,[],/dataframe.py_load
904,/home/amandapotts/git/arkouda/arkouda/dataframe.py_argsort,"def argsort(self, key, ascending=True):
""""""
Return the permutation that sorts the dataframe by `key`.
Parameters
----------
key : str
The key to sort on.
ascending : bool, default = True
If true, sort the key in ascending order.
Otherwise, sort the key in descending order.
Returns
-------
arkouda.pdarrayclass.pdarray
The permutation array that sorts the data on `key`.
See Also
--------
coargsort
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({'col1': [1.1, 3.1, 2.1], 'col2': [6, 5, 4]})
>>> display(df)
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |    1.1 |      6 |
+----+--------+--------+
|  1 |    3.1 |      5 |
+----+--------+--------+
|  2 |    2.1 |      4 |
+----+--------+--------+
>>> df.argsort('col1')
array([0 2 1])
>>> sorted_df1 = df[df.argsort('col1')]
>>> display(sorted_df1)
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |    1.1 |      6 |
+----+--------+--------+
|  1 |    2.1 |      4 |
+----+--------+--------+
|  2 |    3.1 |      5 |
+----+--------+--------+
>>> df.argsort('col2')
array([2 1 0])
>>> sorted_df2 = df[df.argsort('col2')]
>>> display(sorted_df2)
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |    2.1 |      4 |
+----+--------+--------+
|  1 |    3.1 |      5 |
+----+--------+--------+
|  2 |    1.1 |      6 |
+----+--------+--------+
""""""
if self._empty:
return array([], dtype=akint64)
if ascending:
return argsort(self[key])
else:
if isinstance(self[key], pdarray) and self[key].dtype in (
akint64,
akfloat64,
):
return argsort(-self[key])
else:
return argsort(self[key])[arange(self._nrows - 1, -1, -1)]
",[],0,[],/dataframe.py_argsort
905,/home/amandapotts/git/arkouda/arkouda/dataframe.py_coargsort,"def coargsort(self, keys, ascending=True):
""""""
Return the permutation that sorts the dataframe by `keys`.
Note: Sorting using Strings may not yield correct sort order.
Parameters
----------
keys : list of str
The keys to sort on.
Returns
-------
arkouda.pdarrayclass.pdarray
The permutation array that sorts the data on `keys`.
Example
-------
>>> df = ak.DataFrame({'col1': [2, 2, 1], 'col2': [3, 4, 3], 'col3':[5, 6, 7]})
>>> display(df)
+----+--------+--------+--------+
|    |   col1 |   col2 |   col3 |
+====+========+========+========+
|  0 |      2 |      3 |      5 |
+----+--------+--------+--------+
|  1 |      2 |      4 |      6 |
+----+--------+--------+--------+
|  2 |      1 |      3 |      7 |
+----+--------+--------+--------+
>>> df.coargsort(['col1', 'col2'])
array([2 0 1])
>>>
""""""
if self._empty:
return array([], dtype=akint64)
arrays = []
for key in keys:
arrays.append(self[key])
i = coargsort(arrays)
if not ascending:
i = i[arange(self._nrows - 1, -1, -1)]
return i
",[],0,[],/dataframe.py_coargsort
906,/home/amandapotts/git/arkouda/arkouda/dataframe.py__reindex,"def _reindex(self, idx):
if isinstance(self.index, MultiIndex):
new_index = MultiIndex(self.index[idx].values, name=self.index.name, names=self.index.names)
elif isinstance(self.index, Index):
new_index = Index(self.index[idx], name=self.index.name)
else:
new_index = Index(self.index[idx])
return DataFrame(self[idx], index=new_index)
",[],0,[],/dataframe.py__reindex
907,/home/amandapotts/git/arkouda/arkouda/dataframe.py_sort_index,"def sort_index(self, ascending=True):
""""""
Sort the DataFrame by indexed columns.
Note: Fails on sort order of arkouda.strings.Strings columns when multiple columns being sorted.
Parameters
----------
ascending : bool, default = True
Sort values in ascending (default) or descending order.
Example
-------
>>> df = ak.DataFrame({'col1': [1.1, 3.1, 2.1], 'col2': [6, 5, 4]},
...          index = Index(ak.array([2,0,1]), name=""idx""))
>>> display(df)
+----+--------+--------+
| idx|   col1 |   col2 |
+====+========+========+
|  0 |    1.1 |      6 |
+----+--------+--------+
|  1 |    3.1 |      5 |
+----+--------+--------+
|  2 |    2.1 |      4 |
+----+--------+--------+
>>> df.sort_index()
+----+--------+--------+
| idx|   col1 |   col2 |
+====+========+========+
|  0 |    3.1 |      5 |
+----+--------+--------+
|  1 |    2.1 |      4 |
+----+--------+--------+
|  2 |    1.1 |      6 |
+----+--------+--------+
""""""
idx = self.index.argsort(ascending=ascending)
return self._reindex(idx)
",[],0,[],/dataframe.py_sort_index
908,/home/amandapotts/git/arkouda/arkouda/dataframe.py_sort_values,"def sort_values(self, by=None, ascending=True):
""""""
Sort the DataFrame by one or more columns.
If no column is specified, all columns are used.
Note: Fails on order of arkouda.strings.Strings columns when multiple columns being sorted.
Parameters
----------
by : str or list/tuple of str, default = None
The name(s) of the column(s) to sort by.
ascending : bool, default = True
Sort values in ascending (default) or descending order.
See Also
--------
apply_permutation
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({'col1': [2, 2, 1], 'col2': [3, 4, 3], 'col3':[5, 6, 7]})
>>> display(df)
+----+--------+--------+--------+
|    |   col1 |   col2 |   col3 |
+====+========+========+========+
|  0 |      2 |      3 |      5 |
+----+--------+--------+--------+
|  1 |      2 |      4 |      6 |
+----+--------+--------+--------+
|  2 |      1 |      3 |      7 |
+----+--------+--------+--------+
>>> df.sort_values()
+----+--------+--------+--------+
|    |   col1 |   col2 |   col3 |
+====+========+========+========+
|  0 |      1 |      3 |      7 |
+----+--------+--------+--------+
|  1 |      2 |      3 |      5 |
+----+--------+--------+--------+
|  2 |      2 |      4 |      6 |
+----+--------+--------+--------+
>>> df.sort_values(""col3"")
+----+--------+--------+--------+
|    |   col1 |   col2 |   col3 |
+====+========+========+========+
|  0 |      1 |      3 |      7 |
+----+--------+--------+--------+
|  1 |      2 |      3 |      5 |
+----+--------+--------+--------+
|  2 |      2 |      4 |      6 |
+----+--------+--------+--------+
""""""
if self._empty:
return array([], dtype=akint64)
if by is None:
if len(self._columns) == 1:
i = self.argsort(self._columns[0], ascending=ascending)
else:
i = self.coargsort(self._columns, ascending=ascending)
elif isinstance(by, str):
i = self.argsort(by, ascending=ascending)
elif isinstance(by, (list, tuple)):
i = self.coargsort(by, ascending=ascending)
else:
raise TypeError(""Column name(s) must be str or list/tuple of str"")
return self[i]
",[],0,[],/dataframe.py_sort_values
909,/home/amandapotts/git/arkouda/arkouda/dataframe.py_apply_permutation,"def apply_permutation(self, perm):
""""""
Apply a permutation to an entire DataFrame.  The operation is done in
place and the original DataFrame will be modified.
This may be useful if you want to unsort an DataFrame, or even to
apply an arbitrary permutation such as the inverse of a sorting
permutation.
Parameters
----------
perm : pdarray
A permutation array. Should be the same size as the data
arrays, and should consist of the integers [0,size-1] in
some order. Very minimal testing is done to ensure this
is a permutation.
Returns
-------
None
See Also
--------
sort
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]})
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |      4 |
+----+--------+--------+
|  1 |      2 |      5 |
+----+--------+--------+
|  2 |      3 |      6 |
+----+--------+--------+
>>> perm_arry = ak.array([0, 2, 1])
>>> df.apply_permutation(perm_arry)
>>> display(df)
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |      4 |
+----+--------+--------+
|  1 |      3 |      6 |
+----+--------+--------+
|  2 |      2 |      5 |
+----+--------+--------+
""""""
if (perm.min() != 0) or (perm.max() != perm.size - 1):
raise ValueError(""The indicated permutation is invalid."")
if unique(perm).size != perm.size:
raise ValueError(""The indicated permutation is invalid."")
for key, val in self.data.items():
self[key] = self[key][perm]
self._set_index(self.index[perm])
",[],0,[],/dataframe.py_apply_permutation
910,/home/amandapotts/git/arkouda/arkouda/dataframe.py_filter_by_range,"def filter_by_range(self, keys, low=1, high=None):
""""""
Find all rows where the value count of the items in a given set of
columns (keys) is within the range [low, high].
To filter by a specific value, set low == high.
Parameters
----------
keys : str or list of str
The names of the columns to group by.
low : int, default=1
The lowest value count.
high : int, default=None
The highest value count, default to unlimited.
Returns
-------
arkouda.pdarrayclass.pdarray
An array of boolean values for qualified rows in this DataFrame.
Example
-------
>>> df = ak.DataFrame({'col1': [1, 2, 2, 2, 3, 3], 'col2': [4, 5, 6, 7, 8, 9]})
>>> display(df)
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |      4 |
+----+--------+--------+
|  1 |      2 |      5 |
+----+--------+--------+
|  2 |      2 |      6 |
+----+--------+--------+
|  3 |      2 |      7 |
+----+--------+--------+
|  4 |      3 |      8 |
+----+--------+--------+
|  5 |      3 |      9 |
+----+--------+--------+
>>> df.filter_by_range(""col1"", low=1, high=2)
array([True False False False True True])
>>> filtered_df = df[df.filter_by_range(""col1"", low=1, high=2)]
>>> display(filtered_df)
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |      4 |
+----+--------+--------+
|  1 |      3 |      8 |
+----+--------+--------+
|  2 |      3 |      9 |
+----+--------+--------+
""""""
if isinstance(keys, str):
keys = [keys]
gb = self.GroupBy(keys, use_series=False)
vals, cts = gb.count()
if not high:
positions = where(cts >= low, 1, 0)
else:
positions = where(((cts >= low) & (cts <= high)), 1, 0)
broadcast = gb.broadcast(positions, permute=False)
broadcast = broadcast == 1
return broadcast[invert_permutation(gb.permutation)]
",[],0,[],/dataframe.py_filter_by_range
911,/home/amandapotts/git/arkouda/arkouda/dataframe.py_copy,"def copy(self, deep=True):
""""""
Make a copy of this object's data.
When `deep = True` (default), a new object will be created with a copy of
the calling object's data. Modifications to the data of the copy will not
be reflected in the original object.
When `deep = False` a new object will be created without copying the
calling object's data. Any changes to the data of the original object will
be reflected in the shallow copy, and vice versa.
Parameters
----------
deep : bool, default=True
When True, return a deep copy. Otherwise, return a shallow copy.
Returns
-------
arkouda.dataframe.DataFrame
A deep or shallow copy according to caller specification.
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({'col1': [1, 2], 'col2': [3, 4]})
>>> display(df)
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |      3 |
+----+--------+--------+
|  1 |      2 |      4 |
+----+--------+--------+
>>> df_deep = df.copy(deep=True)
>>> df_deep['col1'] +=1
>>> display(df)
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |      3 |
+----+--------+--------+
|  1 |      2 |      4 |
+----+--------+--------+
>>> df_shallow = df.copy(deep=False)
>>> df_shallow['col1'] +=1
>>> display(df)
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      2 |      3 |
+----+--------+--------+
|  1 |      3 |      4 |
+----+--------+--------+
""""""
if deep:
res = DataFrame()
res._size = self._nrows
res._bytes = self._bytes
res._empty = self._empty
res._columns = self._columns[:]  # if this is not a slice, droping columns modifies both
for key, val in self.items():
res[key] = val[:]
res._set_index(Index(self.index.index[:]))
return res
else:
return DataFrame(self)
",[],0,[],/dataframe.py_copy
912,/home/amandapotts/git/arkouda/arkouda/dataframe.py_groupby,"def groupby(self, keys, use_series=True, as_index=True, dropna=True):
""""""
Group the dataframe by a column or a list of columns.  Alias for GroupBy.
Parameters
----------
keys : str or list of str
An (ordered) list of column names or a single string to group by.
use_series : bool, default=True
If True, returns an arkouda.dataframe.GroupBy object.
Otherwise an arkouda.groupbyclass.GroupBy object.
as_index: bool, default=True
If True, groupby columns will be set as index
otherwise, the groupby columns will be treated as DataFrame columns.
dropna : bool, default=True
If True, and the groupby keys contain NaN values,
the NaN values together with the corresponding row will be dropped.
Otherwise, the rows corresponding to NaN values will be kept.
Returns
-------
arkouda.dataframe.GroupBy or arkouda.groupbyclass.GroupBy
If use_series = True, returns an arkouda.dataframe.GroupBy object.
Otherwise returns an arkouda.groupbyclass.GroupBy object.
See Also
--------
arkouda.GroupBy
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({'col1': [1.0, 1.0, 2.0, np.nan], 'col2': [4, 5, 6, 7]})
>>> df
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |      4 |
+----+--------+--------+
|  1 |      1 |      5 |
+----+--------+--------+
|  2 |      2 |      6 |
+----+--------+--------+
|  3 |    nan |      7 |
+----+--------+--------+
>>> df.GroupBy(""col1"")
<arkouda.groupbyclass.GroupBy at 0x7f2cf23e10c0>
>>> df.GroupBy(""col1"").size()
(array([1.00000000000000000 2.00000000000000000]), array([2 1]))
>>> df.GroupBy(""col1"",use_series=True)
col1
1.0    2
2.0    1
dtype: int64
>>> df.GroupBy(""col1"",use_series=True, as_index = False).size()
+----+--------+--------+
|    |   col1 |   size |
+====+========+========+
|  0 |      1 |      2 |
+----+--------+--------+
|  1 |      2 |      1 |
+----+--------+--------+
""""""
return self.GroupBy(keys, use_series, as_index=as_index, dropna=dropna)
",['nan'],1,[],/dataframe.py_groupby
913,/home/amandapotts/git/arkouda/arkouda/dataframe.py_isin,"def isin(self, values: Union[pdarray, Dict, Series, DataFrame]) -> DataFrame:
""""""
Determine whether each element in the DataFrame is contained in values.
Parameters
__________
values : pdarray, dict, Series, or DataFrame
The values to check for in DataFrame. Series can only have a single index.
Returns
_______
arkouda.dataframe.DataFrame
Arkouda DataFrame of booleans showing whether each element in the DataFrame is
contained in values.
See Also
________
ak.Series.isin
Notes
_____
- Pandas supports values being an iterable type. In arkouda, we replace this with pdarray.
- Pandas supports ~ operations. Currently, ak.DataFrame does not support this.
Examples
________
>>> import arkouda as ak
>>> ak.connect()
>>> df = ak.DataFrame({'col_A': ak.array([7, 3]), 'col_B':ak.array([1, 9])})
>>> display(df)
+----+---------+---------+
|    |   col_A |   col_B |
+====+=========+=========+
|  0 |       7 |       1 |
+----+---------+---------+
|  1 |       3 |       9 |
+----+---------+---------+
When `values` is a pdarray, check every value in the DataFrame to determine if
it exists in values.
>>> df.isin(ak.array([0, 1]))
+----+---------+---------+
|    |   col_A |   col_B |
+====+=========+=========+
|  0 |       0 |       1 |
+----+---------+---------+
|  1 |       0 |       0 |
+----+---------+---------+
When `values` is a dict, the values in the dict are passed to check the column
indicated by the key.
>>> df.isin({'col_A': ak.array([0, 3])})
+----+---------+---------+
|    |   col_A |   col_B |
+====+=========+=========+
|  0 |       0 |       0 |
+----+---------+---------+
|  1 |       1 |       0 |
+----+---------+---------+
When `values` is a Series, each column is checked if values is present positionally.
This means that for `True` to be returned, the indexes must be the same.
>>> i = ak.Index(ak.arange(2))
>>> s = ak.Series(data=[3, 9], index=i)
>>> df.isin(s)
+----+---------+---------+
|    |   col_A |   col_B |
+====+=========+=========+
|  0 |       0 |       0 |
+----+---------+---------+
|  1 |       0 |       1 |
+----+---------+---------+
When `values` is a DataFrame, the index and column must match.
Note that 9 is not found because the column name does not match.
>>> other_df = ak.DataFrame({'col_A':ak.array([7, 3]), 'col_C':ak.array([0, 9])})
>>> df.isin(other_df)
+----+---------+---------+
|    |   col_A |   col_B |
+====+=========+=========+
|  0 |       1 |       0 |
+----+---------+---------+
|  1 |       1 |       0 |
+----+---------+---------+
""""""
if isinstance(values, pdarray):
flat_in1d = in1d(concatenate(list(self.data.values())), values)
segs = concatenate(
[
array([0]),
cumsum(array([self.data[col].size for col in self.columns])),
]
)
df_def = {col: flat_in1d[segs[i] : segs[i + 1]] for i, col in enumerate(self.columns)}
elif isinstance(values, Dict):
df_def = {
col: (
in1d(self.data[col], values[col])
if col in values.keys()
else zeros(self._nrows, dtype=akbool)
)
for col in self.columns
}
elif isinstance(values, DataFrame) or (
isinstance(values, Series) and isinstance(values.index, Index)
):
df_def = {col: zeros(self._nrows, dtype=akbool) for col in self.columns}
rows_self, rows_val = intersect(self.index.index, values.index.index, unique=True)
sort_self = self.index[rows_self].argsort()
sort_val = values.index[rows_val].argsort()
for col in self.columns:
if isinstance(values, DataFrame) and col in values.columns:
df_def[col][rows_self] = (
self.data[col][rows_self][sort_self] == values.data[col][rows_val][sort_val]
)
elif isinstance(values, Series):
df_def[col][rows_self] = (
self.data[col][rows_self][sort_self] == values.values[rows_val][sort_val]
)
else:
raise ValueError(""Cannot compute isin with duplicate axis."")
return DataFrame(df_def, index=self.index)
",[],0,[],/dataframe.py_isin
914,/home/amandapotts/git/arkouda/arkouda/dataframe.py_corr,"def corr(self) -> DataFrame:
""""""
Return new DataFrame with pairwise correlation of columns.
Returns
-------
arkouda.dataframe.DataFrame
Arkouda DataFrame containing correlation matrix of all columns.
Raises
------
RuntimeError
Raised if there's a server-side error thrown.
See Also
--------
pdarray.corr
Notes
-----
Generates the correlation matrix using Pearson R for all columns.
Attempts to convert to numeric values where possible for inclusion in the matrix.
Example
-------
>>> df = ak.DataFrame({'col1': [1, 2], 'col2': [-1, -2]})
>>> display(df)
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |     -1 |
+----+--------+--------+
|  1 |      2 |     -2 |
+----+--------+--------+
>>> corr = df.corr()
+----+--------+--------+
|    |   col1 |   col2 |
+====+========+========+
|  0 |      1 |     -1 |
+----+--------+--------+
|  1 |     -1 |      1 |
+----+--------+--------+
""""""
",[],0,[],/dataframe.py_corr
915,/home/amandapotts/git/arkouda/arkouda/dataframe.py_numeric_help,"def numeric_help(d):
if isinstance(d, Strings):
d = Categorical(d)
return d if isinstance(d, pdarray) else d.codes
",[],0,[],/dataframe.py_numeric_help
916,/home/amandapotts/git/arkouda/arkouda/dataframe.py_merge,"def merge(
self,
right: DataFrame,
on: Optional[Union[str, List[str]]] = None,
how: str = ""inner"",
left_suffix: str = ""_x"",
right_suffix: str = ""_y"",
",[],0,[],/dataframe.py_merge
917,/home/amandapotts/git/arkouda/arkouda/dataframe.py_register,"def register(self, user_defined_name: str) -> DataFrame:
""""""
Register this DataFrame object and underlying components with the Arkouda server.
Parameters
----------
user_defined_name : str
User defined name the DataFrame is to be registered under.
This will be the root name for underlying components.
Returns
-------
arkouda.dataframe.DataFrame
The same DataFrame which is now registered with the arkouda server and has an updated name.
This is an in-place modification, the original is returned to support a
fluid programming style.
Please note you cannot register two different DataFrames with the same name.
Raises
------
TypeError
Raised if user_defined_name is not a str.
RegistrationError
If the server was unable to register the DataFrame with the user_defined_name.
See also
--------
unregister
attach
unregister_dataframe_by_name
is_registered
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
Any changes made to a DataFrame object after registering with the server may not be reflected
in attached copies.
Example
-------
>>> df = ak.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]})
>>> df.register(""my_table_name"")
>>> df.attach(""my_table_name"")
>>> df.is_registered()
True
>>> df.unregister()
>>> df.is_registered()
False
""""""
from arkouda.categorical import Categorical as Categorical_
if self.registered_name is not None and self.is_registered():
raise RegistrationError(f""This object is already registered as {self.registered_name}"")
column_data = [
obj.name
if not isinstance(obj, (Categorical_, SegArray, BitVector))
else json.dumps(
{
""codes"": obj.codes.name,
""categories"": obj.categories.name,
""NA_codes"": obj._akNAcode.name,
}
)
if isinstance(obj, Categorical_)
else json.dumps({""segments"": obj.segments.name, ""values"": obj.values.name})
if isinstance(obj, SegArray)
else json.dumps(
{
""name"": obj.name,
""width"": obj.width,
""reverse"": obj.reverse,
}  # BitVector Case
)
for obj in self.values()
]
col_objTypes = [
obj.special_objType if hasattr(obj, ""special_objType"") else obj.objType
for obj in self.values()
]
generic_msg(
cmd=""register"",
args={
""name"": user_defined_name,
""objType"": self.objType,
""idx"": self.index.values.name,
""num_cols"": len(self.columns),
""column_names"": self.columns,
""columns"": column_data,
""col_objTypes"": col_objTypes,
},
)
self.registered_name = user_defined_name
return self
",[],0,[],/dataframe.py_register
918,/home/amandapotts/git/arkouda/arkouda/dataframe.py_unregister,"def unregister(self):
""""""
Unregister this DataFrame object in the arkouda server which was previously
registered using register() and/or attached to using attach().
Raises
------
RegistrationError
If the object is already unregistered or if there is a server error
when attempting to unregister.
See also
--------
register
attach
unregister_dataframe_by_name
is_registered
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
Example
-------
>>> df = ak.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]})
>>> df.register(""my_table_name"")
>>> df.attach(""my_table_name"")
>>> df.is_registered()
True
>>> df.unregister()
>>> df.is_registered()
False
""""""
from arkouda.util import unregister
if not self.registered_name:
raise RegistrationError(""This object is not registered"")
unregister(self.registered_name)
self.registered_name = None  # Clear our internal DataFrame object name
",[],0,[],/dataframe.py_unregister
919,/home/amandapotts/git/arkouda/arkouda/dataframe.py_is_registered,"def is_registered(self) -> bool:
""""""
Return True if the object is contained in the registry.
Returns
-------
bool
Indicates if the object is contained in the registry.
Raises
------
RegistrationError
Raised if there's a server-side error or a mismatch of registered components.
See Also
--------
register
attach
unregister
unregister_dataframe_by_name
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
Example
-------
>>> df = ak.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]})
>>> df.register(""my_table_name"")
>>> df.attach(""my_table_name"")
>>> df.is_registered()
True
>>> df.unregister()
>>> df.is_registered()
False
""""""
from arkouda.util import is_registered
if self.registered_name is None:
return False  # Dataframe cannot be registered as a component
return is_registered(self.registered_name)
",[],0,[],/dataframe.py_is_registered
920,/home/amandapotts/git/arkouda/arkouda/dataframe.py_attach,"def attach(user_defined_name: str) -> DataFrame:
""""""
Function to return a DataFrame object attached to the registered name in the
arkouda server which was registered using register().
Parameters
----------
user_defined_name : str
user defined name which DataFrame object was registered under.
Returns
-------
arkouda.dataframe.DataFrame
The DataFrame object created by re-attaching to the corresponding server components.
Raises
------
RegistrationError
if user_defined_name is not registered
See Also
--------
register, is_registered, unregister
Example
-------
>>> df = ak.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]})
>>> df.register(""my_table_name"")
>>> df.attach(""my_table_name"")
>>> df.is_registered()
True
>>> df.unregister()
>>> df.is_registered()
False
""""""
import warnings
from arkouda.util import attach
warnings.warn(
""ak.DataFrame.attach() is deprecated. Please use ak.attach() instead."",
DeprecationWarning,
)
return attach(user_defined_name)
",[],0,[],/dataframe.py_attach
921,/home/amandapotts/git/arkouda/arkouda/dataframe.py_unregister_dataframe_by_name,"def unregister_dataframe_by_name(user_defined_name: str) -> None:
""""""
Function to unregister DataFrame object by name which was registered
with the arkouda server via register().
Parameters
----------
user_defined_name : str
Name under which the DataFrame object was registered.
Raises
-------
TypeError
If user_defined_name is not a string.
RegistrationError
If there is an issue attempting to unregister any underlying components.
See Also
--------
register
unregister
attach
is_registered
Example
-------
>>> df = ak.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]})
>>> df.register(""my_table_name"")
>>> df.attach(""my_table_name"")
>>> df.is_registered()
True
>>> df.unregister_dataframe_by_name(""my_table_name"")
>>> df.is_registered()
False
""""""
import warnings
from arkouda.util import unregister
warnings.warn(
""ak.DataFrame.unregister_dataframe_by_name() is deprecated. ""
""Please use ak.unregister() instead."",
DeprecationWarning,
)
return unregister(user_defined_name)
",[],0,[],/dataframe.py_unregister_dataframe_by_name
922,/home/amandapotts/git/arkouda/arkouda/dataframe.py__parse_col_name,"def _parse_col_name(entryName, dfName):
""""""
Helper method used by from_return_msg to parse the registered name of the data component
and pull out the column type and column name
Parameters
----------
entryName : string
The full registered name of the data component
dfName : string
The name of the DataFrame
Returns
-------
tuple
(columnName, columnType)
""""""
nameParts = entryName.split("" "")
regName = nameParts[1] if len(nameParts) > 1 else nameParts[0]
colParts = regName.split(""_"")
colType = colParts[2]
if len(colParts) > 5:
nameInd = regName.rindex(dfName) - 1
startInd = len(colType) + 9
return regName[startInd:nameInd], colType
else:
return colParts[3], colType
",[],0,[],/dataframe.py__parse_col_name
923,/home/amandapotts/git/arkouda/arkouda/dataframe.py_from_return_msg,"def from_return_msg(cls, rep_msg):
""""""
Creates a DataFrame object from an arkouda server response message.
Parameters
----------
rep_msg : string
Server response message used to create a DataFrame.
Returns
-------
arkouda.dataframe.DataFrame
""""""
from arkouda.categorical import Categorical as Categorical_
data = json.loads(rep_msg)
idx = None
columns = {}
for k, create_data in data.items():
comps = create_data.split(""+|+"")
if k.lower() == ""index"":
if comps[0] == Strings.objType.upper():
idx = Index(Strings.from_return_msg(comps[1]))
else:
idx = Index(create_pdarray(comps[1]))
else:
if comps[0] == pdarray.objType.upper():
columns[k] = create_pdarray(comps[1])
elif comps[0] == Strings.objType.upper():
columns[k] = Strings.from_return_msg(comps[1])
elif comps[0] == IPv4.special_objType.upper():
columns[k] = IPv4(create_pdarray(comps[1]))
elif comps[0] == Datetime.special_objType.upper():
columns[k] = Datetime(create_pdarray(comps[1]))
elif comps[0] == Timedelta.special_objType.upper():
columns[k] = Timedelta(create_pdarray(comps[1]))
elif comps[0] == Categorical_.objType.upper():
columns[k] = Categorical_.from_return_msg(comps[1])
elif comps[0] == SegArray.objType.upper():
columns[k] = SegArray.from_return_msg(comps[1])
elif comps[0] == BitVector.special_objType.upper():
columns[k] = BitVector.from_return_msg(comps[1])
return cls(columns, idx)
",[],0,[],/dataframe.py_from_return_msg
924,/home/amandapotts/git/arkouda/arkouda/dataframe.py_intx,"def intx(a, b):
""""""
Find all the rows that are in both dataframes.
Columns should be in identical order.
Note: does not work for columns of floating point values, but does work for
Strings, pdarrays of int64 type, and Categorical *should* work.
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> a = ak.DataFrame({'a':ak.arange(5),'b': 2* ak.arange(5)})
>>> display(a)
+----+-----+-----+
|    |   a |   b |
+====+=====+=====+
|  0 |   0 |   0 |
+----+-----+-----+
|  1 |   1 |   2 |
+----+-----+-----+
|  2 |   2 |   4 |
+----+-----+-----+
|  3 |   3 |   6 |
+----+-----+-----+
|  4 |   4 |   8 |
+----+-----+-----+
>>> b = ak.DataFrame({'a':ak.arange(5),'b':ak.array([0,3,4,7,8])})
>>> display(b)
+----+-----+-----+
|    |   a |   b |
+====+=====+=====+
|  0 |   0 |   0 |
+----+-----+-----+
|  1 |   1 |   3 |
+----+-----+-----+
|  2 |   2 |   4 |
+----+-----+-----+
|  3 |   3 |   7 |
+----+-----+-----+
|  4 |   4 |   8 |
+----+-----+-----+
>>> intx(a,b)
>>> intersect_df = a[intx(a,b)]
>>> display(intersect_df)
+----+-----+-----+
|    |   a |   b |
+====+=====+=====+
|  0 |   0 |   0 |
+----+-----+-----+
|  1 |   2 |   4 |
+----+-----+-----+
|  2 |   4 |   8 |
+----+-----+-----+
""""""
if list(a.data) == list(b.data):
a_cols = []
b_cols = []
for key, val in a.items():
if key != ""index"":
a_cols.append(val)
for key, val in b.items():
if key != ""index"":
b_cols.append(val)
return in1d(a_cols, b_cols)
else:
raise ValueError(""Column mismatch."")
",[],0,[],/dataframe.py_intx
925,/home/amandapotts/git/arkouda/arkouda/dataframe.py_intersect,"def intersect(a, b, positions=True, unique=False):
""""""
Find the intersection of two arkouda arrays.
This function can be especially useful when `positions=True` so
that the caller gets the indices of values present in both arrays.
Parameters
----------
a : Strings or pdarray
An array of strings.
b : Strings or pdarray
An array of strings.
positions : bool, default=True
Return tuple of boolean pdarrays that indicate positions in `a` and `b`
of the intersection values.
unique : bool, default=False
If the number of distinct values in `a` (and `b`) is equal to the size of
`a` (and `b`), there is a more efficient method to compute the intersection.
Returns
-------
(arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray) or arkouda.pdarrayclass.pdarray
The indices of `a` and `b` where any element occurs at least once in both
arrays.
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> a = ak.arange(10)
>>> print(a)
[0 1 2 3 4 5 6 7 8 9]
>>> b = 2 * ak.arange(10)
>>> print(b)
[0 2 4 6 8 10 12 14 16 18]
>>> intersect(a,b, positions=True)
(array([True False True False True False True False True False]),
array([True True True True True False False False False False]))
>>> intersect(a,b, positions=False)
array([0 2 4 6 8])
""""""
if isinstance(a, pdarray) and isinstance(b, pdarray):
intx = intersect1d(a, b)
if not positions:
return intx
else:
maska = in1d(a, intx)
maskb = in1d(b, intx)
return (maska, maskb)
elif isinstance(a, Strings) and isinstance(b, Strings):
hash_a00, hash_a01 = a.hash()
hash_b00, hash_b01 = b.hash()
if unique:
hash0 = concatenate([hash_a00, hash_b00])
hash1 = concatenate([hash_a01, hash_b01])
gb = akGroupBy([hash0, hash1])
val, cnt = gb.count()
counts = gb.broadcast(cnt, permute=False)
tmp = counts[:]
counts[gb.permutation] = tmp
del tmp
maska = (counts > 1)[: a.size]
maskb = (counts > 1)[a.size :]
if positions:
return (maska, maskb)
else:
return a[maska]
else:
gba = akGroupBy([hash_a00, hash_a01])
gbb = akGroupBy([hash_b00, hash_b01])
a0, a1 = gba.unique_keys
b0, b1 = gbb.unique_keys
hash0 = concatenate([a0, b0])
hash1 = concatenate([a1, b1])
gb = akGroupBy([hash0, hash1])
val, cnt = gb.count()
counts = gb.broadcast(cnt, permute=False)
tmp = counts[:]
counts[gb.permutation] = tmp
del tmp
countsa = counts[: a0.size]
countsb = counts[a0.size :]
counts2a = gba.broadcast(countsa, permute=False)
counts2b = gbb.broadcast(countsb, permute=False)
tmp = counts2a[:]
counts2a[gba.permutation] = tmp
del tmp
tmp = counts2b[:]
counts2b[gbb.permutation] = tmp
del tmp
maska = counts2a > 1
maskb = counts2b > 1
if positions:
return (maska, maskb)
else:
return a[maska]
",[],0,[],/dataframe.py_intersect
926,/home/amandapotts/git/arkouda/arkouda/dataframe.py_invert_permutation,"def invert_permutation(perm):
""""""
Find the inverse of a permutation array.
Parameters
----------
perm : pdarray
The permutation array.
Returns
-------
arkouda.pdarrayclass.pdarray
The inverse of the permutation array.
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> from arkouda.index import Index
>>> i = Index(ak.array([1,2,0,5,4]))
>>> perm = i.argsort()
>>> print(perm)
[2 0 1 4 3]
>>> invert_permutation(perm)
array([1 2 0 4 3])
""""""
rng = perm.max() - perm.min()
if (unique(perm).size != perm.size) and (perm.size != rng + 1):
raise ValueError(""The array is not a permutation."")
return coargsort([perm, arange(perm.size)])
",[],0,[],/dataframe.py_invert_permutation
927,/home/amandapotts/git/arkouda/arkouda/dataframe.py__inner_join_merge,"def _inner_join_merge(
left: DataFrame,
right: DataFrame,
on: Union[str, List[str]],
col_intersect: Union[str, List[str]],
left_suffix: str = ""_x"",
right_suffix: str = ""_y"",
",[],0,[],/dataframe.py__inner_join_merge
928,/home/amandapotts/git/arkouda/arkouda/dataframe.py__right_join_merge,"def _right_join_merge(
left: DataFrame,
right: DataFrame,
on: Union[str, List[str]],
col_intersect: Union[str, List[str]],
left_suffix: str = ""_x"",
right_suffix: str = ""_y"",
",[],0,[],/dataframe.py__right_join_merge
929,/home/amandapotts/git/arkouda/arkouda/dataframe.py_merge,"def merge(
left: DataFrame,
right: DataFrame,
on: Optional[Union[str, List[str]]] = None,
how: str = ""inner"",
left_suffix: str = ""_x"",
right_suffix: str = ""_y"",
",[],0,[],/dataframe.py_merge
930,/home/amandapotts/git/arkouda/arkouda/security.py_generate_token,"def generate_token(length: int = 32) -> str:
""""""
Uses the secrets.token_hex() method to generate a
a hexidecimal token
Parameters
----------
length : int
The desired length of token
Returns
-------
str
The hexidecimal string generated by Python
Notes
-----
This method uses the Python secrets.token_hex method
""""""
return secrets.token_hex(length // 2)
",[],0,[],/security.py_generate_token
931,/home/amandapotts/git/arkouda/arkouda/security.py_get_home_directory,"def get_home_directory() -> str:
""""""
A platform-independent means of finding path to
the current user's home directory
Returns
-------
str
The user's home directory path
Notes
-----
This method uses the Python os.path.expanduser method
to retrieve the user's home directory
""""""
return expanduser(""~"")
",[],0,[],/security.py_get_home_directory
932,/home/amandapotts/git/arkouda/arkouda/security.py_get_arkouda_client_directory,"def get_arkouda_client_directory() -> Path:
""""""
A platform-independent means of finding path to
the current user's .arkouda directory where artifacts
such as server access tokens are stored.
Returns
-------
Path
Path corresponding to the user's .arkouda directory path
Notes
-----
The default implementation is to place the .arkouda
directory in the current user's home directory. The
default can be overridden by setting the ARKOUDA_CLIENT_DIRECTORY
environment variable.  It is important this is not the same location
as the server's token directory as the file format is different.
""""""
arkouda_parent_dir = os.getenv(""ARKOUDA_CLIENT_DIRECTORY"")
if not arkouda_parent_dir:
arkouda_parent_dir = get_home_directory()
return io_util.get_directory(""{}{}.arkouda"".format(arkouda_parent_dir, os.sep)).absolute()
",[],0,[],/security.py_get_arkouda_client_directory
933,/home/amandapotts/git/arkouda/arkouda/security.py_get_username,"def get_username() -> str:
""""""
A platform-independent means of retrieving the current
user's username for the host system.
Returns
-------
str
The username in the form of string
Raises
------
EnvironmentError
Raised if the host OS is unsupported
Notes
-----
The currently supported operating systems are Windows, Linux,
and MacOS AKA Darwin
""""""
try:
u_tokens = username_tokenizer[platform.system()](get_home_directory())
except KeyError as ke:
raise EnvironmentError(f""Unsupported OS: {ke}"")
return u_tokens[-1]
",[],0,[],/security.py_get_username
934,/home/amandapotts/git/arkouda/arkouda/security.py_generate_username_token_json,"def generate_username_token_json(token: str) -> str:
""""""
Generates a JSON object encapsulating the user's username
and token for connecting to an arkouda server with basic
authentication enabled
Parameters
----------
token : string
The token to be used to access arkouda server
Returns
-------
str
The JSON-formatted string encapsulating username and token
""""""
return json.dumps({""username"": get_username(), ""token"": token})
",[],0,[],/security.py_generate_username_token_json
935,/home/amandapotts/git/arkouda/arkouda/segarray.py__aggregator,"def _aggregator(func):
aggdoc = """"""
Aggregate values over each sub-array.
Parameters
----------
x : pdarray
The values to aggregate. By default, the values of the sub-arrays
themselves are used, but the user may supply an array of values
corresponding to the flattened values of all sub-arrays.
Returns
-------
pdarray
Array of one aggregated value per sub-array.
""""""
",[],0,[],/segarray.py__aggregator
936,/home/amandapotts/git/arkouda/arkouda/segarray.py_update_doc,"def update_doc():
func.__doc__ = aggdoc
return func
",[],0,[],/segarray.py_update_doc
937,/home/amandapotts/git/arkouda/arkouda/segarray.py_segarray,"def segarray(segments: pdarray, values: pdarray, lengths=None, grouping=None):
""""""
Alias for the from_parts function. Prevents user from needing to call `ak.SegArray` constructor
DEPRECATED
""""""
warn(
""ak.segarray has been deprecated. Please use ak.SegArray constructor moving forward"",
DeprecationWarning,
)
return SegArray(segments, values, lengths, grouping)
",[],0,[],/segarray.py_segarray
938,/home/amandapotts/git/arkouda/arkouda/segarray.py___init__,"def __init__(self, segments, values, lengths=None, grouping=None):
self.logger = getArkoudaLogger(name=__class__.__name__)  # type: ignore
self.registered_name: Optional[str] = None
if not isinstance(segments, pdarray) or segments.dtype != akint64:
raise TypeError(""Segments must be int64 pdarray"")
if not isinstance(values, pdarray) and not isinstance(values, Strings):
raise TypeError(""Values must be a pdarray or Strings."")
if not is_sorted(segments):
raise ValueError(""Segments must be unique and in sorted order"")
if segments.size > 0:
if segments[0] != 0:
raise ValueError(""Segments must start at zero."")
elif values.size > 0:
raise ValueError(""Cannot have non-empty values with empty segments"")
self.values = values
self.segments = segments
self.size = segments.size
self.valsize = values.size
self.dtype = values.dtype
if lengths is None:
self.lengths = self._get_lengths()
else:
self.lengths = lengths
self._non_empty = self.lengths > 0
self._non_empty_count = self.non_empty.sum()
if grouping is None:
if self.size == 0 or self._non_empty_count == 0:
self._grouping = GroupBy(zeros(0, dtype=akint64))
else:
self._grouping = GroupBy(
broadcast(self.segments[self.non_empty], arange(self._non_empty_count), self.valsize)
)
else:
self._grouping = grouping
",[],0,[],/segarray.py___init__
939,/home/amandapotts/git/arkouda/arkouda/segarray.py_from_return_msg,"def from_return_msg(cls, rep_msg) -> SegArray:
eles = json.loads(rep_msg)
values = (
Strings.from_return_msg(eles[""values""])
if eles[""values""].split()[2] == ""str""
else create_pdarray(eles[""values""])
)
segments = create_pdarray(eles[""segments""])
lengths = create_pdarray(eles[""lengths""]) if ""lengths"" in eles else None
return cls(segments, values, lengths=lengths)
",[],0,[],/segarray.py_from_return_msg
940,/home/amandapotts/git/arkouda/arkouda/segarray.py_from_parts,"def from_parts(cls, segments, values, lengths=None, grouping=None) -> SegArray:
""""""
DEPRECATED
Construct a SegArray object from its parts
Parameters
----------
segments : pdarray, int64
Start index of each sub-array in the flattened values array
values : pdarray
The flattened values of all sub-arrays
lengths: pdarray
The length of each segment
grouping: GroupBy
grouping of segments
Returns
-------
SegArray
Data structure representing an array whose elements are variable-length arrays.
Notes
-----
Keyword args 'lengths' and 'grouping' are not user-facing. They are used by the
attach method.
""""""
warn(
""ak.SegArray.from_parts has been deprecated. Please use ak.SegArray constructor to ""
""generate SegArray objects."",
DeprecationWarning,
)
return cls(segments, values, lengths=lengths, grouping=grouping)
",[],0,[],/segarray.py_from_parts
941,/home/amandapotts/git/arkouda/arkouda/segarray.py_from_multi_array,"def from_multi_array(cls, m):
""""""
Construct a SegArray from a list of columns. This essentially transposes the input,
resulting in an array of rows.
Parameters
----------
m : list of pdarray or Strings
List of columns, the rows of which will form the sub-arrays of the output
Returns
-------
SegArray
Array of rows of input
""""""
if isinstance(m, pdarray):
return cls(arange(m.size), m)
else:
sizes = np.array([mi.size for mi in m])
dtypes = {mi.dtype for mi in m}
if len(dtypes) != 1:
raise ValueError(""All values must have same dtype"")
n = len(m)
offsets = np.cumsum(sizes) - sizes
newvals = zeros(sum(sizes), dtype=dtypes.pop())
for j in range(n):
newvals[offsets[j] : (offsets[j] + sizes[j])] = m[j]
return cls(array(offsets), newvals)
","['array', 'cumsum']",2,"['array([mi.size for mi in m])', 'cumsum(sizes)']",/segarray.py_from_multi_array
942,/home/amandapotts/git/arkouda/arkouda/segarray.py_non_empty,"def non_empty(self):
from arkouda.infoclass import list_symbol_table
if self._non_empty.name not in list_symbol_table():
self._non_empty = self.lengths > 0
self._non_empty_count = self._non_empty.sum()
return self._non_empty
",[],0,[],/segarray.py_non_empty
943,/home/amandapotts/git/arkouda/arkouda/segarray.py_grouping,"def grouping(self):
if self._grouping is not None:
return self._grouping
if self.size == 0 or self._non_empty_count == 0:
self._grouping = GroupBy(zeros(0, dtype=akint64))
else:
self._grouping = GroupBy(
broadcast(self.segments[self.non_empty], arange(self._non_empty_count), self.valsize)
)
",[],0,[],/segarray.py_grouping
944,/home/amandapotts/git/arkouda/arkouda/segarray.py__get_lengths,"def _get_lengths(self):
if self.size == 0:
return zeros(0, dtype=akint64)
elif self.size == 1:
return array([self.valsize])
else:
return concatenate((self.segments[1:], array([self.valsize]))) - self.segments
",[],0,[],/segarray.py__get_lengths
945,/home/amandapotts/git/arkouda/arkouda/segarray.py___getitem__,"def __getitem__(self, i):
if isSupportedInt(i):
start = self.segments[i]
end = self.segments[i] + self.lengths[i]
return self.values[start:end]
elif (isinstance(i, pdarray) and i.dtype in [akint64, akuint64, akbool]) or isinstance(i, slice):
starts = self.segments[i]
ends = starts + self.lengths[i]
newsegs, inds = gen_ranges(starts, ends)
return SegArray(newsegs, self.values[inds])
else:
raise TypeError(f""Invalid index type: {type(i)}"")
",[],0,[],/segarray.py___getitem__
946,/home/amandapotts/git/arkouda/arkouda/segarray.py_concat,"def concat(cls, x, axis=0, ordered=True):
""""""
Concatenate a sequence of SegArrays
Parameters
----------
x : sequence of SegArray
The SegArrays to concatenate
axis : 0 or 1
Select vertical (0) or horizontal (1) concatenation. If axis=1, all
SegArrays must have same size.
ordered : bool
Must be True. This option is present for compatibility only, because unordered
concatenation is not yet supported.
Returns
-------
SegArray
The input arrays joined into one SegArray
""""""
if not ordered:
raise ValueError(""Unordered concatenation not yet supported on SegArray
if len(x) == 0:
raise ValueError(""Empty sequence passed to concat"")
for xi in x:
if not isinstance(xi, cls):
return NotImplemented
if len({xi.dtype for xi in x}) != 1:
raise ValueError(""SegArrays must all have same dtype to concatenate"")
if axis == 0:
ctr = 0
segs = []
vals = []
for xi in x:
segs.append(xi.segments + ctr)
ctr += xi.valsize
vals.append(xi.values)
return cls(concatenate(segs), concatenate(vals))
elif axis == 1:
sizes = {xi.size for xi in x}
if len(sizes) != 1:
raise ValueError(""SegArrays must all have same size to concatenate with axis=1"")
if sizes.pop() == 0:
return x[0]
dt = list(x)[0].dtype
newlens = sum(xi.lengths for xi in x)
newsegs = cumsum(newlens) - newlens
nonzero = concatenate((newsegs[:-1] < newsegs[1:], array([True])))
nzsegs = newsegs[nonzero]
newvals = zeros(newlens.sum(), dtype=dt)
for xi in x:
fromself = zeros(newvals.size + 1, dtype=akint64)
fromself[nzsegs] += 1
nzlens = xi.lengths[nonzero]
fromself[nzsegs + nzlens] -= 1
fromself = cumsum(fromself[:-1]) == 1
newvals[fromself] = xi.values
nzsegs += nzlens
return cls(newsegs, newvals)
else:
raise ValueError(
""Supported values for axis are 0 (vertical concat) or 1 (horizontal concat)""
)
",[],0,[],/segarray.py_concat
947,/home/amandapotts/git/arkouda/arkouda/segarray.py_copy,"def copy(self):
""""""
Return a deep copy.
""""""
return SegArray(self.segments[:], self.values[:])
",[],0,[],/segarray.py_copy
948,/home/amandapotts/git/arkouda/arkouda/segarray.py___eq__,"def __eq__(self, other):
if not isinstance(other, SegArray):
return NotImplemented
if self.size != other.size:
raise ValueError(""Segarrays must have same size to compare"")
eq = zeros(self.size, dtype=akbool)
leneq = self.lengths == other.lengths
if leneq.sum() > 0:
selfcmp = self[leneq]
othercmp = other[leneq]
intersection = selfcmp.all(selfcmp.values == othercmp.values)
eq[leneq & (self.lengths != 0)] = intersection
eq[leneq & (self.lengths == 0)] = True
return eq
",[],0,[],/segarray.py___eq__
949,/home/amandapotts/git/arkouda/arkouda/segarray.py___len__,"def __len__(self) -> int:
return self.size
",[],0,[],/segarray.py___len__
950,/home/amandapotts/git/arkouda/arkouda/segarray.py___str__,"def __str__(self):
if self.size <= 6:
rows = list(range(self.size))
else:
rows = [0, 1, 2, None, self.size - 3, self.size - 2, self.size - 1]
outlines = [""SegArray([""]
for r in rows:
if r is None:
outlines.append(""..."")
else:
outlines.append(str(self[r]))
outlines.append(""])"")
return ""\n"".join(outlines)
",[],0,[],/segarray.py___str__
951,/home/amandapotts/git/arkouda/arkouda/segarray.py___repr__,"def __repr__(self):
return self.__str__()
",[],0,[],/segarray.py___repr__
952,/home/amandapotts/git/arkouda/arkouda/segarray.py_get_suffixes,"def get_suffixes(self, n, return_origins=True, proper=True):
""""""
Return the n-long suffix of each sub-array, where possible
Parameters
----------
n : int
Length of suffix
return_origins : bool
If True, return a logical index indicating which sub-arrays
were long enough to return an n-suffix
proper : bool
If True, only return proper suffixes, i.e. from sub-arrays
that are at least n+1 long. If False, allow the entire
sub-array to be returned as a suffix.
Returns
-------
suffixes : list of pdarray
An n-long list of pdarrays, essentially a table where each row is an n-suffix.
The number of rows is the number of True values in the returned mask.
origin_indices : pdarray, bool
Boolean array that is True where the sub-array was long enough to return
an n-suffix, False otherwise.
""""""
if proper:
longenough = self.lengths > n
else:
longenough = self.lengths >= n
suffixes = []
for i in range(n):
ind = (self.segments + self.lengths - (n - i))[longenough]
suffixes.append(self.values[ind])
if return_origins:
return suffixes, longenough
else:
return suffixes
",[],0,[],/segarray.py_get_suffixes
953,/home/amandapotts/git/arkouda/arkouda/segarray.py_get_prefixes,"def get_prefixes(self, n, return_origins=True, proper=True):
""""""
Return all sub-array prefixes of length n (for sub-arrays that are at least n+1 long)
Parameters
----------
n : int
Length of suffix
return_origins : bool
If True, return a logical index indicating which sub-arrays
were long enough to return an n-prefix
proper : bool
If True, only return proper prefixes, i.e. from sub-arrays
that are at least n+1 long. If False, allow the entire
sub-array to be returned as a prefix.
Returns
-------
prefixes : list of pdarray
An n-long list of pdarrays, essentially a table where each row is an n-prefix.
The number of rows is the number of True values in the returned mask.
origin_indices : pdarray, bool
Boolean array that is True where the sub-array was long enough to return
an n-suffix, False otherwise.
""""""
if proper:
longenough = self.lengths > n
else:
longenough = self.lengths >= n
prefixes = []
for i in range(n):
ind = (self.segments + i)[longenough]
prefixes.append(self.values[ind])
if return_origins:
return prefixes, longenough
else:
return prefixes
",[],0,[],/segarray.py_get_prefixes
954,/home/amandapotts/git/arkouda/arkouda/segarray.py_get_ngrams,"def get_ngrams(self, n, return_origins=True):
""""""
Return all n-grams from all sub-arrays.
Parameters
----------
n : int
Length of n-gram
return_origins : bool
If True, return an int64 array indicating which sub-array
each returned n-gram came from.
Returns
-------
ngrams : list of pdarray
An n-long list of pdarrays, essentially a table where each row is an n-gram.
origin_indices : pdarray, int
The index of the sub-array from which the corresponding n-gram originated
""""""
if n > self.lengths.max():
raise ValueError(""n must be <= the maximum length of the sub-arrays"")
ngrams = []
notsegstart = ones(self.valsize, dtype=akbool)
notsegstart[self.segments[self.non_empty]] = False
valid = ones(self.valsize - n + 1, dtype=akbool)
for i in range(n):
end = self.valsize - n + i + 1
ngrams.append(self.values[i:end])
if i > 0:
valid &= notsegstart[i:end]
ngrams = [char[valid] for char in ngrams]
if return_origins:
seg_idx = arange(self.size)[self.non_empty]
origin_indices = self.grouping.broadcast(seg_idx, permute=True)[: valid.size][valid]
return ngrams, origin_indices
else:
return ngrams
",[],0,[],/segarray.py_get_ngrams
955,/home/amandapotts/git/arkouda/arkouda/segarray.py__normalize_index,"def _normalize_index(self, j):
if not isSupportedInt(j):
raise TypeError(f""index must be integer, not {type(j)}"")
if j >= 0:
longenough = self.lengths > j
else:
j = self.lengths + j
longenough = j >= 0
return longenough, j
",[],0,[],/segarray.py__normalize_index
956,/home/amandapotts/git/arkouda/arkouda/segarray.py_get_jth,"def get_jth(self, j, return_origins=True, compressed=False, default=0):
""""""
Select the j-th element of each sub-array, where possible.
Parameters
----------
j : int
The index of the value to get from each sub-array. If j is negative,
it counts backwards from the end of each sub-array.
return_origins : bool
If True, return a logical index indicating where j is in bounds
compressed : bool
If False, return array is same size as self, with default value
where j is out of bounds. If True, the return array only contains
values where j is in bounds.
default : scalar
When compressed=False, the value to return when j is out of bounds
for the sub-array
Returns
-------
val : pdarray
compressed=False: The j-th value of each sub-array where j is in
bounds and the default value where j is out of bounds.
compressed=True: The j-th values of only the sub-arrays where j is
in bounds
origin_indices : pdarray, bool
A Boolean array that is True where j is in bounds for the sub-array.
Notes
------
If values are Strings, only the compressed format is supported.
""""""
longenough, newj = self._normalize_index(j)
ind = (self.segments + newj)[longenough]
if compressed or self.dtype == str_:  # Strings not supported by uncompressed version
res = self.values[ind]
else:
res = zeros(self.size, dtype=self.dtype)
res.fill(default)
res[longenough] = self.values[ind]
if return_origins:
return res, longenough
else:
return res
",[],0,[],/segarray.py_get_jth
957,/home/amandapotts/git/arkouda/arkouda/segarray.py_set_jth,"def set_jth(self, i, j, v):
""""""
Set the j-th element of each sub-array in a subset.
Parameters
----------
i : pdarray, int
Indices of sub-arrays to set j-th element
j : int
Index of value to set in each sub-array. If j is negative, it counts
backwards from the end of the sub-array.
v : pdarray or scalar
The value(s) to set. If v is a pdarray, it must have same length as i.
Raises
-----
ValueError
If j is out of bounds in any of the sub-arrays specified by i.
""""""
if self.dtype == str_:
raise TypeError(""String elements are immutable"")
longenough, newj = self._normalize_index(j)
if not longenough[i].all():
raise ValueError(""Not all (i, j) in bounds"")
ind = (self.segments + newj)[i]
self.values[ind] = v
",[],0,[],/segarray.py_set_jth
958,/home/amandapotts/git/arkouda/arkouda/segarray.py_get_length_n,"def get_length_n(self, n, return_origins=True):
""""""
Return all sub-arrays of length n, as a list of columns.
Parameters
----------
n : int
Length of sub-arrays to select
return_origins : bool
Return a logical index indicating which sub-arrays are length n
Returns
-------
columns : list of pdarray
An n-long list of pdarray, where each row is one of the n-long
sub-arrays from the SegArray. The number of rows is the number of
True values in the returned mask.
origin_indices : pdarray, bool
Array of bool for each element of the SegArray, True where sub-array
has length n.
""""""
mask = self.lengths == n
elem = []
for i in range(n):
ind = (self.segments + self.lengths - (n - i))[mask]
elem.append(self.values[ind])
if return_origins:
return elem, mask
else:
return elem
",[],0,[],/segarray.py_get_length_n
959,/home/amandapotts/git/arkouda/arkouda/segarray.py_append,"def append(self, other, axis=0):
""""""
Append other to self, either vertically (axis=0, length of resulting SegArray
increases), or horizontally (axis=1, each sub-array of other appends to the
corresponding sub-array of self).
Parameters
----------
other : SegArray
Array of sub-arrays to append
axis : 0 or 1
Whether to append vertically (0) or horizontally (1). If axis=1, other
must be same size as self.
Returns
-------
SegArray
axis=0: New SegArray containing all sub-arrays
axis=1: New SegArray of same length, with pairs of sub-arrays concatenated
""""""
if not isinstance(other, SegArray):
return NotImplemented
if self.dtype != other.dtype:
raise TypeError(""SegArrays must have same value type to append"")
return self.__class__.concat((self, other), axis=axis)
",[],0,[],/segarray.py_append
960,/home/amandapotts/git/arkouda/arkouda/segarray.py_append_single,"def append_single(self, x, prepend=False):
""""""
Append a single value to each sub-array.
Parameters
----------
x : pdarray or scalar
Single value to append to each sub-array
Returns
-------
SegArray
Copy of original SegArray with values from x appended to each sub-array
""""""
if self.dtype == str_:
raise TypeError(""String elements are immutable and cannot accept a single value"")
if hasattr(x, ""size""):
if x.size != self.size:
raise ValueError(""Argument must be scalar or same size as SegArray"")
if not isinstance(x, type(self.values)) or x.dtype != self.dtype:
raise TypeError(""Argument type must match value type of SegArray"")
newlens = self.lengths + 1
newsegs = cumsum(newlens) - newlens
newvals = zeros(newlens.sum(), dtype=self.dtype)
if prepend:
lastscatter = newsegs
else:
lastscatter = newsegs + newlens - 1
newvals[lastscatter] = x
origscatter = arange(self.valsize) + self.grouping.broadcast(
arange(self.size)[self.non_empty], permute=True
)
if prepend:
origscatter += 1
newvals[origscatter] = self.values
return SegArray(newsegs, newvals)
",[],0,[],/segarray.py_append_single
961,/home/amandapotts/git/arkouda/arkouda/segarray.py_prepend_single,"def prepend_single(self, x):
return self.append_single(x, prepend=True)
",[],0,[],/segarray.py_prepend_single
962,/home/amandapotts/git/arkouda/arkouda/segarray.py_remove_repeats,"def remove_repeats(self, return_multiplicity=False):
""""""
Condense sequences of repeated values within a sub-array to a single value.
Parameters
----------
return_multiplicity : bool
If True, also return the number of times each value was repeated.
Returns
-------
norepeats : SegArray
Sub-arrays with runs of repeated values replaced with single value
multiplicity : SegArray
If return_multiplicity=True, this array contains the number of times
each value in the returned SegArray was repeated in the original SegArray.
""""""
isrepeat = zeros(self.values.size, dtype=akbool)
isrepeat[1:] = self.values[:-1] == self.values[1:]
isrepeat[self.segments[self.non_empty]] = False
truepaths = self.values[~isrepeat]
nhops = self.grouping.sum(~isrepeat)[1]
lens = self.lengths[:]
lens[self.non_empty] = nhops
truesegs = cumsum(lens) - lens
norepeats = SegArray(truesegs, truepaths)
if return_multiplicity:
truehopinds = arange(self.valsize)[~isrepeat]
multiplicity = zeros(truepaths.size, dtype=akint64)
multiplicity[:-1] = truehopinds[1:] - truehopinds[:-1]
multiplicity[-1] = self.valsize - truehopinds[-1]
return norepeats, SegArray(truesegs, multiplicity)
else:
return norepeats
",[],0,[],/segarray.py_remove_repeats
963,/home/amandapotts/git/arkouda/arkouda/segarray.py_to_ndarray,"def to_ndarray(self):
""""""
Convert the array into a numpy.ndarray containing sub-arrays
Returns
-------
np.ndarray
A numpy ndarray with the same sub-arrays (also numpy.ndarray) as this array
See Also
--------
array()
to_list()
Examples
--------
>>> segarr = ak.SegArray(ak.array([0, 4, 7]), ak.arange(12))
>>> segarr.to_ndarray()
array([array([1, 2, 3, 4]), array([5, 6, 7]), array([8, 9, 10, 11, 12])])
>>> type(segarr.to_ndarray())
numpy.ndarray
""""""
ndvals = self.values.to_ndarray()
ndsegs = self.segments.to_ndarray()
arr = [ndvals[start:end] for start, end in zip(ndsegs, ndsegs[1:])]
if self.size > 0:
arr.append(ndvals[ndsegs[-1] :])
return np.array(arr, dtype=object)
","['ndarray', 'array']",2,"['array(arr, dtype=object)']",/segarray.py_to_ndarray
964,/home/amandapotts/git/arkouda/arkouda/segarray.py_to_list,"def to_list(self):
""""""
Convert the segarray into a list containing sub-arrays
Returns
-------
list
A list with the same sub-arrays (also list) as this segarray
See Also
--------
to_ndarray()
Examples
--------
>>> segarr = ak.SegArray(ak.array([0, 4, 7]), ak.arange(12))
>>> segarr.to_list()
[[0, 1, 2, 3], [4, 5, 6], [7, 8, 9, 10, 11]]
>>> type(segarr.to_list())
list
""""""
return [arr.tolist() for arr in self.to_ndarray()]
",[],0,[],/segarray.py_to_list
965,/home/amandapotts/git/arkouda/arkouda/segarray.py_sum,"def sum(self, x=None):
if x is None:
x = self.values
return self.grouping.sum(x)[1]
",[],0,[],/segarray.py_sum
966,/home/amandapotts/git/arkouda/arkouda/segarray.py_prod,"def prod(self, x=None):
if x is None:
x = self.values
return self.grouping.prod(x)[1]
",[],0,[],/segarray.py_prod
967,/home/amandapotts/git/arkouda/arkouda/segarray.py_min,"def min(self, x=None):
if x is None:
x = self.values
return self.grouping.min(x)[1]
",[],0,[],/segarray.py_min
968,/home/amandapotts/git/arkouda/arkouda/segarray.py_max,"def max(self, x=None):
if x is None:
x = self.values
return self.grouping.max(x)[1]
",[],0,[],/segarray.py_max
969,/home/amandapotts/git/arkouda/arkouda/segarray.py_argmin,"def argmin(self, x=None):
if x is None:
x = self.values
return self.grouping.argmin(x)[1]
",[],0,[],/segarray.py_argmin
970,/home/amandapotts/git/arkouda/arkouda/segarray.py_argmax,"def argmax(self, x=None):
if x is None:
x = self.values
return self.grouping.argmax(x)[1]
",[],0,[],/segarray.py_argmax
971,/home/amandapotts/git/arkouda/arkouda/segarray.py_any,"def any(self, x=None):
if x is None:
x = self.values
return self.grouping.any(x)[1]
",[],0,[],/segarray.py_any
972,/home/amandapotts/git/arkouda/arkouda/segarray.py_all,"def all(self, x=None):
if x is None:
x = self.values
return self.grouping.all(x)[1]
",[],0,[],/segarray.py_all
973,/home/amandapotts/git/arkouda/arkouda/segarray.py_OR,"def OR(self, x=None):
if x is None:
x = self.values
return self.grouping.OR(x)[1]
",[],0,[],/segarray.py_OR
974,/home/amandapotts/git/arkouda/arkouda/segarray.py_AND,"def AND(self, x=None):
if x is None:
x = self.values
return self.grouping.AND(x)[1]
",[],0,[],/segarray.py_AND
975,/home/amandapotts/git/arkouda/arkouda/segarray.py_XOR,"def XOR(self, x=None):
if x is None:
x = self.values
return self.grouping.XOR(x)[1]
",[],0,[],/segarray.py_XOR
976,/home/amandapotts/git/arkouda/arkouda/segarray.py_nunique,"def nunique(self, x=None):
if x is None:
x = self.values
return self.grouping.nunique(x)[1]
",[],0,[],/segarray.py_nunique
977,/home/amandapotts/git/arkouda/arkouda/segarray.py_mean,"def mean(self, x=None):
if x is None:
x = self.values
return self.grouping.mean(x)[1]
",[],0,[],/segarray.py_mean
978,/home/amandapotts/git/arkouda/arkouda/segarray.py_aggregate,"def aggregate(self, op, x=None):
if x is None:
x = self.values
return self.grouping.aggregate(x, op)
",[],0,[],/segarray.py_aggregate
979,/home/amandapotts/git/arkouda/arkouda/segarray.py_unique,"def unique(self, x=None):
""""""
Return sub-arrays of unique values.
Parameters
----------
x : pdarray
The values to unique, per group. By default, the values of this
SegArray's sub-arrays.
Returns
-------
SegArray
Same number of sub-arrays as original SegArray, but elements in sub-array
are unique and in sorted order.
""""""
if x is None:
x = self.values
keyidx = self.grouping.broadcast(arange(self.size), permute=True)
ukey, uval = GroupBy([keyidx, x]).unique_keys
g = GroupBy(ukey, assume_sorted=True)
_, lengths = g.count()
return SegArray(g.segments, uval, grouping=g, lengths=lengths)
",[],0,[],/segarray.py_unique
980,/home/amandapotts/git/arkouda/arkouda/segarray.py_hash,"def hash(self) -> Tuple[pdarray, pdarray]:
""""""
Compute a 128-bit hash of each segment.
Returns
-------
Tuple[pdarray,pdarray]
A tuple of two int64 pdarrays. The ith hash value is the concatenation
of the ith values from each array.
""""""
repMsg = type_cast(
str,
generic_msg(
cmd=""segmentedHash"",
args={
""objType"": self.objType,
""values"": self.values,
""segments"": self.segments,
""valObjType"": self.values.objType,
},
),
)
h1, h2 = repMsg.split(""+"")
return create_pdarray(h1), create_pdarray(h2)
",[],0,[],/segarray.py_hash
981,/home/amandapotts/git/arkouda/arkouda/segarray.py_to_hdf,"def to_hdf(
self,
prefix_path,
dataset=""segarray"",
mode=""truncate"",
file_type=""distribute"",
",[],0,[],/segarray.py_to_hdf
982,/home/amandapotts/git/arkouda/arkouda/segarray.py_update_hdf,"def update_hdf(
self,
prefix_path: str,
dataset: str = ""segarray"",
repack: bool = True,
",[],0,[],/segarray.py_update_hdf
983,/home/amandapotts/git/arkouda/arkouda/segarray.py_to_parquet,"def to_parquet(
self, prefix_path, dataset=""segarray"", mode: str = ""truncate"", compression: Optional[str] = None
",[],0,[],/segarray.py_to_parquet
984,/home/amandapotts/git/arkouda/arkouda/segarray.py_save,"def save(
self,
prefix_path,
dataset=""segarray"",
mode=""truncate"",
file_type=""distribute"",
",[],0,[],/segarray.py_save
985,/home/amandapotts/git/arkouda/arkouda/segarray.py_read_hdf,"def read_hdf(cls, prefix_path, dataset=""segarray""):
""""""
Load a saved SegArray from HDF5. All arguments must match what
was supplied to SegArray.save()
Parameters
----------
prefix_path : str
Directory and filename prefix
dataset : str
Name prefix for saved data within the HDF5 files
Returns
-------
SegArray
""""""
from arkouda.io import read_hdf
return read_hdf(prefix_path, datasets=dataset)
",[],0,[],/segarray.py_read_hdf
986,/home/amandapotts/git/arkouda/arkouda/segarray.py_load,"def load(cls, prefix_path, dataset=""segarray"", segment_name=""segments"", value_name=""values""):
warnings.warn(
""ak.SegArray.load() is deprecated. Please use ak.SegArray.read_hdf() instead."",
DeprecationWarning,
)
if segment_name != ""segments"" or value_name != ""values"":
dataset = [dataset + ""_"" + value_name, dataset + ""_"" + segment_name]
return cls.read_hdf(prefix_path, dataset)
",[],0,[],/segarray.py_load
987,/home/amandapotts/git/arkouda/arkouda/segarray.py_intersect,"def intersect(self, other):
""""""
Computes the intersection of 2 SegArrays.
Parameters
----------
other : SegArray
SegArray to compute against
Returns
-------
SegArray
Segments are the 1d intersections of the segments of self and other
See Also
--------
pdarraysetops.intersect1d
Examples
--------
>>> a = [1, 2, 3, 1, 4]
>>> b = [3, 1, 4, 5]
>>> c = [1, 3, 3, 5]
>>> d = [2, 2, 4]
>>> seg_a = ak.segarray(ak.array([0, len(a)]), ak.array(a+b))
>>> seg_b = ak.segarray(ak.array([0, len(c)]), ak.array(c+d))
>>> seg_a.intersect(seg_b)
SegArray([
[1, 3],
[4]
])
""""""
from arkouda.pdarraysetops import intersect1d
a_seg_inds = self.grouping.broadcast(arange(self.size)[self.non_empty])
b_seg_inds = other.grouping.broadcast(arange(other.size)[other.non_empty])
(new_seg_inds, new_values) = intersect1d([a_seg_inds, self.values], [b_seg_inds, other.values])
g = GroupBy(new_seg_inds)
if g.segments.size == self.size:
return SegArray(g.segments, new_values[g.permutation])
else:
segments = zeros(self.size, dtype=akint64)
truth = ones(self.size, dtype=akbool)
k, ct = g.count()
segments[k] = g.segments
truth[k] = zeros(k.size, dtype=akbool)
if truth[-1]:
segments[-1] = g.permutation.size
truth[-1] = False
segments[truth] = segments[arange(self.size)[truth] + 1]
return SegArray(segments, new_values[g.permutation])
",[],0,[],/segarray.py_intersect
988,/home/amandapotts/git/arkouda/arkouda/segarray.py_union,"def union(self, other):
""""""
Computes the union of 2 SegArrays.
Parameters
----------
other : SegArray
SegArray to compute against
Returns
-------
SegArray
Segments are the 1d union of the segments of self and other
See Also
--------
pdarraysetops.union1d
Examples
--------
>>> a = [1, 2, 3, 1, 4]
>>> b = [3, 1, 4, 5]
>>> c = [1, 3, 3, 5]
>>> d = [2, 2, 4]
>>> seg_a = ak.segarray(ak.array([0, len(a)]), ak.array(a+b))
>>> seg_b = ak.segarray(ak.array([0, len(c)]), ak.array(c+d))
>>> seg_a.union(seg_b)
SegArray([
[1, 2, 3, 4, 5],
[1, 2, 3, 4, 5]
])
""""""
from arkouda.pdarraysetops import union1d
a_seg_inds = self.grouping.broadcast(arange(self.size)[self.non_empty])
b_seg_inds = other.grouping.broadcast(arange(other.size)[other.non_empty])
(new_seg_inds, new_values) = union1d([a_seg_inds, self.values], [b_seg_inds, other.values])
g = GroupBy(new_seg_inds)
if g.segments.size == self.size:
return SegArray(g.segments, new_values[g.permutation])
else:
segments = zeros(self.size, dtype=akint64)
truth = ones(self.size, dtype=akbool)
k, ct = g.count()
segments[k] = g.segments
truth[k] = zeros(k.size, dtype=akbool)
if truth[-1]:
segments[-1] = g.permutation.size
truth[-1] = False
segments[truth] = segments[arange(self.size)[truth] + 1]
return SegArray(segments, new_values[g.permutation])
",[],0,[],/segarray.py_union
989,/home/amandapotts/git/arkouda/arkouda/segarray.py_setdiff,"def setdiff(self, other):
""""""
Computes the set difference of 2 SegArrays.
Parameters
----------
other : SegArray
SegArray to compute against
Returns
-------
SegArray
Segments are the 1d set difference of the segments of self and other
See Also
--------
pdarraysetops.setdiff1d
Examples
--------
>>> a = [1, 2, 3, 1, 4]
>>> b = [3, 1, 4, 5]
>>> c = [1, 3, 3, 5]
>>> d = [2, 2, 4]
>>> seg_a = ak.segarray(ak.array([0, len(a)]), ak.array(a+b))
>>> seg_b = ak.segarray(ak.array([0, len(c)]), ak.array(c+d))
>>> seg_a.setdiff(seg_b)
SegArray([
[2, 4],
[1, 3, 5]
])
""""""
from arkouda.pdarraysetops import setdiff1d
a_seg_inds = self.grouping.broadcast(arange(self.size)[self.non_empty])
b_seg_inds = other.grouping.broadcast(arange(other.size)[other.non_empty])
(new_seg_inds, new_values) = setdiff1d([a_seg_inds, self.values], [b_seg_inds, other.values])
g = GroupBy(new_seg_inds)
if g.segments.size == self.size:
return SegArray(g.segments, new_values[g.permutation])
else:
segments = zeros(self.size, dtype=akint64)
truth = ones(self.size, dtype=akbool)
k, ct = g.count()
segments[k] = g.segments
truth[k] = zeros(k.size, dtype=akbool)
if truth[-1]:
segments[-1] = g.permutation.size
truth[-1] = False
segments[truth] = segments[arange(self.size)[truth] + 1]
return SegArray(segments, new_values[g.permutation])
",[],0,[],/segarray.py_setdiff
990,/home/amandapotts/git/arkouda/arkouda/segarray.py_setxor,"def setxor(self, other):
""""""
Computes the symmetric difference of 2 SegArrays.
Parameters
----------
other : SegArray
SegArray to compute against
Returns
-------
SegArray
Segments are the 1d symmetric difference of the segments of self and other
See Also
--------
pdarraysetops.setxor1d
Examples
--------
>>> a = [1, 2, 3, 1, 4]
>>> b = [3, 1, 4, 5]
>>> c = [1, 3, 3, 5]
>>> d = [2, 2, 4]
>>> seg_a = ak.segarray(ak.array([0, len(a)]), ak.array(a+b))
>>> seg_b = ak.segarray(ak.array([0, len(c)]), ak.array(c+d))
>>> seg_a.setxor(seg_b)
SegArray([
[2, 4, 5],
[1, 3, 5, 2]
])
""""""
from arkouda.pdarraysetops import setxor1d
a_seg_inds = self.grouping.broadcast(arange(self.size)[self.non_empty])
b_seg_inds = other.grouping.broadcast(arange(other.size)[other.non_empty])
(new_seg_inds, new_values) = setxor1d([a_seg_inds, self.values], [b_seg_inds, other.values])
g = GroupBy(new_seg_inds)
if g.segments.size == self.size:
return SegArray(g.segments, new_values[g.permutation])
else:
segments = zeros(self.size, dtype=akint64)
truth = ones(self.size, dtype=akbool)
k, ct = g.count()
segments[k] = g.segments
truth[k] = zeros(k.size, dtype=akbool)
if truth[-1]:
segments[-1] = g.permutation.size
truth[-1] = False
segments[truth] = segments[arange(self.size)[truth] + 1]
return SegArray(segments, new_values[g.permutation])
",[],0,[],/segarray.py_setxor
991,/home/amandapotts/git/arkouda/arkouda/segarray.py_filter,"def filter(self, filter, discard_empty: bool = False):
""""""
Filter values out of the SegArray object
Parameters
----------
filter: pdarray, list, or value
The value/s to be filtered out of the SegArray
discard_empty: bool
Defaults to False. When True, empty segments are removed from
the return SegArray
Returns
--------
SegArray
""""""
from arkouda.pdarraysetops import in1d
if isinstance(filter, Sequence):
filter = array(filter)
keep = (
in1d(self.values, filter, invert=True)
if isinstance(filter, pdarray) or isinstance(filter, Strings)
else self.values != filter
)
new_vals = self.values[keep]
lens = self.lengths[:]
seg_cts = self.grouping.sum(keep)[1]
lens[self.non_empty] = seg_cts
new_segs = cumsum(lens) - lens
new_segarray = SegArray(new_segs, new_vals)
return new_segarray[new_segarray.non_empty] if discard_empty else new_segarray
",[],0,[],/segarray.py_filter
992,/home/amandapotts/git/arkouda/arkouda/segarray.py_register,"def register(self, user_defined_name):
""""""
Register this SegArray object and underlying components with the Arkouda server
Parameters
----------
user_defined_name : str
user defined name which this SegArray object will be registered under
Returns
-------
SegArray
The same SegArray which is now registered with the arkouda server and has an updated name.
This is an in-place modification, the original is returned to support
a fluid programming style.
Please note you cannot register two different SegArrays with the same name.
Raises
------
RegistrationError
Raised if the server could not register the SegArray object
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
See Also
--------
unregister, attach, is_registered
""""""
if self.registered_name is not None and self.is_registered():
raise RegistrationError(f""This object is already registered as {self.registered_name}"")
generic_msg(
cmd=""register"",
args={
""name"": user_defined_name,
""objType"": self.objType,
""segments"": self.segments,
""values"": self.values,
""val_type"": self.values.objType,
},
)
self.registered_name = user_defined_name
return self
",[],0,[],/segarray.py_register
993,/home/amandapotts/git/arkouda/arkouda/segarray.py_unregister,"def unregister(self):
""""""
Unregister this SegArray object in the arkouda server which was previously
registered using register() and/or attached to using attach()
Returns
-------
None
Raises
------
RuntimeError
Raised if the server could not unregister the SegArray object from the Symbol Table
Notes
-----
Objects registered with the server are immune to deletion until
they are unregistered.
See Also
--------
register, attach, is_registered
""""""
from arkouda.util import unregister
if not self.registered_name:
raise RegistrationError(""This object is not registered"")
unregister(self.registered_name)
self.registered_name = None
",[],0,[],/segarray.py_unregister
994,/home/amandapotts/git/arkouda/arkouda/segarray.py_unregister_segarray_by_name,"def unregister_segarray_by_name(user_defined_name):
""""""
Using the defined name, remove the registered SegArray object from the Symbol Table
Parameters
----------
user_defined_name : str
user defined name which the SegArray object was registered under
Returns
-------
None
Raises
------
RuntimeError
Raised if the server could not unregister the SegArray object from the Symbol Table
See Also
--------
register, unregister, attach, is_registered
""""""
import warnings
from arkouda.util import unregister
warnings.warn(
""ak.SegArray.unregister_segarray_by_name() is deprecated. ""
""Please use ak.unregister() instead."",
DeprecationWarning,
)
return unregister(user_defined_name)
",[],0,[],/segarray.py_unregister_segarray_by_name
995,/home/amandapotts/git/arkouda/arkouda/segarray.py_attach,"def attach(cls, user_defined_name):
""""""
Using the defined name, attach to a SegArray that has been registered to the Symbol Table
Parameters
----------
user_defined_name : str
user defined name which the SegArray object was registered under
Returns
-------
SegArray
The resulting SegArray
Raises
------
RuntimeError
Raised if the server could not attach to the SegArray object
See Also
--------
register, unregister, is_registered
""""""
import warnings
from arkouda.util import attach
warnings.warn(
""ak.SegArray.attach() is deprecated. Please use ak.attach() instead."",
DeprecationWarning,
)
return attach(user_defined_name)
",[],0,[],/segarray.py_attach
996,/home/amandapotts/git/arkouda/arkouda/segarray.py_is_registered,"def is_registered(self) -> bool:
""""""
Checks if the name of the SegArray object is registered in the Symbol Table
Returns
-------
bool
True if SegArray is registered, false if not
See Also
--------
register, unregister, attach
""""""
from arkouda.util import is_registered
if self.registered_name is None:
return is_registered(self.segments.name, as_component=True) and is_registered(
self.values.name, as_component=True
)
else:
return is_registered(self.registered_name)
",[],0,[],/segarray.py_is_registered
997,/home/amandapotts/git/arkouda/arkouda/segarray.py_transfer,"def transfer(self, hostname: str, port: int_scalars):
""""""
Sends a Segmented Array to a different Arkouda server
Parameters
----------
hostname : str
The hostname where the Arkouda server intended to
receive the Segmented Array is running.
port : int_scalars
The port to send the array over. This needs to be an
open port (i.e., not one that the Arkouda server is
running on). This will open up `numLocales` ports,
each of which in succession, so will use ports of the
range {port..(port+numLocales)} (e.g., running an
Arkouda server of 4 nodes, port 1234 is passed as
`port`, Arkouda will use ports 1234, 1235, 1236,
and 1237 to send the array data).
This port much match the port passed to the call to
`ak.receive_array()`.
Returns
-------
A message indicating a complete transfer
Raises
------
ValueError
Raised if the op is not within the pdarray.BinOps set
TypeError
Raised if other is not a pdarray or the pdarray.dtype is not
a supported dtype
""""""
return generic_msg(
cmd=""sendArray"",
args={
""segments"": self.segments,
""values"": self.values,
""hostname"": hostname,
""port"": port,
""dtype"": self.dtype,
""objType"": ""segarray"",
},
)
",[],0,[],/segarray.py_transfer
998,/home/amandapotts/git/arkouda/arkouda/accessor.py___init__,"def __init__(self, name: str, accessor) -> None:
self._name = name
self._accessor = accessor
",[],0,[],/accessor.py___init__
999,/home/amandapotts/git/arkouda/arkouda/accessor.py___get__,"def __get__(self, obj, cls):
if obj is None:
return self._accessor
accessor_obj = self._accessor(obj)
object.__setattr__(obj, self._name, accessor_obj)
return accessor_obj
",[],0,[],/accessor.py___get__
1000,/home/amandapotts/git/arkouda/arkouda/accessor.py_string_operators,"def string_operators(cls):
for name in [""contains"", ""startswith"", ""endswith""]:
setattr(cls, name, cls._make_op(name))
return cls
",[],0,[],/accessor.py_string_operators
1001,/home/amandapotts/git/arkouda/arkouda/accessor.py_date_operators,"def date_operators(cls):
for name in [""floor"", ""ceil"", ""round""]:
setattr(cls, name, cls._make_op(name))
return cls
",[],0,[],/accessor.py_date_operators
1002,/home/amandapotts/git/arkouda/arkouda/accessor.py__make_op,"def _make_op(cls, name):
",[],0,[],/accessor.py__make_op
1003,/home/amandapotts/git/arkouda/arkouda/accessor.py_accessop,"def accessop(self, *args, **kwargs):
from . import Series
results = getattr(self.series.values, name)(*args, **kwargs)
return Series(data=results, index=self.series.index)
",[],0,[],/accessor.py_accessop
1004,/home/amandapotts/git/arkouda/arkouda/accessor.py___init__,"def __init__(self, series):
data = series.values
if not isinstance(data, Datetime):
raise AttributeError(""Can only use .dt accessor with datetimelike values"")
self.series = series
",[],0,[],/accessor.py___init__
1005,/home/amandapotts/git/arkouda/arkouda/accessor.py___init__,"def __init__(self, series):
data = series.values
if not (isinstance(data, Categorical) or isinstance(data, Strings)):
raise AttributeError(""Can only use .str accessor with string like values"")
self.series = series
",[],0,[],/accessor.py___init__
1006,/home/amandapotts/git/arkouda/arkouda/akscipy/special/_math.py_xlogy,"def xlogy(x: Union[pdarray, np.float64], y: pdarray):
""""""
Computes x * log(y).
Parameters
----------
x : pdarray or np.float64
x must have a datatype that is castable to float64
y : pdarray
Returns
-------
arkouda.pdarrayclass.pdarray
Examples
--------
>>> import arkouda as ak
>>> ak.connect()
>>> from arkouda.akscipy.special import xlogy
>>> xlogy( ak.array([1, 2, 3, 4]),  ak.array([5,6,7,8]))
array([1.6094379124341003 3.5835189384561099 5.8377304471659395 8.317766166719343])
>>> xlogy( 5.0, ak.array([1, 2, 3, 4]))
array([0.00000000000000000 3.4657359027997265 5.4930614433405491 6.9314718055994531])
""""""
if not isinstance(x, (np.float64, pdarray)) and np.can_cast(x, np.float64):
x = np.float64(x)
if isinstance(x, pdarray) and isinstance(y, pdarray):
if x.size == y.size:
return x * log(y)
else:
msg = ""x and y must have the same size.""
warn(msg, UserWarning)
return None
elif isinstance(x, np.float64) and isinstance(y, pdarray):
return x * log(y)
else:
msg = ""x and y must both be pdarrays or x must be castable to float64 and y must be a pdarray.""
warn(msg, UserWarning)
return None
","['float64', 'float64', 'float64', 'can_cast', 'float64', 'float64', 'float64']",7,"['can_cast(x, np.float64)', 'float64(x)']",/akscipy/special/_math.py_xlogy
1007,/home/amandapotts/git/arkouda/arkouda/array_api/_set_functions.py_unique_all,"def unique_all(x: Array, /) -> UniqueAllResult:
raise ValueError(""unique_all not implemented"")
",[],0,[],/array_api/_set_functions.py_unique_all
1008,/home/amandapotts/git/arkouda/arkouda/array_api/_set_functions.py_unique_counts,"def unique_counts(x: Array, /) -> UniqueCountsResult:
raise ValueError(""unique_counts not implemented"")
",[],0,[],/array_api/_set_functions.py_unique_counts
1009,/home/amandapotts/git/arkouda/arkouda/array_api/_set_functions.py_unique_inverse,"def unique_inverse(x: Array, /) -> UniqueInverseResult:
raise ValueError(""unique_inverse not implemented"")
",[],0,[],/array_api/_set_functions.py_unique_inverse
1010,/home/amandapotts/git/arkouda/arkouda/array_api/_set_functions.py_unique_values,"def unique_values(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.unique <numpy.unique>`.
See its docstring for more information.
""""""
res = ak.unique(x._array)
return Array._new(res)
",['unique'],1,[],/array_api/_set_functions.py_unique_values
1011,/home/amandapotts/git/arkouda/arkouda/array_api/_indexing_functions.py_take,"def take(x: Array, indices: Array, /, *, axis: Optional[int] = None) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.take <numpy.take>`.
See its docstring for more information.
""""""
if axis is None and x.ndim != 1:
raise ValueError(""axis must be specified for multidimensional arrays"")
if indices.ndim != 1:
raise ValueError(""indices must be 1D"")
if axis is None:
axis = 0
repMsg = generic_msg(
cmd=f""takeAlongAxis{x.ndim}D"",
args={
""x"": x._array,
""indices"": indices._array,
""axis"": axis,
},
)
return Array._new(create_pdarray(repMsg))
",['take'],1,[],/array_api/_indexing_functions.py_take
1012,/home/amandapotts/git/arkouda/arkouda/array_api/_typing.py___getitem__,"def __getitem__(self, key: int, /) -> _T_co | NestedSequence[_T_co]:
...
",[],0,[],/array_api/_typing.py___getitem__
1013,/home/amandapotts/git/arkouda/arkouda/array_api/_typing.py___len__,"def __len__(self, /) -> int:
...
",[],0,[],/array_api/_typing.py___len__
1014,/home/amandapotts/git/arkouda/arkouda/array_api/_typing.py___dlpack__,"def __dlpack__(self, /, *, stream: None = ...) -> PyCapsule:
...
",[],0,[],/array_api/_typing.py___dlpack__
1015,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_abs,"def abs(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`ak.abs`.
See its docstring for more information.
""""""
if x.dtype not in _numeric_dtypes:
raise TypeError(""Only numeric dtypes are allowed in abs"")
return Array._new(ak.abs(x._array))
",[],0,[],/array_api/_elementwise_functions.py_abs
1016,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_acos,"def acos(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.arccos`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in acos"")
return Array._new(ak.arccos(x._array))
",['arccos'],1,[],/array_api/_elementwise_functions.py_acos
1017,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_acosh,"def acosh(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`ak.arccosh`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in acosh"")
return Array._new(ak.arccosh(x._array))
",[],0,[],/array_api/_elementwise_functions.py_acosh
1018,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_add,"def add(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.add <numpy.add>`.
See its docstring for more information.
""""""
if x1.dtype not in _numeric_dtypes or x2.dtype not in _numeric_dtypes:
raise TypeError(""Only numeric dtypes are allowed in add"")
_result_type(x1.dtype, x2.dtype)
return Array._new(x1._array + x2._array)
",['add'],1,[],/array_api/_elementwise_functions.py_add
1019,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_asin,"def asin(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`ak.arcsin`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in asin"")
return Array._new(ak.arcsin(x._array))
",[],0,[],/array_api/_elementwise_functions.py_asin
1020,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_asinh,"def asinh(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`ak.arcsinh`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in asinh"")
return Array._new(ak.arcsinh(x._array))
",[],0,[],/array_api/_elementwise_functions.py_asinh
1021,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_atan,"def atan(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.arctan`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in atan"")
return Array._new(ak.arctan(x._array))
",['arctan'],1,[],/array_api/_elementwise_functions.py_atan
1022,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_atan2,"def atan2(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`ak.arctan2`.
See its docstring for more information.
""""""
if x1.dtype not in _real_floating_dtypes or x2.dtype not in _real_floating_dtypes:
raise TypeError(""Only real floating-point dtypes are allowed in atan2"")
_result_type(x1.dtype, x2.dtype)
return Array._new(ak.arctan2(x1._array, x2._array))
",[],0,[],/array_api/_elementwise_functions.py_atan2
1023,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_atanh,"def atanh(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`ak.arctanh`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in atanh"")
return Array._new(ak.arctanh(x._array))
",[],0,[],/array_api/_elementwise_functions.py_atanh
1024,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_bitwise_and,"def bitwise_and(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.bitwise_and`.
See its docstring for more information.
""""""
if (
x1.dtype not in _integer_or_boolean_dtypes
or x2.dtype not in _integer_or_boolean_dtypes
):
raise TypeError(""Only integer or boolean dtypes are allowed in bitwise_and"")
_result_type(x1.dtype, x2.dtype)
return Array._new(x1._array & x2._array)
",['bitwise_and'],1,[],/array_api/_elementwise_functions.py_bitwise_and
1025,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_bitwise_left_shift,"def bitwise_left_shift(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.left_shift <numpy.left_shift>`.
See its docstring for more information.
""""""
if x1.dtype not in _integer_dtypes or x2.dtype not in _integer_dtypes:
raise TypeError(""Only integer dtypes are allowed in bitwise_left_shift"")
_result_type(x1.dtype, x2.dtype)
if ak.any(x2._array < 0):
raise ValueError(""bitwise_left_shift(x1, x2) is only defined for x2 >= 0"")
return Array._new(x1._array << x2._array)
",['left_shift'],1,[],/array_api/_elementwise_functions.py_bitwise_left_shift
1026,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_bitwise_invert,"def bitwise_invert(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.invert <numpy.invert>`.
See its docstring for more information.
""""""
raise ValueError(""bitwise invert not implemented"")
",['invert'],1,[],/array_api/_elementwise_functions.py_bitwise_invert
1027,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_bitwise_or,"def bitwise_or(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.bitwise_or <numpy.bitwise_or>`.
See its docstring for more information.
""""""
if (
x1.dtype not in _integer_or_boolean_dtypes
or x2.dtype not in _integer_or_boolean_dtypes
):
raise TypeError(""Only integer or boolean dtypes are allowed in bitwise_or"")
_result_type(x1.dtype, x2.dtype)
return Array._new(x1._array | x2._array)
",['bitwise_or'],1,[],/array_api/_elementwise_functions.py_bitwise_or
1028,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_bitwise_right_shift,"def bitwise_right_shift(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.right_shift <numpy.right_shift>`.
See its docstring for more information.
""""""
if x1.dtype not in _integer_dtypes or x2.dtype not in _integer_dtypes:
raise TypeError(""Only integer dtypes are allowed in bitwise_right_shift"")
_result_type(x1.dtype, x2.dtype)
if ak.any(x2._array < 0):
raise ValueError(""bitwise_right_shift(x1, x2) is only defined for x2 >= 0"")
return Array._new(x1._array >> x2._array)
",['right_shift'],1,[],/array_api/_elementwise_functions.py_bitwise_right_shift
1029,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_bitwise_xor,"def bitwise_xor(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.bitwise_xor <numpy.bitwise_xor>`.
See its docstring for more information.
""""""
if (
x1.dtype not in _integer_or_boolean_dtypes
or x2.dtype not in _integer_or_boolean_dtypes
):
raise TypeError(""Only integer or boolean dtypes are allowed in bitwise_xor"")
_result_type(x1.dtype, x2.dtype)
return Array._new(x1._array ^ x2._array)
",['bitwise_xor'],1,[],/array_api/_elementwise_functions.py_bitwise_xor
1030,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_ceil,"def ceil(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.ceil <numpy.ceil>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in ceil"")
return Array._new(ak.ceil(x._array))
",['ceil'],1,[],/array_api/_elementwise_functions.py_ceil
1031,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_conj,"def conj(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.conj <numpy.conj>`.
See its docstring for more information.
""""""
raise ValueError(""conj not implemented - Arkouda does not support complex types"")
",['conj'],1,[],/array_api/_elementwise_functions.py_conj
1032,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_cos,"def cos(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.cos <numpy.cos>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in cos"")
return Array._new(ak.cos(x._array))
",['cos'],1,[],/array_api/_elementwise_functions.py_cos
1033,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_cosh,"def cosh(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.cosh <numpy.cosh>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in cosh"")
return Array._new(ak.cosh(x._array))
",['cosh'],1,[],/array_api/_elementwise_functions.py_cosh
1034,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_divide,"def divide(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.divide <numpy.divide>`.
See its docstring for more information.
""""""
if x1.dtype not in _floating_dtypes or x2.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in divide"")
_result_type(x1.dtype, x2.dtype)
return Array._new(x1._array / x2._array)
",['divide'],1,[],/array_api/_elementwise_functions.py_divide
1035,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_equal,"def equal(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.equal <numpy.equal>`.
See its docstring for more information.
""""""
_result_type(x1.dtype, x2.dtype)
return Array._new(x1._array == x2._array)
",['equal'],1,[],/array_api/_elementwise_functions.py_equal
1036,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_exp,"def exp(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.exp <numpy.exp>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in exp"")
return Array._new(ak.exp(x._array))
",['exp'],1,[],/array_api/_elementwise_functions.py_exp
1037,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_expm1,"def expm1(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.expm1 <numpy.expm1>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in exp"")
return Array._new(ak.expm1(x._array))
",['expm1'],1,[],/array_api/_elementwise_functions.py_expm1
1038,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_floor,"def floor(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.floor <numpy.floor>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in floor"")
return Array._new(ak.floor(x._array))
",['floor'],1,[],/array_api/_elementwise_functions.py_floor
1039,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_floor_divide,"def floor_divide(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.floor_divide <numpy.floor_divide>`.
See its docstring for more information.
""""""
raise ValueError(""exp not implemented"")
",['floor_divide'],1,[],/array_api/_elementwise_functions.py_floor_divide
1040,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_greater,"def greater(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.greater <numpy.greater>`.
See its docstring for more information.
""""""
if x1.dtype not in _real_numeric_dtypes or x2.dtype not in _real_numeric_dtypes:
raise TypeError(""Only real numeric dtypes are allowed in greater"")
_result_type(x1.dtype, x2.dtype)
return Array._new(x1._array > x2._array)
",['greater'],1,[],/array_api/_elementwise_functions.py_greater
1041,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_greater_equal,"def greater_equal(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.greater_equal <numpy.greater_equal>`.
See its docstring for more information.
""""""
if x1.dtype not in _real_numeric_dtypes or x2.dtype not in _real_numeric_dtypes:
raise TypeError(""Only real numeric dtypes are allowed in greater_equal"")
_result_type(x1.dtype, x2.dtype)
return Array._new(x1._array >= x2._array)
",['greater_equal'],1,[],/array_api/_elementwise_functions.py_greater_equal
1042,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_imag,"def imag(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.imag <numpy.imag>`.
See its docstring for more information.
""""""
raise ValueError(""imag not implemented"")
",['imag'],1,[],/array_api/_elementwise_functions.py_imag
1043,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_isfinite,"def isfinite(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.isfinite <numpy.isfinite>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in isfinite"")
return Array._new(ak.isfinite(x._array))
",['isfinite'],1,[],/array_api/_elementwise_functions.py_isfinite
1044,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_isinf,"def isinf(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.isinf <numpy.isinf>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in isinf"")
return Array._new(ak.isinf(x._array))
",['isinf'],1,[],/array_api/_elementwise_functions.py_isinf
1045,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_isnan,"def isnan(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.isnan <numpy.isnan>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in isnan"")
return Array._new(ak.isnan(x._array))
",['isnan'],1,[],/array_api/_elementwise_functions.py_isnan
1046,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_less,"def less(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.less <numpy.less>`.
See its docstring for more information.
""""""
if x1.dtype not in _real_numeric_dtypes or x2.dtype not in _real_numeric_dtypes:
raise TypeError(""Only real numeric dtypes are allowed in less"")
_result_type(x1.dtype, x2.dtype)
return Array._new(x1._array < x2._array)
",['less'],1,[],/array_api/_elementwise_functions.py_less
1047,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_less_equal,"def less_equal(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.less_equal <numpy.less_equal>`.
See its docstring for more information.
""""""
if x1.dtype not in _real_numeric_dtypes or x2.dtype not in _real_numeric_dtypes:
raise TypeError(""Only real numeric dtypes are allowed in less_equal"")
_result_type(x1.dtype, x2.dtype)
return Array._new(x1._array <= x2._array)
",['less_equal'],1,[],/array_api/_elementwise_functions.py_less_equal
1048,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_log,"def log(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.log <numpy.log>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in log"")
return Array._new(ak.log(x._array))
",['log'],1,[],/array_api/_elementwise_functions.py_log
1049,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_log1p,"def log1p(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.log1p <numpy.log1p>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in log"")
return Array._new(ak.log1p(x._array))
",['log1p'],1,[],/array_api/_elementwise_functions.py_log1p
1050,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_log2,"def log2(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.log2 <numpy.log2>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in log"")
return Array._new(ak.log2(x._array))
",['log2'],1,[],/array_api/_elementwise_functions.py_log2
1051,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_log10,"def log10(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.log10 <numpy.log10>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in log"")
return Array._new(ak.log10(x._array))
",['log10'],1,[],/array_api/_elementwise_functions.py_log10
1052,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_logaddexp,"def logaddexp(x1: Array, x2: Array) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.logaddexp <numpy.logaddexp>`.
See its docstring for more information.
""""""
raise ValueError(""logaddexp not implemented"")
",['logaddexp'],1,[],/array_api/_elementwise_functions.py_logaddexp
1053,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_logical_and,"def logical_and(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.logical_and <numpy.logical_and>`.
See its docstring for more information.
""""""
if x1.dtype not in _boolean_dtypes or x2.dtype not in _boolean_dtypes:
raise TypeError(""Only boolean dtypes are allowed in logical_and"")
_result_type(x1.dtype, x2.dtype)
return Array._new(x1._array & x2._array)
",['logical_and'],1,[],/array_api/_elementwise_functions.py_logical_and
1054,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_logical_not,"def logical_not(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.logical_not <numpy.logical_not>`.
See its docstring for more information.
""""""
repMsg = ak.generic_msg(
cmd=f""efunc{x._array.ndim}D"",
args={
""func"": ""not"",
""array"": x._array,
},
)
return ak.create_pdarray(repMsg)
",['logical_not'],1,[],/array_api/_elementwise_functions.py_logical_not
1055,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_logical_or,"def logical_or(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.logical_or <numpy.logical_or>`.
See its docstring for more information.
""""""
if x1.dtype not in _boolean_dtypes or x2.dtype not in _boolean_dtypes:
raise TypeError(""Only boolean dtypes are allowed in logical_or"")
_result_type(x1.dtype, x2.dtype)
return Array._new(x1._array | x2._array)
",['logical_or'],1,[],/array_api/_elementwise_functions.py_logical_or
1056,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_logical_xor,"def logical_xor(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.logical_xor <numpy.logical_xor>`.
See its docstring for more information.
""""""
if x1.dtype not in _boolean_dtypes or x2.dtype not in _boolean_dtypes:
raise TypeError(""Only boolean dtypes are allowed in logical_xor"")
_result_type(x1.dtype, x2.dtype)
return Array._new(x1._array ^ x2._array)
",['logical_xor'],1,[],/array_api/_elementwise_functions.py_logical_xor
1057,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_multiply,"def multiply(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.multiply <numpy.multiply>`.
See its docstring for more information.
""""""
if x1.dtype not in _numeric_dtypes or x2.dtype not in _numeric_dtypes:
raise TypeError(""Only numeric dtypes are allowed in multiply"")
_result_type(x1.dtype, x2.dtype)
return Array._new(x1._array * x2._array)
",['multiply'],1,[],/array_api/_elementwise_functions.py_multiply
1058,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_negative,"def negative(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.negative <numpy.negative>`.
See its docstring for more information.
""""""
if x.dtype not in _numeric_dtypes:
raise TypeError(""Only numeric dtypes are allowed in negative"")
return Array._new(-x._array)
",['negative'],1,[],/array_api/_elementwise_functions.py_negative
1059,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_not_equal,"def not_equal(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.not_equal <numpy.not_equal>`.
See its docstring for more information.
""""""
_result_type(x1.dtype, x2.dtype)
return Array._new(x1._array != x2._array)
",['not_equal'],1,[],/array_api/_elementwise_functions.py_not_equal
1060,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_positive,"def positive(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.positive <numpy.positive>`.
See its docstring for more information.
""""""
if x.dtype not in _numeric_dtypes:
raise TypeError(""Only numeric dtypes are allowed in positive"")
return Array._new(ak.abs(x._array))
",['positive'],1,[],/array_api/_elementwise_functions.py_positive
1061,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_pow,"def pow(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.power <numpy.power>`.
See its docstring for more information.
""""""
if x1.dtype not in _numeric_dtypes or x2.dtype not in _numeric_dtypes:
raise TypeError(""Only numeric dtypes are allowed in pow"")
_result_type(x1.dtype, x2.dtype)
return Array._new(ak.power(x1._array, x2._array))
",['power'],1,[],/array_api/_elementwise_functions.py_pow
1062,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_real,"def real(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.real <numpy.real>`.
See its docstring for more information.
""""""
raise ValueError(""real not implemented"")
",['real'],1,[],/array_api/_elementwise_functions.py_real
1063,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_remainder,"def remainder(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.remainder <numpy.remainder>`.
See its docstring for more information.
""""""
return Array._new(ak.mod(x1._array, x2._array))
",['remainder'],1,[],/array_api/_elementwise_functions.py_remainder
1064,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_round,"def round(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.round <numpy.round>`.
See its docstring for more information.
""""""
if x.dtype not in _numeric_dtypes:
raise TypeError(""Only numeric dtypes are allowed in round"")
return Array._new(ak.round(x._array))
",['round'],1,[],/array_api/_elementwise_functions.py_round
1065,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_sign,"def sign(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.sign <numpy.sign>`.
See its docstring for more information.
""""""
if x.dtype not in _numeric_dtypes:
raise TypeError(""Only numeric dtypes are allowed in sign"")
return Array._new(ak.sign(x._array))
",['sign'],1,[],/array_api/_elementwise_functions.py_sign
1066,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_sin,"def sin(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.sin <numpy.sin>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in sin"")
return Array._new(ak.sin(x._array))
",['sin'],1,[],/array_api/_elementwise_functions.py_sin
1067,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_sinh,"def sinh(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.sinh <numpy.sinh>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in sinh"")
return Array._new(ak.sinh(x._array))
",['sinh'],1,[],/array_api/_elementwise_functions.py_sinh
1068,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_square,"def square(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.square <numpy.square>`.
See its docstring for more information.
""""""
if x.dtype not in _numeric_dtypes:
raise TypeError(""Only numeric dtypes are allowed in sign"")
return Array._new(ak.sqrt(x._array))
",['square'],1,[],/array_api/_elementwise_functions.py_square
1069,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_sqrt,"def sqrt(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.sqrt <numpy.sqrt>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in sqrt"")
return Array._new(ak.sqrt(x._array))
",['sqrt'],1,[],/array_api/_elementwise_functions.py_sqrt
1070,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_subtract,"def subtract(x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.subtract <numpy.subtract>`.
See its docstring for more information.
""""""
if x1.dtype not in _numeric_dtypes or x2.dtype not in _numeric_dtypes:
raise TypeError(""Only numeric dtypes are allowed in subtract"")
_result_type(x1.dtype, x2.dtype)
return Array._new(x1._array - x2._array)
",['subtract'],1,[],/array_api/_elementwise_functions.py_subtract
1071,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_tan,"def tan(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.tan <numpy.tan>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in tan"")
return Array._new(ak.tan(x._array))
",['tan'],1,[],/array_api/_elementwise_functions.py_tan
1072,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_tanh,"def tanh(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.tanh <numpy.tanh>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in tanh"")
return Array._new(ak.tanh(x._array))
",['tanh'],1,[],/array_api/_elementwise_functions.py_tanh
1073,/home/amandapotts/git/arkouda/arkouda/array_api/_elementwise_functions.py_trunc,"def trunc(x: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.trunc <numpy.trunc>`.
See its docstring for more information.
""""""
if x.dtype not in _floating_dtypes:
raise TypeError(""Only floating-point dtypes are allowed in trunc"")
return Array._new(ak.trunc(x._array))
",['trunc'],1,[],/array_api/_elementwise_functions.py_trunc
1074,/home/amandapotts/git/arkouda/arkouda/array_api/linalg.py_matmul,"def matmul(x1: Array, x2: Array, /) -> Array:
""""""
Matrix product of two arrays.
""""""
from ._array_object import Array
if x1._array.ndim < 2 and x2._array.ndim < 2:
raise ValueError(
""matmul requires at least one array argument to have more than two dimensions""
)
x1b, x2b, tmp_x1, tmp_x2 = broadcast_if_needed(x1._array, x2._array)
repMsg = generic_msg(
cmd=f""matMul{len(x1b.shape)}D"",
args={
""x1"": x1b.name,
""x2"": x2b.name,
},
)
if tmp_x1:
del x1b
if tmp_x2:
del x2b
return Array._new(create_pdarray(repMsg))
",[],0,[],/array_api/linalg.py_matmul
1075,/home/amandapotts/git/arkouda/arkouda/array_api/linalg.py_tensordot,"def tensordot():
raise ValueError(""tensordot not implemented"")
",[],0,[],/array_api/linalg.py_tensordot
1076,/home/amandapotts/git/arkouda/arkouda/array_api/linalg.py_matrix_transpose,"def matrix_transpose(x: Array) -> Array:
""""""
Matrix product of two arrays.
""""""
from ._array_object import Array
if x._array.ndim < 2:
raise ValueError(
""matrix_transpose requires the array to have more than two dimensions""
)
repMsg = generic_msg(
cmd=f""transpose{x._array.ndim}D"",
args={
""array"": x._array.name,
},
)
return Array._new(create_pdarray(repMsg))
",[],0,[],/array_api/linalg.py_matrix_transpose
1077,/home/amandapotts/git/arkouda/arkouda/array_api/linalg.py_vecdot,"def vecdot(x1: Array, x2: Array, /, *, axis: int = -1) -> Array:
from ._array_object import Array
x1b, x2b, tmp_x1, tmp_x2 = broadcast_if_needed(x1._array, x2._array)
repMsg = generic_msg(
cmd=f""vecdot{len(x1b.shape)}D"",
args={
""x1"": x1b.name,
""x2"": x2b.name,
""bcShape"": x1b.shape,
""axis"": axis,
},
)
if tmp_x1:
del x1b
if tmp_x2:
del x2b
return Array._new(create_pdarray(repMsg))
",[],0,[],/array_api/linalg.py_vecdot
1078,/home/amandapotts/git/arkouda/arkouda/array_api/_creation_functions.py__check_valid_dtype,"def _check_valid_dtype(dtype):
for d in (None,) + _all_dtypes:
if dtype is d:
return
raise ValueError(""dtype must be one of the supported dtypes"")
",[],0,[],/array_api/_creation_functions.py__check_valid_dtype
1079,/home/amandapotts/git/arkouda/arkouda/array_api/_creation_functions.py_asarray,"def asarray(
obj: Union[
Array,
bool,
int,
float,
NestedSequence[bool | int | float],
SupportsBufferProtocol,
],
/,
dtype: Optional[Dtype] = None,
device: Optional[Device] = None,
copy: Optional[bool] = None,
",[],0,[],/array_api/_creation_functions.py_asarray
1080,/home/amandapotts/git/arkouda/arkouda/array_api/_creation_functions.py_arange,"def arange(
start: Union[int, float],
/,
stop: Optional[Union[int, float]] = None,
step: Union[int, float] = 1,
dtype: Optional[Dtype] = None,
device: Optional[Device] = None,
",[],0,[],/array_api/_creation_functions.py_arange
1081,/home/amandapotts/git/arkouda/arkouda/array_api/_creation_functions.py_empty,"def empty(
shape: Union[int, Tuple[int, ...]],
dtype: Optional[Dtype] = None,
device: Optional[Device] = None,
",[],0,[],/array_api/_creation_functions.py_empty
1082,/home/amandapotts/git/arkouda/arkouda/array_api/_creation_functions.py_empty_like,"def empty_like(
x: Array, /, *, dtype: Optional[Dtype] = None, device: Optional[Device] = None
",[],0,[],/array_api/_creation_functions.py_empty_like
1083,/home/amandapotts/git/arkouda/arkouda/array_api/_creation_functions.py_eye,"def eye(
n_rows: int,
n_cols: Optional[int] = None,
/,
k: int = 0,
dtype: Optional[Dtype] = None,
device: Optional[Device] = None,
",[],0,[],/array_api/_creation_functions.py_eye
1084,/home/amandapotts/git/arkouda/arkouda/array_api/_creation_functions.py_from_dlpack,"def from_dlpack(x: object, /) -> Array:
raise ValueError(""Not implemented"")
",[],0,[],/array_api/_creation_functions.py_from_dlpack
1085,/home/amandapotts/git/arkouda/arkouda/array_api/_creation_functions.py_full,"def full(
shape: Union[int, Tuple[int, ...]],
fill_value: Union[int, float],
dtype: Optional[Dtype] = None,
device: Optional[Device] = None,
",[],0,[],/array_api/_creation_functions.py_full
1086,/home/amandapotts/git/arkouda/arkouda/array_api/_creation_functions.py_full_like,"def full_like(
x: Array,
/,
fill_value: Union[int, float],
dtype: Optional[Dtype] = None,
device: Optional[Device] = None,
",[],0,[],/array_api/_creation_functions.py_full_like
1087,/home/amandapotts/git/arkouda/arkouda/array_api/_creation_functions.py_linspace,"def linspace(
start: Union[int, float],
stop: Union[int, float],
/,
num: int,
dtype: Optional[Dtype] = None,
device: Optional[Device] = None,
endpoint: bool = True,
",[],0,[],/array_api/_creation_functions.py_linspace
1088,/home/amandapotts/git/arkouda/arkouda/array_api/_creation_functions.py_meshgrid,"def meshgrid(*arrays: Array, indexing: str = ""xy"") -> List[Array]:
raise ValueError(""Not implemented"")
",[],0,[],/array_api/_creation_functions.py_meshgrid
1089,/home/amandapotts/git/arkouda/arkouda/array_api/_creation_functions.py_ones,"def ones(
shape: Union[int, Tuple[int, ...]],
dtype: Optional[Dtype] = None,
device: Optional[Device] = None,
",[],0,[],/array_api/_creation_functions.py_ones
1090,/home/amandapotts/git/arkouda/arkouda/array_api/_creation_functions.py_ones_like,"def ones_like(
x: Array, /, *, dtype: Optional[Dtype] = None, device: Optional[Device] = None
",[],0,[],/array_api/_creation_functions.py_ones_like
1091,/home/amandapotts/git/arkouda/arkouda/array_api/_creation_functions.py_tril,"def tril(x: Array, /, *, k: int = 0) -> Array:
from ._array_object import Array
repMsg = generic_msg(
cmd=f""tril{x._array.ndim}D"",
args={
""array"": x._array.name,
""diag"": k,
},
)
return Array._new(create_pdarray(repMsg))
",[],0,[],/array_api/_creation_functions.py_tril
1092,/home/amandapotts/git/arkouda/arkouda/array_api/_creation_functions.py_triu,"def triu(x: Array, /, *, k: int = 0) -> Array:
from ._array_object import Array
repMsg = generic_msg(
cmd=f""triu{x._array.ndim}D"",
args={
""array"": x._array.name,
""diag"": k,
},
)
return Array._new(create_pdarray(repMsg))
",[],0,[],/array_api/_creation_functions.py_triu
1093,/home/amandapotts/git/arkouda/arkouda/array_api/_creation_functions.py_zeros,"def zeros(
shape: Union[int, Tuple[int, ...]],
/,
dtype: Optional[Dtype] = None,
device: Optional[Device] = None,
",[],0,[],/array_api/_creation_functions.py_zeros
1094,/home/amandapotts/git/arkouda/arkouda/array_api/_creation_functions.py_zeros_like,"def zeros_like(
x: Array, /, *, dtype: Optional[Dtype] = None, device: Optional[Device] = None
",[],0,[],/array_api/_creation_functions.py_zeros_like
1095,/home/amandapotts/git/arkouda/arkouda/array_api/_sorting_functions.py_argsort,"def argsort(
x: Array, /, *, axis: int = -1, descending: bool = False, stable: bool = True
",[],0,[],/array_api/_sorting_functions.py_argsort
1096,/home/amandapotts/git/arkouda/arkouda/array_api/_sorting_functions.py_sort,"def sort(
x: Array, /, *, axis: int = -1, descending: bool = False, stable: bool = True
",[],0,[],/array_api/_sorting_functions.py_sort
1097,/home/amandapotts/git/arkouda/arkouda/array_api/_data_type_functions.py_astype,"def astype(x: Array, dtype: Dtype, /, *, copy: bool = True) -> Array:
if not copy and dtype == x.dtype:
return x
return Array._new(ak.akcast(x._array, dtype))
",[],0,[],/array_api/_data_type_functions.py_astype
1098,/home/amandapotts/git/arkouda/arkouda/array_api/_data_type_functions.py_can_cast,"def can_cast(from_: Union[Dtype, Array], to: Dtype, /) -> bool:
""""""
Array API compatible wrapper for :py:func:`np.can_cast <numpy.can_cast>`.
See its docstring for more information.
""""""
if isinstance(from_, Array):
from_ = from_.dtype
elif from_ not in _all_dtypes:
raise TypeError(f""{from_=}, but should be an array_api array or dtype"")
if to not in _all_dtypes:
raise TypeError(f""{to=}, but should be a dtype"")
try:
dtype = _result_type(from_, to)
return to == dtype
except TypeError:
return False
",['can_cast'],1,[],/array_api/_data_type_functions.py_can_cast
1099,/home/amandapotts/git/arkouda/arkouda/array_api/_data_type_functions.py_isdtype,"def isdtype(
dtype: Dtype, kind: Union[Dtype, str, Tuple[Union[Dtype, str], ...]]
",[],0,[],/array_api/_data_type_functions.py_isdtype
1100,/home/amandapotts/git/arkouda/arkouda/array_api/_data_type_functions.py_result_type,"def result_type(*arrays_and_dtypes: Union[Array, Dtype]) -> Dtype:
""""""
Array API compatible wrapper for :py:func:`np.result_type <numpy.result_type>`.
See its docstring for more information.
""""""
A = []
for a in arrays_and_dtypes:
if isinstance(a, Array):
a = a.dtype
elif isinstance(a, np.ndarray) or a not in _all_dtypes:
raise TypeError(""result_type() inputs must be array_api arrays or dtypes"")
A.append(a)
if len(A) == 0:
raise ValueError(""at least one array or dtype is required"")
elif len(A) == 1:
return A[0]
else:
t = A[0]
for t2 in A[1:]:
t = _result_type(t, t2)
return t
","['result_type', 'ndarray']",2,[],/array_api/_data_type_functions.py_result_type
1101,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py__new,"def _new(cls, x, /, empty: bool = False):
""""""
This is a private method for initializing the array API Array
object.
Functions outside of the array_api submodule should not use this
method. Use one of the creation functions instead, such as
``asarray``.
""""""
obj = super().__new__(cls)
obj._array = x
obj._empty = empty
return obj
",[],0,[],/array_api/_array_object.py__new
1102,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___new__,"def __new__(cls, *args, **kwargs):
raise TypeError(
""The array_api Array object should not be instantiated directly. \
Use an array creation function, such as asarray(), instead.""
)
",[],0,[],/array_api/_array_object.py___new__
1103,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py_tolist,"def tolist(self):
""""""
Convert the array to a Python list or nested lists
""""""
x = self._array.to_list()
if self.shape == ():
return x[0]
else:
return x
",[],0,[],/array_api/_array_object.py_tolist
1104,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py_to_ndarray,"def to_ndarray(self):
""""""
Convert the array to a numpy ndarray
""""""
return self._array.to_ndarray()
",[],0,[],/array_api/_array_object.py_to_ndarray
1105,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___str__,"def __str__(self: Array, /) -> str:
""""""
Performs the operation __str__.
""""""
return self._array.__str__()
",[],0,[],/array_api/_array_object.py___str__
1106,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___repr__,"def __repr__(self: Array, /) -> str:
""""""
Performs the operation __repr__.
""""""
return self._array.__repr__()
",[],0,[],/array_api/_array_object.py___repr__
1107,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py__check_allowed_dtypes,"def _check_allowed_dtypes(
self, other: bool | int | float | Array, dtype_category: str, op: str
",[],0,[],/array_api/_array_object.py__check_allowed_dtypes
1108,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py__promote_scalar,"def _promote_scalar(self, scalar) -> Array:
""""""
Returns a promoted version of a Python scalar appropriate for use with
operations on self.
This may raise an OverflowError in cases where the scalar is an
integer that is too large to fit in a NumPy integer dtype, or
TypeError when the scalar type is incompatible with the dtype of self.
""""""
if isinstance(scalar, bool):
if self.dtype not in _boolean_dtypes:
raise TypeError(
""Python bool scalars can only be promoted with bool arrays""
)
elif isinstance(scalar, int):
if self.dtype in _boolean_dtypes:
raise TypeError(
""Python int scalars cannot be promoted with bool arrays""
)
if self.dtype in _integer_dtypes:
info = np.iinfo(int)
if not (info.min <= scalar <= info.max):
raise OverflowError(
""Python int scalars must be within the bounds of the dtype for integer arrays""
)
elif isinstance(scalar, float):
if self.dtype not in _floating_dtypes:
raise TypeError(
""Python float scalars can only be promoted with floating-point arrays.""
)
elif isinstance(scalar, complex):
if self.dtype not in _complex_floating_dtypes:
raise TypeError(
""Python complex scalars can only be promoted with complex floating-point arrays.""
)
else:
raise TypeError(""'scalar' must be a Python scalar"")
return Array._new(np.array(scalar, self.dtype))
","['iinfo', 'array']",2,"['iinfo(int)', 'array(scalar, self.dtype))']",/array_api/_array_object.py__promote_scalar
1109,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py__normalize_two_args,"def _normalize_two_args(x1, x2) -> Tuple[Array, Array]:
""""""
Normalize inputs to two arg functions to fix type promotion rules
NumPy deviates from the spec type promotion rules in cases where one
argument is 0-dimensional and the other is not. For example:
>>> import numpy as np
>>> a = np.array([1.0], dtype=np.float32)
>>> b = np.array(1.0, dtype=np.float64)
>>> np.add(a, b) # The spec says this should be float64
array([2.], dtype=float32)
To fix this, we add a dimension to the 0-dimension array before passing it
through. This works because a dimension would be added anyway from
broadcasting, so the resulting shape is the same, but this prevents NumPy
from not promoting the dtype.
""""""
if x1.ndim == 0 and x2.ndim != 0:
x1 = Array._new(x1._array[None])
elif x2.ndim == 0 and x1.ndim != 0:
x2 = Array._new(x2._array[None])
return (x1, x2)
","['array', 'float32', 'array', 'float64', 'add']",5,"['array([1.0], dtype=np.float32)', 'array(1.0, dtype=np.float64)', 'add(a, b)']",/array_api/_array_object.py__normalize_two_args
1110,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py__validate_index,"def _validate_index(self, key):
raise IndexError(""not implemented"")
",[],0,[],/array_api/_array_object.py__validate_index
1111,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___abs__,"def __abs__(self: Array, /) -> Array:
""""""
Performs the operation __abs__.
""""""
return self
",[],0,[],/array_api/_array_object.py___abs__
1112,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___add__,"def __add__(self: Array, other: Union[int, float, Array], /) -> Array:
if isinstance(other, (int, float)):
return Array._new(self._array + other)
else:
return Array._new(self._array + other._array)
",[],0,[],/array_api/_array_object.py___add__
1113,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___and__,"def __and__(self: Array, other: Union[int, bool, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___and__
1114,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___array_namespace__,"def __array_namespace__(
self: Array, /, *, api_version: Optional[str] = None
",[],0,[],/array_api/_array_object.py___array_namespace__
1115,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___bool__,"def __bool__(self: Array, /) -> bool:
return True
",[],0,[],/array_api/_array_object.py___bool__
1116,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___complex__,"def __complex__(self: Array, /) -> complex:
return complex(1)
",[],0,[],/array_api/_array_object.py___complex__
1117,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___dlpack_device__,"def __dlpack_device__(self: Array, /) -> Tuple[IntEnum, int]:
raise ValueError(""Not implemented"")
",[],0,[],/array_api/_array_object.py___dlpack_device__
1118,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___eq__,"def __eq__(self: object, other: object, /) -> bool:
if isinstance(other, Array) and isinstance(self, Array):
return self._array == other._array
else:
raise ValueError(""Not implemented"")
",[],0,[],/array_api/_array_object.py___eq__
1119,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___float__,"def __float__(self: Array, /) -> float:
return 1.0
",[],0,[],/array_api/_array_object.py___float__
1120,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___floordiv__,"def __floordiv__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___floordiv__
1121,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___ge__,"def __ge__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___ge__
1122,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___getitem__,"def __getitem__(
self: Array,
key: Union[int, slice, Tuple[Union[int, slice], ...], Array],
/,
",[],0,[],/array_api/_array_object.py___getitem__
1123,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___gt__,"def __gt__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___gt__
1124,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___int__,"def __int__(self: Array, /) -> int:
return 0
",[],0,[],/array_api/_array_object.py___int__
1125,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___index__,"def __index__(self: Array, /) -> int:
return 0
",[],0,[],/array_api/_array_object.py___index__
1126,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___invert__,"def __invert__(self: Array, /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___invert__
1127,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___le__,"def __le__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___le__
1128,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___lshift__,"def __lshift__(self: Array, other: Union[int, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___lshift__
1129,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___lt__,"def __lt__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___lt__
1130,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___matmul__,"def __matmul__(self: Array, other: Array, /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___matmul__
1131,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___mod__,"def __mod__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___mod__
1132,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___mul__,"def __mul__(self: Array, other: Union[int, float, Array], /) -> Array:
if isinstance(other, (int, float)):
return Array._new(self._array * other)
else:
return Array._new(self._array * other._array)
",[],0,[],/array_api/_array_object.py___mul__
1133,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___ne__,"def __ne__(self: object, other: object, /) -> bool:
raise ValueError(""Not implemented"")
",[],0,[],/array_api/_array_object.py___ne__
1134,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___neg__,"def __neg__(self: Array, /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___neg__
1135,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___or__,"def __or__(self: Array, other: Union[int, bool, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___or__
1136,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___pos__,"def __pos__(self: Array, /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___pos__
1137,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___pow__,"def __pow__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___pow__
1138,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___rshift__,"def __rshift__(self: Array, other: Union[int, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___rshift__
1139,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___setitem__,"def __setitem__(
self,
key: Union[int, slice, Tuple[Union[int, slice], ...], Array],
value: Union[int, float, bool, Array],
/,
",[],0,[],/array_api/_array_object.py___setitem__
1140,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___sub__,"def __sub__(self: Array, other: Union[int, float, Array], /) -> Array:
if isinstance(other, (int, float)):
return Array._new(self._array - other)
else:
return Array._new(self._array - other._array)
",[],0,[],/array_api/_array_object.py___sub__
1141,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___truediv__,"def __truediv__(self: Array, other: Union[float, Array], /) -> Array:
if isinstance(other, (int, float)):
return Array._new(self._array / other)
else:
return Array._new(self._array / other._array)
",[],0,[],/array_api/_array_object.py___truediv__
1142,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___xor__,"def __xor__(self: Array, other: Union[int, bool, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___xor__
1143,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___iadd__,"def __iadd__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___iadd__
1144,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___radd__,"def __radd__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___radd__
1145,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___iand__,"def __iand__(self: Array, other: Union[int, bool, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___iand__
1146,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___rand__,"def __rand__(self: Array, other: Union[int, bool, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___rand__
1147,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___ifloordiv__,"def __ifloordiv__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___ifloordiv__
1148,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___rfloordiv__,"def __rfloordiv__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___rfloordiv__
1149,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___ilshift__,"def __ilshift__(self: Array, other: Union[int, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___ilshift__
1150,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___rlshift__,"def __rlshift__(self: Array, other: Union[int, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___rlshift__
1151,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___imatmul__,"def __imatmul__(self: Array, other: Array, /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___imatmul__
1152,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___rmatmul__,"def __rmatmul__(self: Array, other: Array, /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___rmatmul__
1153,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___imod__,"def __imod__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___imod__
1154,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___rmod__,"def __rmod__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___rmod__
1155,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___imul__,"def __imul__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___imul__
1156,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___rmul__,"def __rmul__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___rmul__
1157,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___ior__,"def __ior__(self: Array, other: Union[int, bool, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___ior__
1158,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___ror__,"def __ror__(self: Array, other: Union[int, bool, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___ror__
1159,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___ipow__,"def __ipow__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___ipow__
1160,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___rpow__,"def __rpow__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___rpow__
1161,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___irshift__,"def __irshift__(self: Array, other: Union[int, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___irshift__
1162,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___rrshift__,"def __rrshift__(self: Array, other: Union[int, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___rrshift__
1163,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___isub__,"def __isub__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___isub__
1164,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___rsub__,"def __rsub__(self: Array, other: Union[int, float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___rsub__
1165,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___itruediv__,"def __itruediv__(self: Array, other: Union[float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___itruediv__
1166,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___rtruediv__,"def __rtruediv__(self: Array, other: Union[float, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___rtruediv__
1167,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___ixor__,"def __ixor__(self: Array, other: Union[int, bool, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___ixor__
1168,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py___rxor__,"def __rxor__(self: Array, other: Union[int, bool, Array], /) -> Array:
return self
",[],0,[],/array_api/_array_object.py___rxor__
1169,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py_to_device,"def to_device(self: Array, device: Device, /, stream: None = None) -> Array:
raise ValueError(""Not implemented"")
",[],0,[],/array_api/_array_object.py_to_device
1170,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py_dtype,"def dtype(self) -> Dtype:
return self._array.dtype
",[],0,[],/array_api/_array_object.py_dtype
1171,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py_device,"def device(self) -> Device:
return ""cpu""
",[],0,[],/array_api/_array_object.py_device
1172,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py_mT,"def mT(self) -> Array:
return self
",[],0,[],/array_api/_array_object.py_mT
1173,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py_ndim,"def ndim(self) -> int:
return len(self._array.shape)
",[],0,[],/array_api/_array_object.py_ndim
1174,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py_shape,"def shape(self) -> Tuple[int, ...]:
return tuple(self._array.shape)
",[],0,[],/array_api/_array_object.py_shape
1175,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py_size,"def size(self) -> int:
return int(self._array.size)
",[],0,[],/array_api/_array_object.py_size
1176,/home/amandapotts/git/arkouda/arkouda/array_api/_array_object.py_T,"def T(self) -> Array:
raise ValueError(""Not implemented"")
",[],0,[],/array_api/_array_object.py_T
1177,/home/amandapotts/git/arkouda/arkouda/array_api/_searching_functions.py_argmax,"def argmax(x: Array, /, *, axis: Optional[int] = None, keepdims: bool = False) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.argmax <numpy.argmax>`.
See its docstring for more information.
""""""
if x.dtype not in _real_numeric_dtypes:
raise TypeError(""Only real numeric dtypes are allowed in argmax"")
return Array._new(ak.argmax(x._array))
",['argmax'],1,[],/array_api/_searching_functions.py_argmax
1178,/home/amandapotts/git/arkouda/arkouda/array_api/_searching_functions.py_argmin,"def argmin(x: Array, /, *, axis: Optional[int] = None, keepdims: bool = False) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.argmin <numpy.argmin>`.
See its docstring for more information.
""""""
if x.dtype not in _real_numeric_dtypes:
raise TypeError(""Only real numeric dtypes are allowed in argmin"")
return Array._new(ak.argmin(x._array))
",['argmin'],1,[],/array_api/_searching_functions.py_argmin
1179,/home/amandapotts/git/arkouda/arkouda/array_api/_searching_functions.py_nonzero,"def nonzero(x: Array, /) -> Tuple[Array, ...]:
""""""
Array API compatible wrapper for :py:func:`np.nonzero <numpy.nonzero>`.
See its docstring for more information.
""""""
raise ValueError(""nonzero not implemented"")
",['nonzero'],1,[],/array_api/_searching_functions.py_nonzero
1180,/home/amandapotts/git/arkouda/arkouda/array_api/_searching_functions.py_where,"def where(condition: Array, x1: Array, x2: Array, /) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.where <numpy.where>`.
See its docstring for more information.
""""""
raise ValueError(""where not implemented"")
",['where'],1,[],/array_api/_searching_functions.py_where
1181,/home/amandapotts/git/arkouda/arkouda/array_api/_dtypes.py__result_type,"def _result_type(type1, type2):
if (type1, type2) in _promotion_table:
return _promotion_table[type1, type2]
raise TypeError(f""{type1} and {type2} cannot be type promoted together"")
",[],0,[],/array_api/_dtypes.py__result_type
1182,/home/amandapotts/git/arkouda/arkouda/array_api/_statistical_functions.py_max,"def max(
x: Array,
/,
axis: Optional[Union[int, Tuple[int, ...]]] = None,
keepdims: bool = False,
",[],0,[],/array_api/_statistical_functions.py_max
1183,/home/amandapotts/git/arkouda/arkouda/array_api/_statistical_functions.py_mean,"def mean(
x: Array,
/,
axis: Optional[Union[int, Tuple[int, ...]]] = None,
keepdims: bool = False,
",[],0,[],/array_api/_statistical_functions.py_mean
1184,/home/amandapotts/git/arkouda/arkouda/array_api/_statistical_functions.py_min,"def min(
x: Array,
/,
axis: Optional[Union[int, Tuple[int, ...]]] = None,
keepdims: bool = False,
",[],0,[],/array_api/_statistical_functions.py_min
1185,/home/amandapotts/git/arkouda/arkouda/array_api/_statistical_functions.py_prod,"def prod(
x: Array,
/,
axis: Optional[Union[int, Tuple[int, ...]]] = None,
dtype: Optional[Dtype] = None,
keepdims: bool = False,
",[],0,[],/array_api/_statistical_functions.py_prod
1186,/home/amandapotts/git/arkouda/arkouda/array_api/_statistical_functions.py_std,"def std(
x: Array,
/,
axis: Optional[Union[int, Tuple[int, ...]]] = None,
correction: Union[int, float] = 0.0,
keepdims: bool = False,
",[],0,[],/array_api/_statistical_functions.py_std
1187,/home/amandapotts/git/arkouda/arkouda/array_api/_statistical_functions.py_sum,"def sum(
x: Array,
/,
axis: Optional[Union[int, Tuple[int, ...]]] = None,
dtype: Optional[Dtype] = None,
keepdims: bool = False,
",[],0,[],/array_api/_statistical_functions.py_sum
1188,/home/amandapotts/git/arkouda/arkouda/array_api/_statistical_functions.py_var,"def var(
x: Array,
/,
axis: Optional[Union[int, Tuple[int, ...]]] = None,
correction: Union[int, float] = 0.0,
keepdims: bool = False,
",[],0,[],/array_api/_statistical_functions.py_var
1189,/home/amandapotts/git/arkouda/arkouda/array_api/_utility_functions.py_all,"def all(
x: Array,
/,
axis: Optional[Union[int, Tuple[int, ...]]] = None,
keepdims: bool = False,
",[],0,[],/array_api/_utility_functions.py_all
1190,/home/amandapotts/git/arkouda/arkouda/array_api/_utility_functions.py_any,"def any(
x: Array,
/,
axis: Optional[Union[int, Tuple[int, ...]]] = None,
keepdims: bool = False,
",[],0,[],/array_api/_utility_functions.py_any
1191,/home/amandapotts/git/arkouda/arkouda/array_api/_manipulation_functions.py_broadcast_arrays,"def broadcast_arrays(*arrays: Array) -> List[Array]:
""""""
Array API compatible wrapper for :py:func:`np.broadcast_arrays <numpy.broadcast_arrays>`.
See its docstring for more information.
""""""
shapes = [a.shape for a in arrays]
bcShape = shapes[0]
for shape in shapes[1:]:
bcShape = broadcast_dims(bcShape, shape)
return [broadcast_to(a, shape=bcShape) for a in arrays]
",['broadcast_arrays'],1,[],/array_api/_manipulation_functions.py_broadcast_arrays
1192,/home/amandapotts/git/arkouda/arkouda/array_api/_manipulation_functions.py_broadcast_to,"def broadcast_to(x: Array, /, shape: Tuple[int, ...]) -> Array:
""""""
Broadcast the array to the specified shape.
""""""
try:
return Array._new(
create_pdarray(
cast(
str,
generic_msg(
cmd=f""broadcastTo{x.ndim}Dx{len(shape)}D"",
args={
""name"": x._array,
""shape"": shape,
},
),
)
)
)
except RuntimeError as e:
raise ValueError(f""Failed to broadcast array: {e}"")
",[],0,[],/array_api/_manipulation_functions.py_broadcast_to
1193,/home/amandapotts/git/arkouda/arkouda/array_api/_manipulation_functions.py_concat,"def concat(
arrays: Union[Tuple[Array, ...], List[Array]], /, *, axis: Optional[int] = 0
",[],0,[],/array_api/_manipulation_functions.py_concat
1194,/home/amandapotts/git/arkouda/arkouda/array_api/_manipulation_functions.py_expand_dims,"def expand_dims(x: Array, /, *, axis: int) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.expand_dims <numpy.expand_dims>`.
See its docstring for more information.
""""""
try:
return Array._new(
create_pdarray(
cast(
str,
generic_msg(
cmd=f""expandDims{x.ndim}D"",
args={
""name"": x._array,
""axis"": axis,
},
),
)
)
)
except RuntimeError as e:
raise (IndexError(f""Failed to expand array dimensions: {e}""))
",['expand_dims'],1,[],/array_api/_manipulation_functions.py_expand_dims
1195,/home/amandapotts/git/arkouda/arkouda/array_api/_manipulation_functions.py_flip,"def flip(x: Array, /, *, axis: Optional[Union[int, Tuple[int, ...]]] = None) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.flip <numpy.flip>`.
See its docstring for more information.
""""""
axisList = []
if axis is not None:
axisList = list(axis) if isinstance(axis, tuple) else [axis]
try:
return Array._new(
create_pdarray(
cast(
str,
generic_msg(
cmd=f""flipAll{x.ndim}D"" if axis is None else f""flip{x.ndim}D"",
args={
""name"": x._array,
""nAxes"": len(axisList),
""axis"": axisList,
},
),
)
)
)
except RuntimeError as e:
raise IndexError(f""Failed to flip array: {e}"")
",['flip'],1,[],/array_api/_manipulation_functions.py_flip
1196,/home/amandapotts/git/arkouda/arkouda/array_api/_manipulation_functions.py_permute_dims,"def permute_dims(x: Array, /, axes: Tuple[int, ...]) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.transpose <numpy.transpose>`.
See its docstring for more information.
""""""
try:
return Array._new(
create_pdarray(
cast(
str,
generic_msg(
cmd=f""permuteDims{x.ndim}D"",
args={
""name"": x._array,
""axes"": axes,
},
),
)
)
)
except RuntimeError as e:
raise IndexError(f""Failed to permute array dimensions: {e}"")
",['transpose'],1,[],/array_api/_manipulation_functions.py_permute_dims
1197,/home/amandapotts/git/arkouda/arkouda/array_api/_manipulation_functions.py_reshape,"def reshape(
x: Array, /, shape: Tuple[int, ...], *, copy: Optional[bool] = None
",[],0,[],/array_api/_manipulation_functions.py_reshape
1198,/home/amandapotts/git/arkouda/arkouda/array_api/_manipulation_functions.py_roll,"def roll(
x: Array,
/,
shift: Union[int, Tuple[int, ...]],
axis: Optional[Union[int, Tuple[int, ...]]] = None,
",[],0,[],/array_api/_manipulation_functions.py_roll
1199,/home/amandapotts/git/arkouda/arkouda/array_api/_manipulation_functions.py_squeeze,"def squeeze(x: Array, /, axis: Union[int, Tuple[int, ...]]) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.squeeze <numpy.squeeze>`.
See its docstring for more information.
""""""
nAxes = len(axis) if isinstance(axis, tuple) else 1
try:
return Array._new(
create_pdarray(
cast(
str,
generic_msg(
cmd=f""squeeze{x.ndim}Dx{x.ndim - nAxes}D"",
args={
""name"": x._array,
""nAxes"": nAxes,
""axes"": list(axis) if isinstance(axis, tuple) else [axis],
},
),
)
)
)
except RuntimeError as e:
raise ValueError(f""Failed to squeeze array: {e}"")
",['squeeze'],1,[],/array_api/_manipulation_functions.py_squeeze
1200,/home/amandapotts/git/arkouda/arkouda/array_api/_manipulation_functions.py_stack,"def stack(arrays: Union[Tuple[Array, ...], List[Array]], /, *, axis: int = 0) -> Array:
""""""
Array API compatible wrapper for :py:func:`np.stack <numpy.stack>`.
See its docstring for more information.
""""""
return Array._new(
create_pdarray(
cast(
str,
generic_msg(
cmd=f""stack{arrays[0].ndim}D"",
args={
""names"": [a._array for a in arrays],
""n"": len(arrays),
""axis"": axis,
},
),
)
)
)
",['stack'],1,[],/array_api/_manipulation_functions.py_stack
